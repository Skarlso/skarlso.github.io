<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Aws on Ramblings of a build engineer</title>
    <link>http://skarlso.github.io/categories/aws/index.xml</link>
    <description>Recent content in Aws on Ramblings of a build engineer</description>
    <generator>Hugo -- gohugo.io</generator>
    <atom:link href="http://skarlso.github.io/categories/aws/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Furnace - The building of an AWS CLI Tool for CloudFormation and CodeDeploy - Part 1</title>
      <link>http://skarlso.github.io/2017/03/16/building-furnace-part-1</link>
      <pubDate>Thu, 16 Mar 2017 21:49:00 +0100</pubDate>
      
      <guid>http://skarlso.github.io/2017/03/16/building-furnace-part-1</guid>
      <description>

&lt;h1 id=&#34;building-furnace-part-1&#34;&gt;Building Furnace: Part 1&lt;/h1&gt;

&lt;h1 id=&#34;intro&#34;&gt;Intro&lt;/h1&gt;

&lt;p&gt;Hi folks.&lt;/p&gt;

&lt;p&gt;This is the first part of a 4 part series which talks about the process of building a middlish sized project in Go,
with AWS. Including Unit testing and a experimental plugin feature.&lt;/p&gt;

&lt;p&gt;The first part will talk about the AWS services used in brief and will contain a basic description for those who are not familiar
with them. The second part will talk about the Go SDK and the project structure itself, how it can be used, improved, and how it can
help in everyday life. The third part will talk about the experimental plugin system, and finally, we will tackle unit testing AWS
in Go.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s begin, shall we?&lt;/p&gt;

&lt;h1 id=&#34;aws&#34;&gt;AWS&lt;/h1&gt;

&lt;h2 id=&#34;cloudformation&#34;&gt;CloudFormation&lt;/h2&gt;

&lt;p&gt;If you haven&amp;rsquo;t yet read about, or know off, AWS&amp;rsquo; CloudFormation service, you can either go ahead and read the &lt;a href=&#34;https://aws.amazon.com/cloudformation/&#34;&gt;Documentation&lt;/a&gt;
or read on for a very quick summary. If you are familiar with CF, you should skip ahead to &lt;a href=&#34;##CodeDeploy&#34;&gt;CodeDeploy&lt;/a&gt; section.&lt;/p&gt;

&lt;p&gt;CF is a service which bundles together other AWS services (for example: EC2, S3, ELB, ASG, RDS) into one, easily manageable stack.
After a stack has been created, all the resources can be handled as one, located, tagged and used via CF specific console commands.
It&amp;rsquo;s also possible to define any number of parameters, so a stack can actually be very versatile. A parameter can be anything, from
SSH IP restriction to KeyPair names and list of tags to create or in what region the stack will be in.&lt;/p&gt;

&lt;p&gt;To describe how these parts fit together, one must use a CloudFormation Template file which is either in JSON or in
YAML format. A simple example looks like this:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;    Parameters:
      KeyName:
        Description: The EC2 Key Pair to allow SSH access to the instance
        Type: AWS::EC2::KeyPair::KeyName
    Resources:
      Ec2Instance:
        Type: AWS::EC2::Instance
        Properties:
          SecurityGroups:
          - Ref: InstanceSecurityGroup
          - MyExistingSecurityGroup
          KeyName:
            Ref: KeyName
          ImageId: ami-7a11e213
      InstanceSecurityGroup:
        Type: AWS::EC2::SecurityGroup
        Properties:
          GroupDescription: Enable SSH access via port 22
          SecurityGroupIngress:
          - IpProtocol: tcp
            FromPort: &#39;22&#39;
            ToPort: &#39;22&#39;
            CidrIp: 0.0.0.0/0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;There are a myriad of these template samples &lt;a href=&#34;https://aws.amazon.com/cloudformation/aws-cloudformation-templates/&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;m not going to explain this in too much detail. Parameters define the parameters, and resources define all the AWS services which
we would like to configure. Here we can see, that we are creating an EC2 instance with a custom Security Group plus and already
existing security group. ImageId is the AMI which will be used for the EC2 instance. The InstanceSecurityGroup is only defining
some SSH access to the instance.&lt;/p&gt;

&lt;p&gt;That is pretty much it. This can become bloated relatively quickly once, VPCs, ELBs, and ASGs come into play. And CloudFormation
templates can also contain simple logical switches, like, conditions, ref for variables, maps and other shenanigans.&lt;/p&gt;

&lt;p&gt;For example consider this part in the above example:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;      KeyName:
        Ref: KeyName
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Here, we use the &lt;code&gt;KeyName&lt;/code&gt; parameter as a Reference Value which will be interpolated to the real value, or the default one, as the
template gets processed.&lt;/p&gt;

&lt;h2 id=&#34;codedeploy&#34;&gt;CodeDeploy&lt;/h2&gt;

&lt;p&gt;If you haven&amp;rsquo;t heard about CodeDeploy yet, please browse the relevant &lt;a href=&#34;http://docs.aws.amazon.com/codedeploy/latest/userguide/welcome.html&#34;&gt;Documentation&lt;/a&gt;
or follow along for a &amp;ldquo;quick&amp;rdquo; description.&lt;/p&gt;

&lt;p&gt;CodeDeploy just does what the name says. It deploys code. Any kind of code, as long as the deployment process is described in a
file called &lt;code&gt;appspec.yml&lt;/code&gt;. It can be easy as coping a file to a specific location or incredibly complex with builds of various
kinds.&lt;/p&gt;

&lt;p&gt;For a simple example look at this configuration:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;    version: 0.0
    os: linux
    files:
      - source: /index.html
        destination: /var/www/html/
      - source: /healthy.html
        destination: /var/www/html/
    hooks:
      BeforeInstall:
        - location: scripts/install_dependencies
          timeout: 300
          runas: root
        - location: scripts/clean_up
          timeout: 300
          runas: root
        - location: scripts/start_server
          timeout: 300
          runas: root
      ApplicationStop:
        - location: scripts/stop_server
          timeout: 300
          runas: root
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;CodeDeploy applications have hooks and life-cycle events which can be used to control the deployment process of an like, starting
the WebServer; making sure files are in the right location; copying files, running configuration management software like puppet,
ansible or chef; etc, etc.&lt;/p&gt;

&lt;p&gt;What can be done in an &lt;code&gt;appspec.yml&lt;/code&gt; file is described here: &lt;a href=&#34;http://docs.aws.amazon.com/codedeploy/latest/userguide/app-spec-ref.html&#34;&gt;Appspec Reference Documentation&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Deployment happens in one of two ways:&lt;/p&gt;

&lt;h3 id=&#34;github&#34;&gt;GitHub&lt;/h3&gt;

&lt;p&gt;If the preferred way to deploy the application is from GitHub a commit hash must be used to identify which &amp;ldquo;version&amp;rdquo; of the
application is to be deployed. For example:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;    rev = &amp;amp;codedeploy.RevisionLocation{
        GitHubLocation: &amp;amp;codedeploy.GitHubLocation{
            CommitId:   aws.String(&amp;quot;kajdf94j0f9k309klksjdfkj&amp;quot;),
            Repository: aws.String(&amp;quot;Skarlso/furnace-codedeploy-app&amp;quot;),
        },
        RevisionType: aws.String(&amp;quot;GitHub&amp;quot;),
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Commit Id is the hash of the latest release and repository is the full account/repository pointing to the application.&lt;/p&gt;

&lt;h3 id=&#34;s3&#34;&gt;S3&lt;/h3&gt;

&lt;p&gt;The second way is to use an S3 bucket. The bucket will contain an archived version of the application with a given extension. I&amp;rsquo;m
saying given extension, because it has to be specified like this (and can be either &amp;lsquo;zip&amp;rsquo;, or &amp;lsquo;tar&amp;rsquo; or &amp;lsquo;tgz&amp;rsquo;):&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;    rev = &amp;amp;codedeploy.RevisionLocation{
        S3Location: &amp;amp;codedeploy.S3Location{
            Bucket:     aws.String(&amp;quot;my_codedeploy_bucket&amp;quot;),
            BundleType: aws.String(&amp;quot;zip&amp;quot;),
            Key:        aws.String(&amp;quot;my_awesome_app&amp;quot;),
            Version:    aws.String(&amp;quot;VersionId&amp;quot;),
        },
        RevisionType: aws.String(&amp;quot;S3&amp;quot;),
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Here, we specify the bucket name, the extension, the name of the file and an optional version id, which can be ignored.&lt;/p&gt;

&lt;h3 id=&#34;deploying&#34;&gt;Deploying&lt;/h3&gt;

&lt;p&gt;So how does code deploy get either of the applications to our EC2 instances? It uses an agent which is running on all of the
instances that we create. In order to do this, the agent needs to be present on our instance. For linux this can be achieved with
the following UserData (UserData in CF is the equivalent of a bootsrap script):&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;    &amp;quot;UserData&amp;quot; : {
        &amp;quot;Fn::Base64&amp;quot; : { &amp;quot;Fn::Join&amp;quot; : [ &amp;quot;\n&amp;quot;, [
            &amp;quot;#!/bin/bash -v&amp;quot;,
            &amp;quot;sudo yum -y update&amp;quot;,
            &amp;quot;sudo yum -y install ruby wget&amp;quot;,
            &amp;quot;cd /home/ec2-user/&amp;quot;,
            &amp;quot;wget https://aws-codedeploy-eu-central-1.s3.amazonaws.com/latest/install&amp;quot;,
            &amp;quot;chmod +x ./install&amp;quot;,
            &amp;quot;sudo ./install auto&amp;quot;,
            &amp;quot;sudo service codedeploy-agent start&amp;quot;,
        ] ] }
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;A simple user data configuration in the CloudFormation template will make sure that every instance that we create will have the
CodeDeploy agent running and waiting for instructions. This agent is self updating. Which can cause some trouble if AWS releases a
broken agent. However unlikely, it can happen. Never the less, once installed, it&amp;rsquo;s no longer a concern to be bothered with.&lt;/p&gt;

&lt;p&gt;It communications on HTTPS port 443.&lt;/p&gt;

&lt;p&gt;CodeDeploy identifies instances which need to be updated according to our preferences, by tagging the EC2 and Auto Scaling groups.
Tagging happens in the CloudFormation template through the AutoScalingGroup settings like this:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;    &amp;quot;Tags&amp;quot; : [
        {
            &amp;quot;Key&amp;quot; : &amp;quot;fu_stage&amp;quot;,
            &amp;quot;Value&amp;quot; : { &amp;quot;Ref&amp;quot;: &amp;quot;AWS::StackName&amp;quot; },
            &amp;quot;PropagateAtLaunch&amp;quot; : true
        }
    ]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This will give the EC2 instance a tag called &lt;code&gt;fu_stage&lt;/code&gt; with value equaling to the name of the stack. Once this is done, CodeDeploy
looks like this:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;    params := &amp;amp;codedeploy.CreateDeploymentInput{
        ApplicationName:               aws.String(appName),
        IgnoreApplicationStopFailures: aws.Bool(true),
        DeploymentGroupName:           aws.String(appName + &amp;quot;DeploymentGroup&amp;quot;),
        Revision:                      revisionLocation(),
        TargetInstances: &amp;amp;codedeploy.TargetInstances{
            AutoScalingGroups: []*string{
                aws.String(&amp;quot;AutoScalingGroupPhysicalID&amp;quot;),
            },
            TagFilters: []*codedeploy.EC2TagFilter{
                {
                    Key:   aws.String(&amp;quot;fu_stage&amp;quot;),
                    Type:  aws.String(&amp;quot;KEY_AND_VALUE&amp;quot;),
                    Value: aws.String(config.STACKNAME),
                },
            },
        },
        UpdateOutdatedInstancesOnly: aws.Bool(false),
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;CreateDeploymentInput is the entire parameter list that is needed in order to identify instances to deploy code to. We can see
here that it looks for an AutoScalingGroup by Physical Id and the tag labeled &lt;code&gt;fu_stage&lt;/code&gt;. Once found, it will use
&lt;code&gt;UpdateOutdatedInstancesOnly&lt;/code&gt; to determine if an instance needs to be updated or not. Set to false means, it always updates.&lt;/p&gt;

&lt;h1 id=&#34;furnace&#34;&gt;Furnace&lt;/h1&gt;

&lt;p&gt;Where does &lt;a href=&#34;https://github.com/Skarlso/go-furnace&#34;&gt;Furnace&lt;/a&gt; fit in, in all of this? Furnace provides a very easy mechanism to create,
delete and push code to a CloudFormation stack using CodeDeploy, and a couple of environment properties. Furnace &lt;code&gt;create&lt;/code&gt; will
create a CloudFormation stack according to the provided template, all the while asking for the parameters defined in it for
flexibility. &lt;code&gt;delete&lt;/code&gt; will remove the stack and all affiliated resources except for the created CodeDeploy application. For that,
there is &lt;code&gt;delete-application&lt;/code&gt;. &lt;code&gt;status&lt;/code&gt; will display information about the stack: Outputs, Parameters, Id, Name, and status.
Something like this:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;    2017/03/16 21:14:37 Stack state is:  {
      Capabilities: [&amp;quot;CAPABILITY_IAM&amp;quot;],
      CreationTime: 2017-03-16 20:09:38.036 +0000 UTC,
      DisableRollback: false,
      Outputs: [{
          Description: &amp;quot;URL of the website&amp;quot;,
          OutputKey: &amp;quot;URL&amp;quot;,
          OutputValue: &amp;quot;http://FurnaceSt-ElasticL-ID.eu-central-1.elb.amazonaws.com&amp;quot;
        }],
      Parameters: [
        {
          ParameterKey: &amp;quot;KeyName&amp;quot;,
          ParameterValue: &amp;quot;UserKeyPair&amp;quot;
        },
        {
          ParameterKey: &amp;quot;SSHLocation&amp;quot;,
          ParameterValue: &amp;quot;0.0.0.0/0&amp;quot;
        },
        {
          ParameterKey: &amp;quot;CodeDeployBucket&amp;quot;,
          ParameterValue: &amp;quot;None&amp;quot;
        },
        {
          ParameterKey: &amp;quot;InstanceType&amp;quot;,
          ParameterValue: &amp;quot;t2.nano&amp;quot;
        }
      ],
      StackId: &amp;quot;arn:aws:cloudformation:eu-central-1:9999999999999:stack/FurnaceStack/asdfadsf-adsfa3-432d-a-fdasdf&amp;quot;,
      StackName: &amp;quot;FurnaceStack&amp;quot;,
      StackStatus: &amp;quot;CREATE_COMPLETE&amp;quot;
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;( This will later be improved to include created resources as well. )&lt;/p&gt;

&lt;p&gt;Once the stack is &lt;code&gt;CREATE_COMPLETE&lt;/code&gt; a simple &lt;code&gt;push&lt;/code&gt; will deliver our application on each instance in the stack. We will get into
more detail about how these commands are working in Part 2 of this series.&lt;/p&gt;

&lt;h1 id=&#34;final-words&#34;&gt;Final Words&lt;/h1&gt;

&lt;p&gt;This is it for now.&lt;/p&gt;

&lt;p&gt;Join me next time when I will talk about the AWS Go SDK and its intricacies and we will start to look at the basics of Furnace.&lt;/p&gt;

&lt;p&gt;As always,
Thanks for reading!
Gergely.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Minecraft world automatic backup to AWS S3 bucket - Part 2 (Custom functions)</title>
      <link>http://skarlso.github.io/2016/04/17/minecraft-server-aws-s3-backup-part2</link>
      <pubDate>Sun, 17 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>http://skarlso.github.io/2016/04/17/minecraft-server-aws-s3-backup-part2</guid>
      <description>&lt;p&gt;Hi folks.&lt;/p&gt;

&lt;p&gt;Got an update for the backup script. This time, you&amp;rsquo;ll have the ability to implement your own upload capabilities. I provide a mock implementation for the required functions.&lt;/p&gt;

&lt;p&gt;Here is the script again, now modified and a bit cleaned up. I hope it&amp;rsquo;s helpful.&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;#!/bin/bash

if [[ -t 1 ]]; then
    colors=$(tput colors)
    if [[ $colors ]]; then
        RED=&#39;\033[0;31m&#39;
        LIGHT_GREEN=&#39;\033[1;32m&#39;
        NC=&#39;\033[0m&#39;
    fi
fi

if [[ -z ${MINECRAFT_BUCKET} ]]; then
    printf &amp;quot;Please set the env variable %bMINECRAFT_BUCKET%b to the s3 archive bucket name.\n&amp;quot; &amp;quot;${RED}&amp;quot; &amp;quot;${NC}&amp;quot;
    exit 1
fi

if [[ -z ${MINECRAFT_ARCHIVE_LIMIT} ]]; then
    printf &amp;quot;Please set the env variable %bMINECRAFT_ARCHIVE_LIMIT%b to limit the number of archives to keep.\n&amp;quot; &amp;quot;${RED}&amp;quot; &amp;quot;${NC}&amp;quot;
    exit 1
fi

if [[ -z ${MINECRAFT_WORLD} ]]; then
    printf &amp;quot;Please set the env variable %bMINECRAFT_WORLD%b to specify what world to back-up.\n&amp;quot; &amp;quot;${RED}&amp;quot; &amp;quot;${NC}&amp;quot;
    exit 1
fi

backup_world=${MINECRAFT_WORLD}
backup_bucket=${MINECRAFT_BUCKET}
backup_limit=${MINECRAFT_ARCHIVE_LIMIT}
archive_name=&amp;quot;${backup_world}-$(date +&amp;quot;%H-%M-%S-%m-%d-%Y&amp;quot;).zip&amp;quot;

function create_archive {
    printf &amp;quot;Creating archive of %b${backup_world}%b\n&amp;quot; &amp;quot;${RED}&amp;quot; &amp;quot;${NC}&amp;quot;
    zip -r $archive_name $backup_world
}

function amazon_bak {

    create_archive

    printf &amp;quot;Checking if bucket has more than %b${backup_limit}%b files already.\n&amp;quot; &amp;quot;${RED}&amp;quot; &amp;quot;${NC}&amp;quot;
    content=( $(aws s3 ls s3://$backup_bucket | awk &#39;{print $4}&#39;) )

    if [[ ${#content[@]} -eq $backup_limit || ${#content[@]} -gt $backup_limit  ]]; then
        echo &amp;quot;There are too many archives. Deleting oldest one.&amp;quot;
        # We can assume here that the list is in cronological order
    	printf &amp;quot;%bs3://${backup_bucket}/${content[0]}\n%b&amp;quot; &amp;quot;${RED}&amp;quot; &amp;quot;${NC}&amp;quot;
        aws s3 rm s3://$backup_bucket/${content[0]}
    fi

    printf &amp;quot;Uploading %b${archive_name}%b to s3 archive bucket.\n&amp;quot; &amp;quot;${RED}&amp;quot; &amp;quot;${NC}&amp;quot;
    state=$(aws s3 cp $archive_name s3://$backup_bucket)

    if [[ &amp;quot;$state&amp;quot; =~ &amp;quot;upload:&amp;quot; ]]; then
        printf &amp;quot;File upload %bsuccessful%b.\n&amp;quot; &amp;quot;${LIGHT_GREEN}&amp;quot; &amp;quot;${NC}&amp;quot;
    else
        printf &amp;quot;%bError%b occured while uploading archive. Please investigate.\n&amp;quot; &amp;quot;${RED}&amp;quot; &amp;quot;${NC}&amp;quot;
    fi
}

function custom {
    if [[ -e custom.sh ]]; then
        source ./custom.sh
    else
        echo &amp;quot;custom.sh script not found. Please implement the apropriate functions.&amp;quot;
        exit 1
    fi

    echo &amp;quot;Checking for the number of files. Limit is: $backup_limit.&amp;quot;
    files=( $(list) )
    if [[ ${#files[@]} -eq $backup_limit || ${#files[@]} -gt $backup_limit ]]; then
        echo &amp;quot;Deleting extra file.&amp;quot;
        delete ${files[0]}
        if [[ $? != 0 ]]; then
            printf &amp;quot;%bFailed%b to delete file. Please investigate failure.&amp;quot; &amp;quot;${RED}&amp;quot; &amp;quot;${NC}&amp;quot;
            exit $?
        fi
    fi

    echo &amp;quot;Zipping world.&amp;quot;
    create_archive

    echo &amp;quot;Uploading world.&amp;quot;
    upload $archive_name

    if [[ $? != 0 ]]; then
        printf &amp;quot;%bFailed%b to upload archive. Please investigate the error.&amp;quot; &amp;quot;${RED}&amp;quot; &amp;quot;${NC}&amp;quot;
        exit $?
    fi

    printf &amp;quot;Upload %bsuccessful%b&amp;quot; &amp;quot;${LIGHT_GREEN}&amp;quot; &amp;quot;${NC}&amp;quot;
}

function help {
    echo &amp;quot;Usage:&amp;quot;
    echo &amp;quot;./backup_world [METHOD]&amp;quot;
    echo &amp;quot;Exp.: ./backup_world aws|./backup_world custom|./backup_world dropbox&amp;quot;
    echo &amp;quot;Each method has it&#39;s own environment properties that it requires.&amp;quot;
    echo &amp;quot;Global: MINECRAFT_WORLD|MINECRAFT_BUCKET|MINECRAFT_ARCHIVE_LIMIT&amp;quot;
    echo &amp;quot;Custom: Have a file, called &#39;custom.sh&#39; which is sourced.&amp;quot;
    echo &amp;quot;Implement these three functions: upload | list | delete.&amp;quot;
    echo &amp;quot;upload -&amp;gt; should return exit code 0 on success, should return exit code 1 on failure.&amp;quot;
    echo &amp;quot;list -&amp;gt; should return a list of cronologically ordered items.&amp;quot;
    echo &amp;quot;delete -&amp;gt; should return exit code 0 on success, should return exit code 1 on failure.&amp;quot;
}

case $1 in
    aws )
        amazon_bak
        ;;
    custom )
        custom
        ;;
    * )
        help
        ;;
esac
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And here is the sample implementation for the custom upload functionality.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;#!/bin/bash

function upload {
    echo &amp;quot;uploading&amp;quot;
    local result=0
    return $result
}

function delete {
    echo &amp;quot;deleting $1&amp;quot;
    local result=0
    return $result
}

function list {
    local arr=(&amp;quot;file1&amp;quot; &amp;quot;file2&amp;quot; &amp;quot;file3&amp;quot;)
    echo &amp;quot;${arr[@]}&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Thanks for reading!&lt;/p&gt;

&lt;p&gt;Gergely.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Minecraft world automatic backup to AWS S3 bucket</title>
      <link>http://skarlso.github.io/2016/04/16/minecraft-server-aws-s3-backup</link>
      <pubDate>Sat, 16 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>http://skarlso.github.io/2016/04/16/minecraft-server-aws-s3-backup</guid>
      <description>&lt;p&gt;Hi Folks.&lt;/p&gt;

&lt;p&gt;Previously we created a Minecraft server using Docker. After my server got popular in the family, and a lot of stuff started to pile up on it, as a good IT person, I&amp;rsquo;m backing up the world once in a while.&lt;/p&gt;

&lt;p&gt;For that, I&amp;rsquo;m using AWS S3 with the CLI and a little bash script which runs once a week.&lt;/p&gt;

&lt;p&gt;The script is really straightforward. I&amp;rsquo;m doing manual versioning, although S3 does provide one out of the box. However, amazon&amp;rsquo;s S3 versioning doesn&amp;rsquo;t allow limiting the number of versions being kept. And since I&amp;rsquo;m doing that anyways, might as well take care of the rest.&lt;/p&gt;

&lt;p&gt;Without further ado, here is the script:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;#!/bin/bash

if [[ -t 1 ]]; then
    colors=$(tput colors)
    if [[ $colors ]]; then
        RED=&#39;\033[0;31m&#39;
        LIGHT_GREEN=&#39;\033[1;32m&#39;
        NC=&#39;\033[0m&#39;
    fi
fi

if [[ -z ${MINECRAFT_BUCKET} ]]; then
	printf &amp;quot;Please set the env variable ${RED}MINECRAFT_BUCKET${NC} to the s3 archive bucket name.\n&amp;quot;
	exit 0
fi

if [[ -z ${MINECRAFT_ARCHIVE_LIMIT} ]]; then
	printf &amp;quot;Please set the env variable ${RED}MINECRAFT_ARCHIVE_LIMIT${NC} to limit the number of archives to keep.\n&amp;quot;
	exit 0
fi

backup_bucket=${MINECRAFT_BUCKET}
backup_limit=${MINECRAFT_ARCHIVE_LIMIT}
world=$1
printf &amp;quot;Creating archive of ${RED}${world}${NC}\n&amp;quot;
archive_name=&amp;quot;${world}-$(date +&amp;quot;%H-%M-%S-%m-%d-%Y&amp;quot;).zip&amp;quot;
zip -r $archive_name $world

printf &amp;quot;Checking if bucket has more than ${RED}${backup_limit}${NC} files already.\n&amp;quot;
content=( $(aws s3 ls s3://$backup_bucket | awk &#39;{print $4}&#39;) )

if [[ ${#content[@]} -eq $backup_limit || ${#content[@]} -gt $backup_limit  ]]; then
    echo &amp;quot;There are too many archives. Deleting oldest one.&amp;quot;
    # We can assume here that the list is in cronological order
	printf &amp;quot;${RED}s3://${backup_bucket}/${content[0]}\n&amp;quot;
    aws s3 rm s3://$backup_bucket/${content[0]}
fi

printf &amp;quot;Uploading ${RED}${archive_name}${NC} to s3 archive bucket.\n&amp;quot;
state=$(aws s3 cp $archive_name s3://$backup_bucket)

if [[ &amp;quot;$state&amp;quot; =~ &amp;quot;upload:&amp;quot; ]]; then
    printf &amp;quot;File upload ${LIGHT_GREEN}successful${NC}.\n&amp;quot;
else
    printf &amp;quot;${RED}Error${NC} occured while uploading archive. Please investigate.\n&amp;quot;
fi
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;It uses environment properties to define where to upload the given world and how many versions to keep.&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;m calling this from a cron job, and it&amp;rsquo;s sitting next to where the Minecraft world is.&lt;/p&gt;

&lt;p&gt;That&amp;rsquo;s it folks.&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;ll start expanding on this idea and implement various services, like your own server address, or dropbox, or what have you.&lt;/p&gt;

&lt;p&gt;Happy backing up.&lt;/p&gt;

&lt;p&gt;Gergely.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>