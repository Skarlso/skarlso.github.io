<!doctype html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Aws &middot; Ramblings of a build engineer</title>

    <meta name="description" content="">

    <meta name="generator" content="Hugo 0.40.3" />
    <meta name="twitter:card" content="summary">
    
    <meta name="twitter:title" content="Aws &middot; Ramblings of a build engineer">
    <meta name="twitter:description" content="">

    <meta property="og:type" content="article">
    <meta property="og:title" content="Aws &middot; Ramblings of a build engineer">
    <meta property="og:description" content="">

    <link href='//fonts.googleapis.com/css?family=Source+Sans+Pro:400,700|Oxygen:400,700' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/pure/0.6.0/pure-min.css">
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/pure/0.6.0/grids-responsive-min.css">

    <link rel="stylesheet" href="https://skarlso.github.io//css/all.min.css">
    <link href="//maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css" rel="stylesheet">

    <link rel="alternate" type="application/rss+xml" title="Ramblings of a build engineer" href="https://skarlso.github.io//index.xml" />
</head>
<body>


<div id="layout" class="pure-g">
    <div class="sidebar pure-u-1 pure-u-md-1-4">
    <div class="header">
        <hgroup>
            <h1 class="brand-title"><a href="https://skarlso.github.io/">Ramblings of a build engineer</a></h1>
            <h2 class="brand-tagline"></h2>
        </hgroup>

        <nav class="nav">
            <ul class="nav-list">
                
                <li class="nav-item">
                    <a class="pure-button" href="https://twitter.com/Skarlso"><i class="fa fa-twitter"></i> Twitter</a>
                </li>
                
                
                <li class="nav-item">
                    <a class="pure-button" href="https://github.com/Skarlso "><i class="fa fa-github-alt"></i> github</a>
                </li>
                
                
                <li class="nav-item">
                    <a class="pure-button" href="https://linkedin.com/in/brautigamgergely "><i class="fa fa-linkedin-alt"></i> linkedin</a>
                </li>
                
                <li class="nav-item">
                    <a class="pure-button" href="https://skarlso.github.io//index.xml"><i class="fa fa-rss"></i> rss</a>
                </li>
                <li class="nav-item">
                    <link href="https://fonts.googleapis.com/css?family=Cookie" rel="stylesheet">
                    <a class="pure-button" target="_blank" href="https://www.buymeacoffee.com/skarlso">
                        <img src="https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg" alt="Buy me a coffee">
                        Buy me a coffee
                    </a>
                </li>
                <li class="nav-item">
                    
                    <a class="pure-button" href="https://skarlso.github.io/2018/01/13/furnace-massive-update/"><i class="fa fa-twitter"></i>Huge Furnace Update</a>
                    
                    <a class="pure-button" href="https://skarlso.github.io/2017/12/04/commit-build-deploy/"><i class="fa fa-twitter"></i>Commit-Build-Deploy With AWS CodeBuild and Lambda</a>
                    
                    <a class="pure-button" href="https://skarlso.github.io/2017/04/16/building-furnace-part-4/"><i class="fa fa-twitter"></i>Furnace - The building of an AWS CLI Tool for CloudFormation and CodeDeploy - Part 4</a>
                    
                    <a class="pure-button" href="https://skarlso.github.io/2017/03/22/building-furnace-part-3/"><i class="fa fa-twitter"></i>Furnace - The building of an AWS CLI Tool for CloudFormation and CodeDeploy - Part 3</a>
                    
                    <a class="pure-button" href="https://skarlso.github.io/2017/03/19/building-furnace-part-2/"><i class="fa fa-twitter"></i>Furnace - The building of an AWS CLI Tool for CloudFormation and CodeDeploy - Part 2</a>
                    
                    <a class="pure-button" href="https://skarlso.github.io/2017/03/16/building-furnace-part-1/"><i class="fa fa-twitter"></i>Furnace - The building of an AWS CLI Tool for CloudFormation and CodeDeploy - Part 1</a>
                    
                    <a class="pure-button" href="https://skarlso.github.io/2016/04/17/minecraft-server-aws-s3-backup-part2/"><i class="fa fa-twitter"></i>Minecraft world automatic backup to AWS S3 bucket - Part 2 (Custom functions)</a>
                    
                    <a class="pure-button" href="https://skarlso.github.io/2016/04/16/minecraft-server-aws-s3-backup/"><i class="fa fa-twitter"></i>Minecraft world automatic backup to AWS S3 bucket</a>
                    
                </li>
            </ul>
        </nav>
    </div>
</div>


    <div class="content pure-u-1 pure-u-md-3-4">
        <div>
            
            <div class="posts">
                
                <h1 class="content-subhead">13 Jan 2018, 22:34</h1>
                <section class="post">
                    <header class="post-header">

                        <a href="https://skarlso.github.io/2018/01/13/furnace-massive-update/" class="post-title">Huge Furnace Update</a>

                        <p class="post-meta">
                            
                                By <strong class="post-author">hannibal</strong>
                            
                            
                                under 
                                
                                <a class="post-category post-category-AWS" href="https://skarlso.github.io//categories/aws">AWS</a><a class="post-category post-category-Go" href="https://skarlso.github.io//categories/go">Go</a><a class="post-category post-category-Furnace" href="https://skarlso.github.io//categories/furnace">Furnace</a><a class="post-category post-category-GCP" href="https://skarlso.github.io//categories/gcp">GCP</a>
                            
                        </p>
                    </header>

                    <div class="post-description">
                        

<h1 id="intro">Intro</h1>

<p>Hi folks.</p>

<p>In the past couple of months I&rsquo;ve been slowly updating <a href="https://github.com/Skarlso/go-furnace">Furnace</a>.</p>

<p>There are three major changes that happened. Let&rsquo;s take a look at them, shall we?</p>

<h2 id="google-cloud-platform">Google Cloud Platform</h2>

<p>Furnace now supports <a href="https://cloud.google.com">Google Cloud Platform (GCP)</a>. It provides the same API to handle GCP resource as with AWS. Namely, <code>create</code>, <code>delete</code>, <code>status</code>, <code>update</code>. I opted to leave out <code>push</code> because Google mostly works with git based repositories, meaning a push is literary just a push, than Google handles distributing the new code by itself.</p>

<p>All the rest of the commands should work the same way as AWS.</p>

<h3 id="deployment-manager">Deployment Manager</h3>

<p>GCP has a similar service to AWS CloudFormations called <a href="https://cloud.google.com/deployment-manager/docs/">Deployment Manager</a>. The documentation is fairly detailed with a Bookshelf example app to deploy. Code and Templates can be found in their Git repositroy here: <a href="https://github.com/GoogleCloudPlatform/deploymentmanager-samples">Deployment Manager Git Repository</a>.</p>

<h3 id="setting-up-gcp">Setting up GCP</h3>

<p>As the README of Furnace outlines&hellip;</p>

<blockquote>
<p>Please carefully read and follow the instruction outlined in this document: <a href="https://cloud.google.com/sdk/#Quick_Start">Google Cloud Getting Started</a>. It will describe how to download and install the SDK and initialize cloud to a Project ID.</p>

<p>Take special attention to these documents:</p>

<p><a href="https://cloud.google.com/sdk/docs/initializing">Initializing GCloud Tools</a>
<a href="https://cloud.google.com/sdk/docs/authorizing">Authorizing Tools</a></p>

<p>Furnace uses a Google Key-File to authenticate with your Google Cloud Account and Project.
In the future, Furnace assumes these things are properly set up and in working order.</p>
</blockquote>

<p>To initialize the client, it uses the following code:</p>

<pre><code class="language-go">  ctx := context.Background()
  client, err := google.DefaultClient(ctx, dm.NdevCloudmanScope)
</code></pre>

<p>The DefaultClient in turn, does the following:</p>

<pre><code class="language-go">// FindDefaultCredentials searches for &quot;Application Default Credentials&quot;.
//
// It looks for credentials in the following places,
// preferring the first location found:
//
//   1. A JSON file whose path is specified by the
//      GOOGLE_APPLICATION_CREDENTIALS environment variable.
//   2. A JSON file in a location known to the gcloud command-line tool.
//      On Windows, this is %APPDATA%/gcloud/application_default_credentials.json.
//      On other systems, $HOME/.config/gcloud/application_default_credentials.json.
//   3. On Google App Engine it uses the appengine.AccessToken function.
//   4. On Google Compute Engine and Google App Engine Managed VMs, it fetches
//      credentials from the metadata server.
//      (In this final case any provided scopes are ignored.)
func FindDefaultCredentials(ctx context.Context, scope ...string) (*DefaultCredentials, error) {
</code></pre>

<p>Take note on the order. This is how Google will authenticate your requests.</p>

<h3 id="running-gcp">Running GCP</h3>

<p>Running gcp is largely similar to AWS. First, you create the necessary templates to your infrastructure. This is done via the Deployment Manager and it&rsquo;s templating engine. The GCP templates are Python <a href="http://jinja.pocoo.org/">JINJA</a> files. Examples are provided in the <code>template</code> directory. It&rsquo;s a bit more complicated than the CloudFormation templates in that it uses outside templates plus schema files to configure dynamic details.</p>

<p>It&rsquo;s all explained in these documents: <a href="https://cloud.google.com/deployment-manager/docs/step-by-step-guide/create-a-template">Creating a Template Step-by-step</a> and <a href="https://cloud.google.com/deployment-manager/docs/configuration/templates/create-basic-template">Creating a Basic Template</a>.</p>

<p>It&rsquo;s not trivial however. And using the API can also be confusing. The Google Code is just a generated Go code file using gRPC. But studying it may provide valuable insigth into how the API is structured. I&rsquo;m also providing some basic samples that I gathered together and the readme does a bit more explaining on how to use them.</p>

<h3 id="your-first-stack">Your First Stack</h3>

<p>Once you have everything set-up you&rsquo;ll need a configuration file for Furnace. The usage is outlined more here <a href="#YAML-Configuration">YAML Configuration</a>. The configuration file for GCP looks like this:</p>

<pre><code class="language-yaml">main:
  project_name: testplatform-1234
  spinner: 1
gcp:
  template_name: google_template.yaml
  stack_name: test-stack

</code></pre>

<p>Where <code>project_name</code> is the name you generate for your first billable Google Cloud Platform project. Template lives next to this yaml file and stack name must be DNS complient.</p>

<p>Once you have a project and a template setup, it&rsquo;s as simple as calling <code>./furnace-gcp create</code> or <code>./furnace-gcp create mycustomstack</code>.</p>

<h3 id="deleting">Deleting</h3>

<p>Deleting happens with <code>./furnace-gcp delete</code> or <code>./furnace-gcp delete mycustomstack</code>. Luckily, as with AWS, this means that every resource created with the DeploymentManager will be deleted leaving no need for search and cleanup.</p>

<h3 id="project-name-vs-project-id">Project Name vs. Project ID</h3>

<p>Unlike with AWS Google requires your stack name and project id to be DNS complient. This is most likely because all API calls and such contain that information.</p>

<h2 id="separate-binaries">Separate Binaries</h2>

<p>In order to mitigate some of Furnace&rsquo;s size, I&rsquo;m providing separate binaries for each service it supports.</p>

<p>The AWS binaries can be found in <code>aws</code> folder, and respectively, the Google Cloud Platform is located in <code>gcp</code>. Both are build-able by running <code>make</code>.</p>

<p>If you would like to run both with a single command, a top level make file is provided for your convinience. Just run <code>make</code> from the root. That will build all binaries. Later on, Digital Oceans will join the ranks.</p>

<h2 id="yaml-configuration">YAML Configuration</h2>

<p>Last but not least, Furnace now employs YAML files for configuration. However, it isn&rsquo;t JUST using YAML files. It also employs a smart configuration pattern which works as follows.</p>

<p>Since Furnace is a distributed binary file which could be running from any given location at any time. Because of that, at first I opted for a global configuration directory.</p>

<p>Now, however, furnace uses a furnace configuration file named with the following pattern: <code>.stackalias.furnace</code>. Where stackname, or stack is the name of a custom stack you would like to create for a project. The content of this file is a single entry, which is the location, relative to this file, of the YAML configuration files for the given stack. For example:</p>

<pre><code class="language-bash">stacks/mydatabasestack.yaml
</code></pre>

<p>This means, that in the directory called <code>stacks</code> there will a yaml configuration file for your database stack. The AWS config file looks like this:</p>

<pre><code class="language-YAML">main:
  stackname: FurnaceStack
  spinner: 1
aws:
  code_deploy_role: CodeDeployServiceRole
  region: us-east-1
  enable_plugin_system: false
  template_name: cloud_formation.template
  app_name: furnace_app
  code_deploy:
    # Only needed in case S3 is used for code deployment
    code_deploy_s3_bucket: furnace_code_bucket
    # The name of the zip file in case it's on a bucket
    code_deploy_s3_key: furnace_deploy_app
    # In case a Git Repository is used for the application, define these two settings
    git_account: Skarlso/furnace-codedeploy-app
    git_revision: b89451234...

</code></pre>

<p>The important part is the <code>template_name</code>. The template has to be next to this yaml file. To use this file, you simply call any of the AWS or GCP commands with an extra, optional parameter like this:</p>

<pre><code class="language-bash">./furnace-aws create mydatabase
</code></pre>

<p>Note that mydatabase will translate to <code>.mydatabase.furnace</code>.</p>

<p>The intelligent part is, that this file could be placed anywhere in the project folder structure; because furnace, when looking for a config file, traverses backwards from the current execution directory up until <code>/</code>. Where root is not included in the search.</p>

<p>Consider the following directory tree:</p>

<p>├── docs<br />
│   ├── <code>furnace-aws status mydatabase</code><br />
├── stacks<br />
│   ├── mystack.template<br />
│   └── mystack.yaml<br />
└── .mydatabase.furnace</p>

<p>You are currently in your <code>docs</code> directory and would like to ask for the status of your database. You don&rsquo;t have to move to the location of the setting file, just simply run the command from where you are. This only works if you are above the location of the file. If you would be below, furnace would say it can&rsquo;t find the file. Because it only traverses upwards.</p>

<p><code>.mydatabase.furnace</code> here contains only a single entry <code>stacks/mystack.yaml</code>. And that&rsquo;s it. This way, you could have multiple furnace files, for example a <code>.database.furnace</code>, <code>.front-end.furnace</code> and a <code>.backend.furnace</code>. All three would work in unison, and if want needs updating, simply run <code>./furnace-aws update backend</code>. And done!</p>

<h1 id="closing-words">Closing words</h1>

<p>As always, contributions are welcomed in the form of issues or pull requests. Questions anything, I tend to answer as soon as I can.</p>

<p>Always run the tests before submitting.</p>

<p>Thank you for reading.
Gergely.</p>

                    </div>
                </section>
                
                <h1 class="content-subhead">04 Dec 2017, 22:34</h1>
                <section class="post">
                    <header class="post-header">

                        <a href="https://skarlso.github.io/2017/12/04/commit-build-deploy/" class="post-title">Commit-Build-Deploy With AWS CodeBuild and Lambda</a>

                        <p class="post-meta">
                            
                                By <strong class="post-author">hannibal</strong>
                            
                            
                                under 
                                
                                <a class="post-category post-category-AWS" href="https://skarlso.github.io//categories/aws">AWS</a><a class="post-category post-category-Go" href="https://skarlso.github.io//categories/go">Go</a>
                            
                        </p>
                    </header>

                    <div class="post-description">
                        

<h1 id="intro">Intro</h1>

<p>Hi All.</p>

<p>Today I would like to write about an AWS finger practice.</p>

<p>Previously, I wrote about how I build and deploy my blog with <a href="www.wercker.com">Wercker</a>. Since, I&rsquo;m a cloud engineer and I dislike Oracle and it&rsquo;s ever expending tenctacles into the abyss, I wanted to switch to use something else.</p>

<p>My build and deploy cycle is simple.</p>

<p>Commit to Blogsource Repo -&gt; Wercker WebHook -&gt; Builds my blog using Hugo -&gt; Pushed to a Different Repository which my Github Blog.</p>

<p>That&rsquo;s all.</p>

<p>It&rsquo;s quiet possible to reproduce this on AWS without infering costs. Unless you publish like&hellip; a couple 100 posts / week.</p>

<p>I&rsquo;m going to use the following services: <a href="https://aws.amazon.com/cloudformation/">CloudFormation</a>, <a href="https://aws.amazon.com/lambda/details/">AWS Lambda</a>, <a href="https://aws.amazon.com/codebuild/">CodeBuild</a>, <a href="https://aws.amazon.com/s3/">S3</a>.</p>

<p>To deploy the below describe architecture in your account in us-east-1 region simply click this button:
<a href="https://console.aws.amazon.com/cloudformation/home?region=us-east-1#/stacks/new?stackName=blogbuilder&amp;templateURL=https://s3.amazonaws.com/blog-builder-template-bucket/template.yaml"><img src="https://skarlso.github.io/img/cloudformation-launch-stack.png" alt="Launch Stack" /></a></p>

<p>BEFORE doing that though you need the following created:</p>

<p>Have a bucket for your lambda function. The lambda function can be found here:</p>

<p><a href="https://github.com/Skarlso/aws-lambda-code-pusher">Lambda Repository</a>.</p>

<p>Zip up the lambda folder contents by doing this:</p>

<pre><code class="language-bash">cd lambda
zip -r gitpusher.zip *
aws s3 cp gitpusher.zip s3://your-lambda-bucket
</code></pre>

<p>That&rsquo;s it.</p>

<p>To read a description of the stack, please continue.</p>

<h1 id="tl-dr">TL;DR;</h1>

<p>The architecture I&rsquo;m about to lay out is simple in its use and design. I tried not to complicate things, because I think the simpler something is, the less prone to failure it will be.</p>

<p>In its most basic form the flow is as follows:</p>

<p><img src="https://skarlso.github.io/img/blog_builder_flow.png" alt="Flow" />.</p>

<p>You push something into a repository you provide. CodeBuild has a webhook to this repository so on each commit it starts to build the blog. The build will use a so called <code>buildspec.yaml</code> file which describes how your blog should be built. Mine looks like this:</p>

<pre><code class="language-yaml">version: 0.2

phases:
  install:
    commands:
      - echo Installing required packages and Hugo
      - apt-get update
      - apt-get install -y git golang wget
      - wget -q https://github.com/gohugoio/hugo/releases/download/v0.31/hugo_0.31_Linux-64bit.deb -O /tmp/hugo.dep
      - dpkg -i /tmp/hugo.dep
  pre_build:
    commands:
      - echo Downloading source code
      - git clone https://github.com/Skarlso/blogsource.git /opt/app
  build:
    commands:
      - echo Build started on `date`
      - cd /opt/app &amp;&amp; hugo --theme purehugo
  post_build:
    commands:
      - echo Build completed on `date`
artifacts:
  files:
    - /opt/app/public/**/*
</code></pre>

<p>When it&rsquo;s finished, CodeBuild will upload everything in the public folder as a zip to a bucket. The bucket has a lambda attached which triggers on putObject event with the extension <code>.zip</code>. It downloads the archive, extracts it and pushes it to another repository, which is the repository for the blog.</p>

<p>And done! That&rsquo;s it. For an architecture overview, please read on.</p>

<h1 id="architecture">Architecture</h1>

<p>Now, we are going to use CloudFormation stack to deploy these resources. Because we aren&rsquo;t animals to create them by hand, yes?</p>

<p>An overview of my current architecture is best shown by this image:</p>

<p><img src="https://skarlso.github.io/img/blog_builder_cf_template.png" alt="AWS Stack" />.</p>

<p>Let&rsquo;s go over these components one - by - one.</p>

<h2 id="lambda-role">Lambda Role</h2>

<p>This is the <a href="http://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles.html">Role</a> which allows the Lambda to access things in your account. It needs the following service access: s3, logs, lambda; and the following permissions: logs:Create*, logs:PutLogEvents, s3:GetObject, s3:ListBucket.</p>

<h2 id="code-build-role">Code Build Role</h2>

<p>This is the role which allows CodeBuild to have access to services it needs. These services are the following: s3, logs, ssm, codebuild. CodeBuild also needs the following actions allowed: logs:Create*, logs:PutLogEvents, s3:GetObject, s3:PutObject, ssm:GetParameters.</p>

<h2 id="build-bucket">Build Bucket</h2>

<p>This is the bucket in which CodeBuild will push the generated build artifact.</p>

<h2 id="blog-pusher-function">Blog Pusher Function</h2>

<p>This is the heart of this project. It contains the logic to download the zipped artifact, extract it, create a hollow repository from the extracted archive and push the changes to the repository. And just the changes.</p>

<p>This is achieve by a short Python 3.6 script which can be found in the linked repository.</p>

<h2 id="parameters">Parameters</h2>

<p>The stack requires you to provide a couple of parameters which are described in the template. Like, bucket name, github repository, git token and such. Please refer to the template for a full description of each.</p>

<h2 id="charges">Charges</h2>

<p>I recently push a couple of builds to test this configuration and I inferred 0.2 USD in charges. But that was like 10-15 builds a day.</p>

<h1 id="deploying">Deploying</h1>

<p>In order to deploy this you can use <a href="https://github.com/Skarlso/go-furnace">Furnace</a> to easily manage the template and it&rsquo;s parameters. Once you copy the template to the target directory, simply run <code>furnace aws create</code> and provide the necessary parameters.</p>

<h1 id="conclusion">Conclusion</h1>

<p>And that is all. A nice little stack which does the same as Wercker without costs but the leisure of simply pushing up some change to a repository of your choosing.</p>

<p>I hope you enjoyed this little write up as much as I enjoyed creating it.</p>

<p>As always,
Thanks for reading!
Gergely.</p>

                    </div>
                </section>
                
                <h1 class="content-subhead">16 Apr 2017, 09:23</h1>
                <section class="post">
                    <header class="post-header">

                        <a href="https://skarlso.github.io/2017/04/16/building-furnace-part-4/" class="post-title">Furnace - The building of an AWS CLI Tool for CloudFormation and CodeDeploy - Part 4</a>

                        <p class="post-meta">
                            
                                By <strong class="post-author">hannibal</strong>
                            
                            
                                under 
                                
                                <a class="post-category post-category-Golang" href="https://skarlso.github.io//categories/golang">Golang</a><a class="post-category post-category-AWS" href="https://skarlso.github.io//categories/aws">AWS</a>
                            
                        </p>
                    </header>

                    <div class="post-description">
                        

<h1 id="intro">Intro</h1>

<p>Hi folks.</p>

<p>Previously on this blog: <a href="https://skarlso.github.io/2017/03/16/building-furnace-part-1/">Part 1</a>. <a href="https://skarlso.github.io/2017/03/19/building-furnace-part-2/">Part 2</a>. <a href="https://skarlso.github.io/2017/03/22/building-furnace-part-3/">Part 3</a>.</p>

<p>In this part we are going to talk about Unit Testing Furnace and how to work some magic with AWS and Go.</p>

<h1 id="mock-stub-fake-dummy-canned-insert-name-here">Mock Stub Fake Dummy Canned <Insert Name Here></h1>

<p>Unit testing in Go usually follows the Dependency Injection model of dealing with Mocks and Stubs.</p>

<p>## DI</p>

<p>Dependency Inject in short is one object supplying the dependencies of another object. In a longer description, it&rsquo;s ideal to be used
for removing the lock on a third party library, like the AWS client. Imaging having code which solely depends on the AWS client. How
would you unit test that code without having to ACTUALLY connect to AWS? You couldn&rsquo;t. Every time you try to test the code it would run
the live code and it would try and connect to AWS and perform the operations it&rsquo;s design to do. The Ruby library with it&rsquo;s metaprogramming
allows you to set the client globally to stub responses, but, alas, this is not the world of Ruby.</p>

<p>Here is where DI comes to the rescue. If you have control over the AWS client on a very high level, and would pass it around as a function
parameter, or create that client in an <code>init()</code> function and have it globally defined; you would be able to implement your own client, and
have your code use that with stubbed responses which your tests need. For example, you would like a CreateApplication call to fail, or you
would like a DescribeStack which returns an aws.Error(&ldquo;StackAlreadyExists&rdquo;).</p>

<p>For this, however, you need the API of the AWS client. Which is provided by AWS.</p>

<h2 id="aws-client-api">AWS Client API</h2>

<p>In order for DI to work, the injected object needs to be of a certain type for us to inject our own. Luckily, AWS provides an Interface for
all of it&rsquo;s clients. Meaning, we can implement our own version for all of the clients, like S3, CloudFormation, CodeDeploy etc.</p>

<p>For each client you want to mock out, an <em>*iface</em> package should be present like this:</p>

<pre><code class="language-go">  &quot;github.com/aws/aws-sdk-go/service/cloudformation/cloudformationiface&quot;
</code></pre>

<p>In this package you find and use the interface like this:</p>

<pre><code class="language-go">type fakeCloudFormationClient struct {
	cloudformationiface.CloudFormationAPI
	err error
}
</code></pre>

<p>And with this, we have our own CloudFormation client. The real code uses the real clients as function parameters, like this:</p>

<pre><code class="language-go">// Execute defines what this command does.
func (c *Create) Execute(opts *commander.CommandHelper) {
	log.Println(&quot;Creating cloud formation session.&quot;)
	sess := session.New(&amp;aws.Config{Region: aws.String(config.REGION)})
	cfClient := cloudformation.New(sess, nil)
	client := CFClient{cfClient}
	createExecute(opts, &amp;client)
}
</code></pre>

<p>We can&rsquo;t test Execute itself, as it&rsquo;s using the real client here (or you could have a global from some library, thus allowing you to tests
even <code>Execute</code> here) but there is very little logic in this function for this very reason. All the logic is in small functions for which
the main starting point and our testing opportunity is, <code>createExecute</code>.</p>

<h2 id="stubbing-calls">Stubbing Calls</h2>

<p>Now, that we have our own client, and with the power of Go&rsquo;s interface embedding as seen above with CloudFormationAPI, we have to only stub
the functions which we are actually using, instead of every function of the given interface. This looks like this:</p>

<pre><code class="language-go">	cfClient := new(CFClient)
	cfClient.Client = &amp;fakeCloudFormationClient{err: nil}
</code></pre>

<p>Where cfClient is a struct like this:</p>

<pre><code class="language-go">// CFClient abstraction for cloudFormation client.
type CFClient struct {
	Client cloudformationiface.CloudFormationAPI
}
</code></pre>

<p>And a stubbed call can than be written as follows:</p>

<pre><code class="language-go">func (fc *fakeCreateCFClient) WaitUntilStackCreateComplete(input *cloudformation.DescribeStacksInput) error {
	return nil
}
</code></pre>

<p>This can range from a very trivial example, like the one above, to intricate ones as well, like this gem:</p>

<pre><code class="language-go">func (fc *fakePushCFClient) ListStackResources(input *cloudformation.ListStackResourcesInput) (*cloudformation.ListStackResourcesOutput, error) {
	if &quot;NoASG&quot; == *input.StackName {
		return &amp;cloudformation.ListStackResourcesOutput{
			StackResourceSummaries: []*cloudformation.StackResourceSummary{
				{
					ResourceType:       aws.String(&quot;NoASG&quot;),
					PhysicalResourceId: aws.String(&quot;arn::whatever&quot;),
				},
			},
		}, fc.err
	}
	return &amp;cloudformation.ListStackResourcesOutput{
		StackResourceSummaries: []*cloudformation.StackResourceSummary{
			{
				ResourceType:       aws.String(&quot;AWS::AutoScaling::AutoScalingGroup&quot;),
				PhysicalResourceId: aws.String(&quot;arn::whatever&quot;),
			},
		},
	}, fc.err
}
</code></pre>

<p>This ListStackResources stub lets us test two scenarios based on the stackname. If the test stackname is &lsquo;NoASG&rsquo; it will return a result
which equals to a result containing no AutoScaling Group. Otherwise, it will return the correct ResourceType for an ASG.</p>

<p>It is a common practice to line up several scenario based stubbed responses in order to test the robustness of your code.</p>

<p>Unfortunately, this also means that your tests will be a bit cluttered with stubs and mock structs and whatnots. For that, I&rsquo;m partially
using a package available struct file in which I&rsquo;m defining most of the mock structs at least. And from there on, the tests will only contain
specific stubs for that particular file. This can be further fine grained by having defaults and than only override in case you need something
else.</p>

<h1 id="testing-fatals">Testing fatals</h1>

<p>Now, the other point which is not really AWS related, but still comes to mind when dealing with Furnace, is testing error scenarios.</p>

<p>Because Furnace is a CLI application it uses Fatals to signal if something is wrong and it doesn&rsquo;t want to continue or recover because, frankly
it can&rsquo;t. If AWS throws an error, that&rsquo;s it. You can retry, but in 90% of the cases, it&rsquo;s usually something that you messed up.</p>

<p>So, how do we test for a fatal or an <code>os.Exit</code>? There are a number of points on that if you do a quick search. You may end up on this talk:
<a href="https://talks.golang.org/2014/testing.slide#23">GoTalk 2014 Testing Slide #23</a>. Which does an interesting thing. It calls the test binary in a
separate process and tests the exit code.</p>

<p>Others, and me as well, will say that you have to have your own logger implemented and use a different logger / os.Exit in your test environment.</p>

<p>Others others will tell you to not to have tests around os.Exit and fatal things, rather return an error and only the main should pop a world
ending event. I leave it up to you which you want to use. Either is fine.</p>

<p>In Furnace, I&rsquo;m using a global logger in my error handling util like this:</p>

<pre><code class="language-go">// HandleFatal handler fatal errors in Furnace.
func HandleFatal(s string, err error) {
	LogFatalf(s, err)
}
</code></pre>

<p>And <code>LogFatalf</code> is an exported variable <code>var LogFatalf = log.Fatalf</code>. Than in a test, I just override this variable with a local anonymous
function:</p>

<pre><code class="language-go">func TestCreateExecuteEmptyStack(t *testing.T) {
	failed := false
	utils.LogFatalf = func(s string, a ...interface{}) {
		failed = true
	}
	config.WAITFREQUENCY = 0
	client := new(CFClient)
	stackname := &quot;EmptyStack&quot;
	client.Client = &amp;fakeCreateCFClient{err: nil, stackname: stackname}
	opts := &amp;commander.CommandHelper{}
	createExecute(opts, client)
	if !failed {
		t.Error(&quot;expected outcome to fail during create&quot;)
	}
}
</code></pre>

<p>It can get even more granular by testing for the error message to make sure that it actually fails at the point we think we are
testing:</p>

<pre><code class="language-go">func TestCreateStackReturnsWithError(t *testing.T) {
	failed := false
	expectedMessage := &quot;failed to create stack&quot;
	var message string
	utils.LogFatalf = func(s string, a ...interface{}) {
		failed = true
		if err, ok := a[0].(error); ok {
			message = err.Error()
		}
	}
	config.WAITFREQUENCY = 0
	client := new(CFClient)
	stackname := &quot;NotEmptyStack&quot;
	client.Client = &amp;fakeCreateCFClient{err: errors.New(expectedMessage), stackname: stackname}
	config := []byte(&quot;{}&quot;)
	create(stackname, config, client)
	if !failed {
		t.Error(&quot;expected outcome to fail&quot;)
	}
	if message != expectedMessage {
		t.Errorf(&quot;message did not equal expected message of '%s', was:%s&quot;, expectedMessage, message)
	}
}
</code></pre>

<h1 id="conclusion">Conclusion</h1>

<p>This is it. That&rsquo;s all it took to write Furnace. I hope you enjoyed reading it as much as I enjoyed writing all these thoughts down.</p>

<p>I hope somebody might learn from my journey and also improve upon it.</p>

<p>Any comments are much appreciated and welcomed. Also, PRs and Issues can be submitted on the GitHub page of <a href="https://github.com/Skarlso/go-furnace">Furnace</a>.</p>

<p>Thank you for reading!
Gergely.</p>

                    </div>
                </section>
                
                <h1 class="content-subhead">22 Mar 2017, 12:03</h1>
                <section class="post">
                    <header class="post-header">

                        <a href="https://skarlso.github.io/2017/03/22/building-furnace-part-3/" class="post-title">Furnace - The building of an AWS CLI Tool for CloudFormation and CodeDeploy - Part 3</a>

                        <p class="post-meta">
                            
                                By <strong class="post-author">hannibal</strong>
                            
                            
                                under 
                                
                                <a class="post-category post-category-Golang" href="https://skarlso.github.io//categories/golang">Golang</a><a class="post-category post-category-AWS" href="https://skarlso.github.io//categories/aws">AWS</a>
                            
                        </p>
                    </header>

                    <div class="post-description">
                        

<h1 id="intro">Intro</h1>

<p>Hi folks.</p>

<p>Previously on this blog: <a href="http://skarlso.github.io/2017/03/16/building-furnace-part-1/">Part 1</a>. <a href="https://skarlso.github.io/2017/03/19/building-furnace-part-2/">Part 2</a>. <a href="https://skarlso.github.io/2017/04/16/building-furnace-part-4/">Part 4</a>.</p>

<p>In this part, I&rsquo;m going to talk about the experimental plugin system of Furnace.</p>

<h1 id="go-experimental-plugins">Go Experimental Plugins</h1>

<p>Since Go 1.8 was released, an exciting and new feature was introduced called a Plug-in system. This system works with dynamic
libraries built with a special switch to <code>go build</code>. These libraries, <code>.so</code> or <code>.dylib</code> (later), are than loaded and once that
succeeds, specific functions can be called from them (symbol resolution).</p>

<p>We will see how this works. For package information, visit the plugin packages Go doc page
<a href="https://tip.golang.org/pkg/plugin/">here</a>.</p>

<h1 id="furnace-plugins">Furnace Plugins</h1>

<p>So, what does furnace use plugins for? Furnace uses plugins to execute arbitery code in, currently, four given locations / events.</p>

<p>These are: <code>pre_create, post_create, pre_delete, post_delete</code>. These events are called, as their name suggests, before and after
the creation and deletion of the CloudFormation stack. It allows the user to execute some code without having to rebuild the whole
project. It does that by defining a single entry point for the custom code called <code>RunPlugin</code>. Any number of functions can be
implemented, but the plugin MUST provide this single, exported function. Otherwise it will fail and ignore that plugin.</p>

<h2 id="using-plugins">Using Plugins</h2>

<p>It&rsquo;s really easy to implement, and use these plugins. I&rsquo;m not going into the detail of how to load them, because that is done by
Furnace, but only how to write and use them.</p>

<p>To use a plugin, create a go file called: <code>0001_mailer.go</code>. The <code>0001</code> before it will define WHEN it&rsquo;s executed.
Having multiple plugins is completely okay. Execution of order however, depends on the names of the files.</p>

<p>Now, in 0001_mailer.post_create we would have something like this:</p>

<pre><code class="language-go">package main

import &quot;log&quot;

// RunPlugin runs the plugin.
func RunPlugin() {
	log.Println(&quot;My Awesome Pre Create Plugin.&quot;)
}
</code></pre>

<p>Next step is the build this file to be a plugin library. Note: Right now, this only works on Linux!</p>

<p>To build this file run the following:</p>

<pre><code>go build -buildmode=plugin -o 0001_mailer.pre_create 0001_mailer.go
</code></pre>

<p>The important part here is the extension of the file specified with <code>-o</code>. It&rsquo;s important because that&rsquo;s how Furnace identifies
what plugins it has to run.</p>

<p>Finally, copy this file to <code>~/.config/go-furnace/plugins</code> and you are all set.</p>

<h2 id="slack-notification-plugin">Slack notification Plugin</h2>

<p>To demonstrate how a plugin could be used is if you need some kind of notification once a Stack is completed. For example, you
might want to send a message to a Slack room. To do this, your plugin would look something like this:</p>

<pre><code class="language-go">package main

import (
	&quot;fmt&quot;
	&quot;os&quot;

	&quot;github.com/nlopes/slack&quot;
)

func RunPlugin() {
	stackname := os.Getenv(&quot;FURNACE_STACKNAME&quot;)
	api := slack.New(&quot;YOUR_TOKEN_HERE&quot;)
	params := slack.PostMessageParameters{}
	channelID, timestamp, err := api.PostMessage(&quot;#general&quot;, fmt.Sprintf(&quot;Stack with name '%s' is Done.&quot;, stackname), params)
	if err != nil {
		fmt.Printf(&quot;%s\n&quot;, err)
		return
	}
	fmt.Printf(&quot;Message successfully sent to channel %s at %s&quot;, channelID, timestamp)
}
</code></pre>

<p>Currently, Furnace has no ability to share information of the stack with an outside plugin. Thus &lsquo;Done&rsquo; could be anything from
Rollback to Failed to CreateComplete.</p>

<h1 id="closing-words">Closing Words</h1>

<p>That&rsquo;s it for plugins. Thanks very much for reading!
Gergely.</p>

                    </div>
                </section>
                
                <h1 class="content-subhead">19 Mar 2017, 12:03</h1>
                <section class="post">
                    <header class="post-header">

                        <a href="https://skarlso.github.io/2017/03/19/building-furnace-part-2/" class="post-title">Furnace - The building of an AWS CLI Tool for CloudFormation and CodeDeploy - Part 2</a>

                        <p class="post-meta">
                            
                                By <strong class="post-author">hannibal</strong>
                            
                            
                                under 
                                
                                <a class="post-category post-category-Golang" href="https://skarlso.github.io//categories/golang">Golang</a><a class="post-category post-category-AWS" href="https://skarlso.github.io//categories/aws">AWS</a>
                            
                        </p>
                    </header>

                    <div class="post-description">
                        

<h1 id="intro">Intro</h1>

<p>Hi folks.</p>

<p>Previously on this blog: <a href="https://skarlso.github.io/2017/03/16/building-furnace-part-1/">Part 1</a>, <a href="https://skarlso.github.io/2017/03/22/building-furnace-part-3/">Part 3</a>, <a href="https://skarlso.github.io/2017/04/16/building-furnace-part-4/">Part 4</a></p>

<p>In this part, I&rsquo;m going to talk about the AWS Go SDK and begin do dissect the intricacies of Furnace.</p>

<h1 id="aws-sdk">AWS SDK</h1>

<p>Fortunately, the Go SDK for AWS is quiet verbose and littered with examples of all sorts. But that doesn&rsquo;t make it less complex
and less cryptic at times. I&rsquo;m here to lift some of the early confusions, in hopes that I can help someone to avoid wasting time.</p>

<h2 id="getting-started-and-developers-guide">Getting Started and Developers Guide</h2>

<p>As always, and common from AWS, the documentation is top notch. There is a 141 pages long developer&rsquo;s guide on the SDK containing
a getting started section and an API reference. Go check it out. I&rsquo;ll wait. <a href="http://docs.aws.amazon.com/sdk-for-go/v1/developer-guide/aws-sdk-go-dg.pdf">AWS Go SDK DG PDF</a>. I will only talk about some gotchas and things I encountered, not the basics of the SDK.</p>

<h2 id="aws-string-and-other-types">aws.String and other types</h2>

<p>Something which is immediately visible once we take a look at the API is that everything is a pointer. Now, there are a
tremendous amount of discussions about this, but I&rsquo;m with Amazon. There are various reasons for it, but to list the most prominent
ones:
    - Type completion and compile time type safety.
    - Values for AWS API calls have valid zero values, in addition to being optional, i.e. not being provided at all.
    - Other option, like, empty interfaces with maps, or using zero values, or struct wrappers around every type, made life much
       harder rather than easier or not possible at all.
    - The AWS API is volatile. You never know when something gets to be optional, or required. Pointers made that decision easy.</p>

<p>There are good number of other discussions around this topic, for example: <a href="https://github.com/aws/aws-sdk-go/issues/363">AWS Go GitHub #363</a>.</p>

<p>In order to use primitives, AWS has helper functions like <code>aws.String</code>. Because &amp;&ldquo;asdf&rdquo; is not allowed, you would have to create a
variable and use its address in situations where a string pointer is needed, for example, name of the stack. These primitive helpers will
make in-lining possible. We&rsquo;ll see later that they are used to a great extent. Pointers, however, make life a bit difficult when
constructing Input structs and make for poor aesthetics.</p>

<p>This is something I&rsquo;m returning in a test for stubbing a client call:</p>

<pre><code class="language-go">		return &amp;cloudformation.ListStackResourcesOutput{
			StackResourceSummaries: []*cloudformation.StackResourceSummary{
				{
					ResourceType:       aws.String(&quot;NoASG&quot;),
					PhysicalResourceId: aws.String(&quot;arn::whatever&quot;),
				},
			},
		}
</code></pre>

<p>This doesn&rsquo;t look so appealing, but one gets used to it quickly.</p>

<h2 id="error-handling">Error handling</h2>

<p>Errors also have their own types. An AWS error looks like this:</p>

<pre><code class="language-go">if err != nil {
    if awsErr, ok := err.(awserr.Error); ok {
    }
}
</code></pre>

<p>First, we check if error is nil, than we type check if the error is an AWS error or something different. In the wild, this will
look something like this:</p>

<pre><code class="language-go">	if err != nil {
		if awsErr, ok := err.(awserr.Error); ok {
			if awsErr.Code() != codedeploy.ErrCodeDeploymentGroupAlreadyExistsException {
				log.Println(awsErr.Code())
				return err
			}
			log.Println(&quot;DeploymentGroup already exists. Nothing to do.&quot;)
			return nil
		}
		return err
	}
</code></pre>

<p>If it&rsquo;s an AWS error, we can check further for the error code that it returns in order to identify what to handle, or what to throw
on to the caller to a potential fatal. Here, I&rsquo;m ignoring the AlreadyExistsException because, if it does, we just go on to a next
action.</p>

<h2 id="examples">Examples</h2>

<p>Luckily the API doc is very mature. In most of the cases, they provide an example to an API call. These examples, however, from
time to time provide more confusion than clarity. Take CloudFormation. For me, when I first glanced upon the
description of the API it wasn&rsquo;t immediately clear that the <code>TemplateBody</code> was supposed to be the whole template, and that
the rest of the fields were almost all optional settings. Or provided overrides in special cases.</p>

<p>And since the template is not an ordinary JAML or JSON file, I was looking for something that parses it into that the Struct I
was going to use. After some time, and digging, I realized that I didn&rsquo;t need that, and that I just need to read in the template,
define some extra parameters, and give the TemplateBody the whole of the template. The parameters defined by the CloudFormation
template where extracted for me by <code>ValidateTemplate</code> API call which returned all of them in a convenient
<code>[]*cloudformation.Parameter</code> slice. These things are not described in the document or visible from the examples. I mainly found
them through playing with the API and focused experimentation.</p>

<h2 id="waiters">Waiters</h2>

<p>From other SDK implementations, we got used to Waiters. These handy methods wait for a service to become available or for certain
situations to take in effect, like a Stage being <code>CREATE_COMPLETE</code>. The Go waiters, however, don&rsquo;t allow for callback to be fired,
or for running blocks, like the ruby SDK does. For this, I wrote a handy little waiter for myself, which outputs a spinner to see
that we are currently waiting for something and not frozen in time. This waiter looks like this:</p>

<pre><code class="language-go">// WaitForFunctionWithStatusOutput waits for a function to complete its action.
func WaitForFunctionWithStatusOutput(state string, freq int, f func()) {
	var wg sync.WaitGroup
	wg.Add(1)
	done := make(chan bool)
	go func() {
		defer wg.Done()
		f()
		done &lt;- true
	}()
	go func() {
		counter := 0
		for {
			counter = (counter + 1) % len(Spinners[config.SPINNER])
			fmt.Printf(&quot;\r[%s] Waiting for state: %s&quot;, yellow(string(Spinners[config.SPINNER][counter])), red(state))
			time.Sleep(time.Duration(freq) * time.Second)
			select {
			case &lt;-done:
				fmt.Println()
				break
			default:
			}
		}
	}()

	wg.Wait()
}
</code></pre>

<p>And I&rsquo;m calling it with the following method:</p>

<pre><code class="language-go">	utils.WaitForFunctionWithStatusOutput(&quot;DELETE_COMPLETE&quot;, config.WAITFREQUENCY, func() {
		cfClient.Client.WaitUntilStackDeleteComplete(describeStackInput)
	})
</code></pre>

<p>This would output these lines to the console:</p>

<pre><code class="language-bash">[\] Waiting for state: DELETE_COMPLETE
</code></pre>

<p>The spinner can be configured to be one of the following types:</p>

<pre><code class="language-go">var Spinners = []string{`←↖↑↗→↘↓↙`,
	`▁▃▄▅▆▇█▇▆▅▄▃`,
	`┤┘┴└├┌┬┐`,
	`◰◳◲◱`,
	`◴◷◶◵`,
	`◐◓◑◒`,
	`⣾⣽⣻⢿⡿⣟⣯⣷`,
	`|/-\`}
</code></pre>

<p>Handy.</p>

<p>And with that, let&rsquo;s dive into the basics of Furnace.</p>

<h1 id="furnace">Furnace</h1>

<h2 id="directory-structure-and-packages">Directory Structure and Packages</h2>

<p>Furnace is divided into three main packages.</p>

<h3 id="commands">commands</h3>

<p>Commands package is where the gist of Furnace lies. These commands represent the commands which are used through the CLI. Each
file has the implementation for one command. The structure is devised by this library: <a href="https://github.com/Yitsushi/go-commander">Yitsushi&rsquo;s Command Library</a>.
As of the writing of this post, the following commands are available:
- create - Creates a stack using the CloudFormation template file under ~/.config/go-furnace
- delete - Deletes the created Stack. Doesn&rsquo;t do anything if the stack doesn&rsquo;t exist
- push - Pushes an application to a stack
- status - Displays information about the stack
- delete-application - Deletes the CodeDeploy application and deployment group created by <code>push</code></p>

<p>These commands represent the heart of furnace. I would like to keep these to a minimum, but I do plan on adding more, like
<code>update</code> and <code>rollout</code>. Further details and help messages on these commands can be obtained by running: <code>./furnace help</code> or
<code>./furnace help create</code>.</p>

<pre><code class="language-bash">❯ ./furnace help push
Usage: furnace push appName [-s3]

Push a version of the application to a stack

Examples:
  furnace push
  furnace push appName
  furnace push appName -s3
  furnace push -s3
</code></pre>

<h3 id="config">config</h3>

<p>Contains the configuration loader and some project wide defaults which are as follows:
- Events for the plugin system - <code>pre-create</code>, <code>post-create</code>, <code>pre-delete</code>, <code>post-delete</code>.
- CodeDeploy role name - <code>CodeDeployServiceRole</code>. This is used if none is provided to locate the CodeDeploy IAM role.
- Wait frequency - Is the setting which controls how long the waiter should sleep in between status updates. Default is <code>1s</code>.
- Spinner - Is just the number of the spinner to use.
- Plugin registry - Is a map of functions to run for the above events.</p>

<p>Further more, config loads the CloudFormation template and checks if some necessary settings are present in the environment, exp:
the configuration folder under <code>~/.config/go-furnace</code>.</p>

<h3 id="utils">utils</h3>

<p>These are some helper functions which are used throughout the project. To list them:
- error_handler - Is a simple error handler. I&rsquo;m thinking of refactoring this one to some saner version.
- spinner - Sets up which spinner to use in the waiter function.
- waiter - Contains the verbose waiter introduced above under <a href="##Waiters">Waiters</a>.</p>

<h2 id="configuration-and-environment-variables">Configuration and Environment variables</h2>

<p>Furnace is a Go application, thus it doesn&rsquo;t have the luxury of Ruby or Python where the configuration files are usually bundled
with the app. But, it does have a standard for it. Usually, configurations reside in either of these two locations. Environment
Properties or|and configuration files under a fixed location ( i.e. HOME/.config/app-name ). Furnace employs both.</p>

<p>Settings like, region, stack name, enable plugin system, are under environment properties ( though this can change ), while the
CloudFormation template lives under <code>~/.config/go-furnace/</code>. Lastly it assumes some things, like the Deployment IAM role just
exists under the used AWS account. All these are loaded and handled by the config package described above.</p>

<h2 id="usage">Usage</h2>

<p>A typical scenario for Furnace would be the following:</p>

<ul>
<li>Setup your CloudFormation template or use the one provided. The one provided sets up a highly available and self healing setting
using Auto-Scaling and Load-Balancing with a single application instance. Edit this template to your liking than copy it to
<code>~/.config/go-furnace</code>.</li>
<li>Create the configured stack with <code>./furnace create</code>.</li>
<li>Create will ask for the parameters defined in the template. If defaults are setup, simply hitting enter will use these defaults.
Take note, that the provided template sets up SSH access via a provided key. If that key is not present in CF, you won&rsquo;t be able
to SSH into the created instance.</li>
<li>Once the stack is completed, the application is ready to be pushed. To do this, run: <code>./furnace push</code>. This will locate the
appropriate version of the app from S3 or GitHub and push that version to the instances in the Auto-Scaling group. To all of
them.</li>
</ul>

<h2 id="general-practices-applied-to-the-project">General Practices Applied to the Project</h2>

<h3 id="commands-1">Commands</h3>

<p>For each command the main entry point is the <code>execute</code> function. These functions are usually calling out the small chunks of
distributed methods. Logic was kept to a bare minimum ( probably could be simplified even further ) in the execute functions
mostly for testability and the likes. We will see that in a followup post.</p>

<h3 id="errors">Errors</h3>

<p>Errors are handled immediately and usually through a fatal. If any error occurs than the application is halted. In followup
versions this might become more granular. I.e. don&rsquo;t immediately stop the world, maybe try to recover, or create a Poller or
Re-Tryer, which tries a call again for a configured amount of times.</p>

<h3 id="output-colors">Output colors</h3>

<p>Not that important, but still&hellip; Aesthetics. Displaying data to the console in a nice way gives it some extra flare.</p>

<h3 id="makefile">Makefile</h3>

<p>This project works with a Makefile for various reasons. Later on, once the project might become more complex, a Makefile makes it
really easy to handle different ways of packaging the application. Currently, for example, it provides a <code>linux</code> target which will
make Go build the project for Linux architecture on any other Architecture i.e. cross-compiling.</p>

<p>It also provides an easy way to run unit tests with <code>make test</code> and installing with <code>make &amp;&amp; make install</code>.</p>

<h1 id="closing-words">Closing Words</h1>

<p>That is all for Part 2. Join me in Part 3 where I will talk about the experimental Plugin system that Furnace employs.</p>

<p>Thank you for reading!
Gergely.</p>

                    </div>
                </section>
                
                <h1 class="content-subhead">16 Mar 2017, 21:49</h1>
                <section class="post">
                    <header class="post-header">

                        <a href="https://skarlso.github.io/2017/03/16/building-furnace-part-1/" class="post-title">Furnace - The building of an AWS CLI Tool for CloudFormation and CodeDeploy - Part 1</a>

                        <p class="post-meta">
                            
                                By <strong class="post-author">hannibal</strong>
                            
                            
                                under 
                                
                                <a class="post-category post-category-Golang" href="https://skarlso.github.io//categories/golang">Golang</a><a class="post-category post-category-AWS" href="https://skarlso.github.io//categories/aws">AWS</a>
                            
                        </p>
                    </header>

                    <div class="post-description">
                        

<h1 id="other-posts">Other posts:</h1>

<p><a href="https://skarlso.github.io/2017/03/19/building-furnace-part-2/">Part 2</a>, <a href="https://skarlso.github.io/2017/03/22/building-furnace-part-3/">Part 3</a>, <a href="https://skarlso.github.io/2017/04/16/building-furnace-part-4/">Part 4</a>.</p>

<h1 id="building-furnace-part-1">Building Furnace: Part 1</h1>

<h1 id="intro">Intro</h1>

<p>Hi folks.</p>

<p>This is the first part of a 4 part series which talks about the process of building a middlish sized project in Go,
with AWS. Including Unit testing and a experimental plugin feature.</p>

<p>The first part will talk about the AWS services used in brief and will contain a basic description for those who are not familiar
with them. The second part will talk about the Go SDK and the project structure itself, how it can be used, improved, and how it can
help in everyday life. The third part will talk about the experimental plugin system, and finally, we will tackle unit testing AWS
in Go.</p>

<p>Let&rsquo;s begin, shall we?</p>

<h1 id="aws">AWS</h1>

<h2 id="cloudformation">CloudFormation</h2>

<p>If you haven&rsquo;t yet read about, or know off, AWS&rsquo; CloudFormation service, you can either go ahead and read the <a href="https://aws.amazon.com/cloudformation/">Documentation</a>
or read on for a very quick summary. If you are familiar with CF, you should skip ahead to <a href="##CodeDeploy">CodeDeploy</a> section.</p>

<p>CF is a service which bundles together other AWS services (for example: EC2, S3, ELB, ASG, RDS) into one, easily manageable stack.
After a stack has been created, all the resources can be handled as one, located, tagged and used via CF specific console commands.
It&rsquo;s also possible to define any number of parameters, so a stack can actually be very versatile. A parameter can be anything, from
SSH IP restriction to KeyPair names and list of tags to create or in what region the stack will be in.</p>

<p>To describe how these parts fit together, one must use a CloudFormation Template file which is either in JSON or in
YAML format. A simple example looks like this:</p>

<pre><code class="language-yaml">    Parameters:
      KeyName:
        Description: The EC2 Key Pair to allow SSH access to the instance
        Type: AWS::EC2::KeyPair::KeyName
    Resources:
      Ec2Instance:
        Type: AWS::EC2::Instance
        Properties:
          SecurityGroups:
          - Ref: InstanceSecurityGroup
          - MyExistingSecurityGroup
          KeyName:
            Ref: KeyName
          ImageId: ami-7a11e213
      InstanceSecurityGroup:
        Type: AWS::EC2::SecurityGroup
        Properties:
          GroupDescription: Enable SSH access via port 22
          SecurityGroupIngress:
          - IpProtocol: tcp
            FromPort: '22'
            ToPort: '22'
            CidrIp: 0.0.0.0/0
</code></pre>

<p>There are a myriad of these template samples <a href="https://aws.amazon.com/cloudformation/aws-cloudformation-templates/">here</a>.</p>

<p>I&rsquo;m not going to explain this in too much detail. Parameters define the parameters, and resources define all the AWS services which
we would like to configure. Here we can see, that we are creating an EC2 instance with a custom Security Group plus and already
existing security group. ImageId is the AMI which will be used for the EC2 instance. The InstanceSecurityGroup is only defining
some SSH access to the instance.</p>

<p>That is pretty much it. This can become bloated relatively quickly once, VPCs, ELBs, and ASGs come into play. And CloudFormation
templates can also contain simple logical switches, like, conditions, ref for variables, maps and other shenanigans.</p>

<p>For example consider this part in the above example:</p>

<pre><code class="language-yaml">      KeyName:
        Ref: KeyName
</code></pre>

<p>Here, we use the <code>KeyName</code> parameter as a Reference Value which will be interpolated to the real value, or the default one, as the
template gets processed.</p>

<h2 id="codedeploy">CodeDeploy</h2>

<p>If you haven&rsquo;t heard about CodeDeploy yet, please browse the relevant <a href="http://docs.aws.amazon.com/codedeploy/latest/userguide/welcome.html">Documentation</a>
or follow along for a &ldquo;quick&rdquo; description.</p>

<p>CodeDeploy just does what the name says. It deploys code. Any kind of code, as long as the deployment process is described in a
file called <code>appspec.yml</code>. It can be easy as coping a file to a specific location or incredibly complex with builds of various
kinds.</p>

<p>For a simple example look at this configuration:</p>

<pre><code class="language-yaml">    version: 0.0
    os: linux
    files:
      - source: /index.html
        destination: /var/www/html/
      - source: /healthy.html
        destination: /var/www/html/
    hooks:
      BeforeInstall:
        - location: scripts/install_dependencies
          timeout: 300
          runas: root
        - location: scripts/clean_up
          timeout: 300
          runas: root
        - location: scripts/start_server
          timeout: 300
          runas: root
      ApplicationStop:
        - location: scripts/stop_server
          timeout: 300
          runas: root
</code></pre>

<p>CodeDeploy applications have hooks and life-cycle events which can be used to control the deployment process of an like, starting
the WebServer; making sure files are in the right location; copying files, running configuration management software like puppet,
ansible or chef; etc, etc.</p>

<p>What can be done in an <code>appspec.yml</code> file is described here: <a href="http://docs.aws.amazon.com/codedeploy/latest/userguide/app-spec-ref.html">Appspec Reference Documentation</a>.</p>

<p>Deployment happens in one of two ways:</p>

<h3 id="github">GitHub</h3>

<p>If the preferred way to deploy the application is from GitHub a commit hash must be used to identify which &ldquo;version&rdquo; of the
application is to be deployed. For example:</p>

<pre><code class="language-go">    rev = &amp;codedeploy.RevisionLocation{
        GitHubLocation: &amp;codedeploy.GitHubLocation{
            CommitId:   aws.String(&quot;kajdf94j0f9k309klksjdfkj&quot;),
            Repository: aws.String(&quot;Skarlso/furnace-codedeploy-app&quot;),
        },
        RevisionType: aws.String(&quot;GitHub&quot;),
    }
</code></pre>

<p>Commit Id is the hash of the latest release and repository is the full account/repository pointing to the application.</p>

<h3 id="s3">S3</h3>

<p>The second way is to use an S3 bucket. The bucket will contain an archived version of the application with a given extension. I&rsquo;m
saying given extension, because it has to be specified like this (and can be either &lsquo;zip&rsquo;, or &lsquo;tar&rsquo; or &lsquo;tgz&rsquo;):</p>

<pre><code class="language-go">    rev = &amp;codedeploy.RevisionLocation{
        S3Location: &amp;codedeploy.S3Location{
            Bucket:     aws.String(&quot;my_codedeploy_bucket&quot;),
            BundleType: aws.String(&quot;zip&quot;),
            Key:        aws.String(&quot;my_awesome_app&quot;),
            Version:    aws.String(&quot;VersionId&quot;),
        },
        RevisionType: aws.String(&quot;S3&quot;),
    }
</code></pre>

<p>Here, we specify the bucket name, the extension, the name of the file and an optional version id, which can be ignored.</p>

<h3 id="deploying">Deploying</h3>

<p>So how does code deploy get either of the applications to our EC2 instances? It uses an agent which is running on all of the
instances that we create. In order to do this, the agent needs to be present on our instance. For linux this can be achieved with
the following UserData (UserData in CF is the equivalent of a bootsrap script):</p>

<pre><code class="language-bash">    &quot;UserData&quot; : {
        &quot;Fn::Base64&quot; : { &quot;Fn::Join&quot; : [ &quot;\n&quot;, [
            &quot;#!/bin/bash -v&quot;,
            &quot;sudo yum -y update&quot;,
            &quot;sudo yum -y install ruby wget&quot;,
            &quot;cd /home/ec2-user/&quot;,
            &quot;wget https://aws-codedeploy-eu-central-1.s3.amazonaws.com/latest/install&quot;,
            &quot;chmod +x ./install&quot;,
            &quot;sudo ./install auto&quot;,
            &quot;sudo service codedeploy-agent start&quot;,
        ] ] }
    }
</code></pre>

<p>A simple user data configuration in the CloudFormation template will make sure that every instance that we create will have the
CodeDeploy agent running and waiting for instructions. This agent is self updating. Which can cause some trouble if AWS releases a
broken agent. However unlikely, it can happen. Never the less, once installed, it&rsquo;s no longer a concern to be bothered with.</p>

<p>It communications on HTTPS port 443.</p>

<p>CodeDeploy identifies instances which need to be updated according to our preferences, by tagging the EC2 and Auto Scaling groups.
Tagging happens in the CloudFormation template through the AutoScalingGroup settings like this:</p>

<pre><code class="language-json">    &quot;Tags&quot; : [
        {
            &quot;Key&quot; : &quot;fu_stage&quot;,
            &quot;Value&quot; : { &quot;Ref&quot;: &quot;AWS::StackName&quot; },
            &quot;PropagateAtLaunch&quot; : true
        }
    ]
</code></pre>

<p>This will give the EC2 instance a tag called <code>fu_stage</code> with value equaling to the name of the stack. Once this is done, CodeDeploy
looks like this:</p>

<pre><code class="language-go">    params := &amp;codedeploy.CreateDeploymentInput{
        ApplicationName:               aws.String(appName),
        IgnoreApplicationStopFailures: aws.Bool(true),
        DeploymentGroupName:           aws.String(appName + &quot;DeploymentGroup&quot;),
        Revision:                      revisionLocation(),
        TargetInstances: &amp;codedeploy.TargetInstances{
            AutoScalingGroups: []*string{
                aws.String(&quot;AutoScalingGroupPhysicalID&quot;),
            },
            TagFilters: []*codedeploy.EC2TagFilter{
                {
                    Key:   aws.String(&quot;fu_stage&quot;),
                    Type:  aws.String(&quot;KEY_AND_VALUE&quot;),
                    Value: aws.String(config.STACKNAME),
                },
            },
        },
        UpdateOutdatedInstancesOnly: aws.Bool(false),
    }
</code></pre>

<p>CreateDeploymentInput is the entire parameter list that is needed in order to identify instances to deploy code to. We can see
here that it looks for an AutoScalingGroup by Physical Id and the tag labeled <code>fu_stage</code>. Once found, it will use
<code>UpdateOutdatedInstancesOnly</code> to determine if an instance needs to be updated or not. Set to false means, it always updates.</p>

<h1 id="furnace">Furnace</h1>

<p>Where does <a href="https://github.com/Skarlso/go-furnace">Furnace</a> fit in, in all of this? Furnace provides a very easy mechanism to create,
delete and push code to a CloudFormation stack using CodeDeploy, and a couple of environment properties. Furnace <code>create</code> will
create a CloudFormation stack according to the provided template, all the while asking for the parameters defined in it for
flexibility. <code>delete</code> will remove the stack and all affiliated resources except for the created CodeDeploy application. For that,
there is <code>delete-application</code>. <code>status</code> will display information about the stack: Outputs, Parameters, Id, Name, and status.
Something like this:</p>

<pre><code class="language-bash">    2017/03/16 21:14:37 Stack state is:  {
      Capabilities: [&quot;CAPABILITY_IAM&quot;],
      CreationTime: 2017-03-16 20:09:38.036 +0000 UTC,
      DisableRollback: false,
      Outputs: [{
          Description: &quot;URL of the website&quot;,
          OutputKey: &quot;URL&quot;,
          OutputValue: &quot;http://FurnaceSt-ElasticL-ID.eu-central-1.elb.amazonaws.com&quot;
        }],
      Parameters: [
        {
          ParameterKey: &quot;KeyName&quot;,
          ParameterValue: &quot;UserKeyPair&quot;
        },
        {
          ParameterKey: &quot;SSHLocation&quot;,
          ParameterValue: &quot;0.0.0.0/0&quot;
        },
        {
          ParameterKey: &quot;CodeDeployBucket&quot;,
          ParameterValue: &quot;None&quot;
        },
        {
          ParameterKey: &quot;InstanceType&quot;,
          ParameterValue: &quot;t2.nano&quot;
        }
      ],
      StackId: &quot;arn:aws:cloudformation:eu-central-1:9999999999999:stack/FurnaceStack/asdfadsf-adsfa3-432d-a-fdasdf&quot;,
      StackName: &quot;FurnaceStack&quot;,
      StackStatus: &quot;CREATE_COMPLETE&quot;
    }
</code></pre>

<p>( This will later be improved to include created resources as well. )</p>

<p>Once the stack is <code>CREATE_COMPLETE</code> a simple <code>push</code> will deliver our application on each instance in the stack. We will get into
more detail about how these commands are working in Part 2 of this series.</p>

<h1 id="final-words">Final Words</h1>

<p>This is it for now.</p>

<p>Join me next time when I will talk about the AWS Go SDK and its intricacies and we will start to look at the basics of Furnace.</p>

<p>As always,
Thanks for reading!
Gergely.</p>

                    </div>
                </section>
                
                <h1 class="content-subhead">17 Apr 2016, 00:00</h1>
                <section class="post">
                    <header class="post-header">

                        <a href="https://skarlso.github.io/2016/04/17/minecraft-server-aws-s3-backup-part2/" class="post-title">Minecraft world automatic backup to AWS S3 bucket - Part 2 (Custom functions)</a>

                        <p class="post-meta">
                            
                                By <strong class="post-author">hannibal</strong>
                            
                            
                                under 
                                
                                <a class="post-category post-category-Minecraft" href="https://skarlso.github.io//categories/minecraft">Minecraft</a><a class="post-category post-category-AWS" href="https://skarlso.github.io//categories/aws">AWS</a><a class="post-category post-category-Bash" href="https://skarlso.github.io//categories/bash">Bash</a>
                            
                        </p>
                    </header>

                    <div class="post-description">
                        <p>Hi folks.</p>

<p>Got an update for the backup script. This time, you&rsquo;ll have the ability to implement your own upload capabilities. I provide a mock implementation for the required functions.</p>

<p>Here is the script again, now modified and a bit cleaned up. I hope it&rsquo;s helpful.</p>

<p></p>

<pre><code class="language-bash">#!/bin/bash

if [[ -t 1 ]]; then
    colors=$(tput colors)
    if [[ $colors ]]; then
        RED='\033[0;31m'
        LIGHT_GREEN='\033[1;32m'
        NC='\033[0m'
    fi
fi

if [[ -z ${MINECRAFT_BUCKET} ]]; then
    printf &quot;Please set the env variable %bMINECRAFT_BUCKET%b to the s3 archive bucket name.\n&quot; &quot;${RED}&quot; &quot;${NC}&quot;
    exit 1
fi

if [[ -z ${MINECRAFT_ARCHIVE_LIMIT} ]]; then
    printf &quot;Please set the env variable %bMINECRAFT_ARCHIVE_LIMIT%b to limit the number of archives to keep.\n&quot; &quot;${RED}&quot; &quot;${NC}&quot;
    exit 1
fi

if [[ -z ${MINECRAFT_WORLD} ]]; then
    printf &quot;Please set the env variable %bMINECRAFT_WORLD%b to specify what world to back-up.\n&quot; &quot;${RED}&quot; &quot;${NC}&quot;
    exit 1
fi

backup_world=${MINECRAFT_WORLD}
backup_bucket=${MINECRAFT_BUCKET}
backup_limit=${MINECRAFT_ARCHIVE_LIMIT}
archive_name=&quot;${backup_world}-$(date +&quot;%H-%M-%S-%m-%d-%Y&quot;).zip&quot;

function create_archive {
    printf &quot;Creating archive of %b${backup_world}%b\n&quot; &quot;${RED}&quot; &quot;${NC}&quot;
    zip -r $archive_name $backup_world
}

function amazon_bak {

    create_archive

    printf &quot;Checking if bucket has more than %b${backup_limit}%b files already.\n&quot; &quot;${RED}&quot; &quot;${NC}&quot;
    content=( $(aws s3 ls s3://$backup_bucket | awk '{print $4}') )

    if [[ ${#content[@]} -eq $backup_limit || ${#content[@]} -gt $backup_limit  ]]; then
        echo &quot;There are too many archives. Deleting oldest one.&quot;
        # We can assume here that the list is in cronological order
    	printf &quot;%bs3://${backup_bucket}/${content[0]}\n%b&quot; &quot;${RED}&quot; &quot;${NC}&quot;
        aws s3 rm s3://$backup_bucket/${content[0]}
    fi

    printf &quot;Uploading %b${archive_name}%b to s3 archive bucket.\n&quot; &quot;${RED}&quot; &quot;${NC}&quot;
    state=$(aws s3 cp $archive_name s3://$backup_bucket)

    if [[ &quot;$state&quot; =~ &quot;upload:&quot; ]]; then
        printf &quot;File upload %bsuccessful%b.\n&quot; &quot;${LIGHT_GREEN}&quot; &quot;${NC}&quot;
    else
        printf &quot;%bError%b occured while uploading archive. Please investigate.\n&quot; &quot;${RED}&quot; &quot;${NC}&quot;
    fi
}

function custom {
    if [[ -e custom.sh ]]; then
        source ./custom.sh
    else
        echo &quot;custom.sh script not found. Please implement the apropriate functions.&quot;
        exit 1
    fi

    echo &quot;Checking for the number of files. Limit is: $backup_limit.&quot;
    files=( $(list) )
    if [[ ${#files[@]} -eq $backup_limit || ${#files[@]} -gt $backup_limit ]]; then
        echo &quot;Deleting extra file.&quot;
        delete ${files[0]}
        if [[ $? != 0 ]]; then
            printf &quot;%bFailed%b to delete file. Please investigate failure.&quot; &quot;${RED}&quot; &quot;${NC}&quot;
            exit $?
        fi
    fi

    echo &quot;Zipping world.&quot;
    create_archive

    echo &quot;Uploading world.&quot;
    upload $archive_name

    if [[ $? != 0 ]]; then
        printf &quot;%bFailed%b to upload archive. Please investigate the error.&quot; &quot;${RED}&quot; &quot;${NC}&quot;
        exit $?
    fi

    printf &quot;Upload %bsuccessful%b&quot; &quot;${LIGHT_GREEN}&quot; &quot;${NC}&quot;
}

function help {
    echo &quot;Usage:&quot;
    echo &quot;./backup_world [METHOD]&quot;
    echo &quot;Exp.: ./backup_world aws|./backup_world custom|./backup_world dropbox&quot;
    echo &quot;Each method has it's own environment properties that it requires.&quot;
    echo &quot;Global: MINECRAFT_WORLD|MINECRAFT_BUCKET|MINECRAFT_ARCHIVE_LIMIT&quot;
    echo &quot;Custom: Have a file, called 'custom.sh' which is sourced.&quot;
    echo &quot;Implement these three functions: upload | list | delete.&quot;
    echo &quot;upload -&gt; should return exit code 0 on success, should return exit code 1 on failure.&quot;
    echo &quot;list -&gt; should return a list of cronologically ordered items.&quot;
    echo &quot;delete -&gt; should return exit code 0 on success, should return exit code 1 on failure.&quot;
}

case $1 in
    aws )
        amazon_bak
        ;;
    custom )
        custom
        ;;
    * )
        help
        ;;
esac
</code></pre>

<p>And here is the sample implementation for the custom upload functionality.</p>

<pre><code class="language-bash">#!/bin/bash

function upload {
    echo &quot;uploading&quot;
    local result=0
    return $result
}

function delete {
    echo &quot;deleting $1&quot;
    local result=0
    return $result
}

function list {
    local arr=(&quot;file1&quot; &quot;file2&quot; &quot;file3&quot;)
    echo &quot;${arr[@]}&quot;
}
</code></pre>

<p>Thanks for reading!</p>

<p>Gergely.</p>
                    </div>
                </section>
                
                <h1 class="content-subhead">16 Apr 2016, 00:00</h1>
                <section class="post">
                    <header class="post-header">

                        <a href="https://skarlso.github.io/2016/04/16/minecraft-server-aws-s3-backup/" class="post-title">Minecraft world automatic backup to AWS S3 bucket</a>

                        <p class="post-meta">
                            
                                By <strong class="post-author">hannibal</strong>
                            
                            
                                under 
                                
                                <a class="post-category post-category-Minecraft" href="https://skarlso.github.io//categories/minecraft">Minecraft</a><a class="post-category post-category-AWS" href="https://skarlso.github.io//categories/aws">AWS</a><a class="post-category post-category-Bash" href="https://skarlso.github.io//categories/bash">Bash</a>
                            
                        </p>
                    </header>

                    <div class="post-description">
                        <p>Hi Folks.</p>

<p>Previously we created a Minecraft server using Docker. After my server got popular in the family, and a lot of stuff started to pile up on it, as a good IT person, I&rsquo;m backing up the world once in a while.</p>

<p>For that, I&rsquo;m using AWS S3 with the CLI and a little bash script which runs once a week.</p>

<p>The script is really straightforward. I&rsquo;m doing manual versioning, although S3 does provide one out of the box. However, amazon&rsquo;s S3 versioning doesn&rsquo;t allow limiting the number of versions being kept. And since I&rsquo;m doing that anyways, might as well take care of the rest.</p>

<p>Without further ado, here is the script:</p>

<pre><code class="language-bash">#!/bin/bash

if [[ -t 1 ]]; then
    colors=$(tput colors)
    if [[ $colors ]]; then
        RED='\033[0;31m'
        LIGHT_GREEN='\033[1;32m'
        NC='\033[0m'
    fi
fi

if [[ -z ${MINECRAFT_BUCKET} ]]; then
	printf &quot;Please set the env variable ${RED}MINECRAFT_BUCKET${NC} to the s3 archive bucket name.\n&quot;
	exit 0
fi

if [[ -z ${MINECRAFT_ARCHIVE_LIMIT} ]]; then
	printf &quot;Please set the env variable ${RED}MINECRAFT_ARCHIVE_LIMIT${NC} to limit the number of archives to keep.\n&quot;
	exit 0
fi

backup_bucket=${MINECRAFT_BUCKET}
backup_limit=${MINECRAFT_ARCHIVE_LIMIT}
world=$1
printf &quot;Creating archive of ${RED}${world}${NC}\n&quot;
archive_name=&quot;${world}-$(date +&quot;%H-%M-%S-%m-%d-%Y&quot;).zip&quot;
zip -r $archive_name $world

printf &quot;Checking if bucket has more than ${RED}${backup_limit}${NC} files already.\n&quot;
content=( $(aws s3 ls s3://$backup_bucket | awk '{print $4}') )

if [[ ${#content[@]} -eq $backup_limit || ${#content[@]} -gt $backup_limit  ]]; then
    echo &quot;There are too many archives. Deleting oldest one.&quot;
    # We can assume here that the list is in cronological order
	printf &quot;${RED}s3://${backup_bucket}/${content[0]}\n&quot;
    aws s3 rm s3://$backup_bucket/${content[0]}
fi

printf &quot;Uploading ${RED}${archive_name}${NC} to s3 archive bucket.\n&quot;
state=$(aws s3 cp $archive_name s3://$backup_bucket)

if [[ &quot;$state&quot; =~ &quot;upload:&quot; ]]; then
    printf &quot;File upload ${LIGHT_GREEN}successful${NC}.\n&quot;
else
    printf &quot;${RED}Error${NC} occured while uploading archive. Please investigate.\n&quot;
fi
</code></pre>

<p>It uses environment properties to define where to upload the given world and how many versions to keep.</p>

<p>I&rsquo;m calling this from a cron job, and it&rsquo;s sitting next to where the Minecraft world is.</p>

<p>That&rsquo;s it folks.</p>

<p>I&rsquo;ll start expanding on this idea and implement various services, like your own server address, or dropbox, or what have you.</p>

<p>Happy backing up.</p>

<p>Gergely.</p>

                    </div>
                </section>
                
            </div>
            

            <div class="footer">
    <div class="pure-menu pure-menu-horizontal pure-menu-open">
        <ul>
            <li>Powered by <a class="hugo" href="https://gohugo.io/" target="_blank">hugo</a></li>
        </ul>
    </div>
</div>
<script src="https://skarlso.github.io//js/all.min.js"></script>

        </div>
    </div>
</div>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-69463020-2', 'auto');
ga('send', 'pageview');

</script>

</body>
</html>
