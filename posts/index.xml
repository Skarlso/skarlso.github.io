<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
	<channel>
		<title>Posts on Ramblings of a cloud engineer</title>
		<link>https://skarlso.github.io/posts/</link>
		<description>Recent content in Posts on Ramblings of a cloud engineer</description>
		<generator>Hugo -- gohugo.io</generator>
		<language>en-us</language>
		<lastBuildDate>Thu, 15 Mar 2018 23:01:00 +0100</lastBuildDate>
		<atom:link href="https://skarlso.github.io/posts/index.xml" rel="self" type="application/rss+xml" />
		
		<item>
			<title>Kubernetes distributed application deployment with sample Face Recognition App</title>
			<link>https://skarlso.github.io/2018/03/15/kubernetes-distributed-application/</link>
			<pubDate>Thu, 15 Mar 2018 23:01:00 +0100</pubDate>
			
			<guid>https://skarlso.github.io/2018/03/15/kubernetes-distributed-application/</guid>
			<description>Intro Alright folks. Settle in and get comfortable. This is going to be a long, but hopefully, fun ride.
I&amp;rsquo;m going to deploy a distributed application with Kubernetes. I attempted to create an application that I thought resembled a real world app. Obviously I had to cut some corners due to time and energy constraints.
My focus will be on Kubernetes and deployment.
Shall we delve right in?
The Application TL;DR The application itself consists of six parts.</description>
			<content type="html"><![CDATA[

<h1 id="intro">Intro</h1>

<p>Alright folks. Settle in and get comfortable. This is going to be a long, but hopefully, fun ride.</p>

<p>I&rsquo;m going to deploy a distributed application with <a href="https://kubernetes.io/">Kubernetes</a>. I attempted to create an application that I thought resembled a real world app. Obviously I had to cut some corners due to time and energy constraints.</p>

<p>My focus will be on Kubernetes and deployment.</p>

<p>Shall we delve right in?</p>

<h1 id="the-application">The Application</h1>

<h2 id="tl-dr">TL;DR</h2>

<p><img src="/img/kube_overview.png" alt="kube overview" /></p>

<p>The application itself consists of six parts. The repository can be found here: <a href="https://github.com/Skarlso/kube-cluster-sample">Kube Cluster Sample</a>.</p>

<p>It’s a face recognition service which identifies images of people, comparing them to known individuals. A simple frontend displays a table of these images whom they belong to. This happens by sending a request to a <a href="https://github.com/Skarlso/kube-cluster-sample/tree/master/receiver">receiver</a>. The request contains a path to an image. This image can sit on an NFS somewhere. The receiver stores this path in the DB (MySQL) and sends a processing request to a queue. The queue uses: <a href="http://nsq.io/">NSQ</a>. The request contains the ID of the saved image.</p>

<p>An <a href="https://github.com/Skarlso/kube-cluster-sample/tree/master/image_processor">Image Processing</a> service is constantly monitoring the queue for jobs to do. The processing consists of the following steps: taking the ID; loading the image; and finally,  sending the image to a <a href="https://github.com/Skarlso/kube-cluster-sample/tree/master/face_recognition">face recognition</a> backend written in Python via <a href="https://grpc.io/">gRPC</a>. If the identification is successful, the backend will return the name of the image corresponding to that person. The image_processor then updates the image’s record with the person’s ID and marks the image as “processed successfully”. If identification is unsuccessful, the image will be left as “pending”. If there was a failure during identification, the image will be flagged as “failed”.</p>

<p>Failed images can be retried  with a cron job, for example:</p>

<p>So how does this all work? Let&rsquo;s check it out .</p>

<h2 id="receiver">Receiver</h2>

<p>The receiver service is the starting point of the process. It&rsquo;s an API which receives a request in the following format:</p>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash">curl -d <span class="s1">&#39;{&#34;path&#34;:&#34;/unknown_images/unknown0001.jpg&#34;}&#39;</span> http://127.0.0.1:8000/image/post</code></pre></div>
<p>In this instance, the receiver stores the path using a shared database cluster. The entity will then receive an ID from the database service. This application is based on the model where unique identification for Entity Objects is provided by the persistence layer. Once the ID is procured, the receiver will send a message to NSQ. At this point in the process, the receiver&rsquo;s job is done.</p>

<h2 id="image-processor">Image Processor</h2>

<p>Here is where the excitement begins. When Image Processor first runs it creates two Go routines. These are&hellip;</p>

<h3 id="consume">Consume</h3>

<p>This is an NSQ consumer. It has three integral jobs. Firstly, it listens for messages on the queue. Secondly, when there is a message, it appends the received ID to a thread safe slice of IDs that the second routine processes. And lastly, it signals the second routine that there is work to be do. It does this through <a href="https://golang.org/pkg/sync/#Cond">sync.Condition</a>.</p>

<h3 id="processimages">ProcessImages</h3>

<p>This routine processes a slice of IDs until the slice is drained completely. Once the slice is drained, the routine suspends instead of sleep-waiting on a channel. The processing of a single ID can be seen in the following linear steps:</p>

<ul>
<li>Establish a gRPC connection to the Face Recognition service (explained under Face Recognition)</li>
<li>Retrieve the image record from the database</li>
<li>Setup two functions for the <a href="#circuit-breaker">Circuit Breaker</a>

<ul>
<li>Function 1: The main function which runs  the RPC method call</li>
<li>Function 2: A health check for the Ping of the circuit breaker</li>
</ul></li>
<li>Call Function 1 which sends the path of the image to the face recognition service. This path should be accessible by the face recognition service. Preferably something shared like an NFS</li>
<li>If this call fails, update the image record as FAILED PROCESSING</li>
<li>If it succeeds, an image name should come back which corresponds to a person in the db. It runs a joined SQL query which gets the corresponding person&rsquo;s ID</li>
<li>Update the Image record in the database with PROCESSED status and the ID of the person that image was identified as</li>
</ul>

<p>This service can be replicated. In other words, more than one can run at the same time.</p>

<h3 id="circuit-breaker">Circuit Breaker</h3>

<p>A  system in which replicating resources requires little to no effort, there still can be cases where, for example, the network goes down, or there are communication problems of any kind between two services. I like to implement a little circuit breaker around the gRPC calls for fun.</p>

<p>This is how it works:</p>

<p><img src="/img/kube_circuit1.png" alt="kube circuit" /></p>

<p>As you can see, once there are 5 unsuccessful calls to the service, the circuit breaker activates, not allowing any more calls to go through. After a configured amount of time, it will send a Ping call to the service to see if it&rsquo;s back up. If that still errors out, it will increase the timeout. If not, it opens the circuit, allowing traffic to proceed.</p>

<h2 id="front-end">Front-End</h2>

<p>This is only a simple table view with Go&rsquo;s own html/template used to render a list of images.</p>

<h2 id="face-recognition">Face Recognition</h2>

<p>Here is where the identification magic happens. I decided to make this a gRPC based service for the  sole purpose of its flexibility. I started writing it in Go but decided that a Python implementation would be much sorter. In fact, excluding the gRPC code, the recognition part is approximately 7 lines of Python code. I&rsquo;m using this fantastic library which contains all the C bindings to OpenCV. <a href="https://github.com/ageitgey/face_recognition">Face Recognition</a>. Having an API contract here means that I can change the implementation anytime as long as it adheres to the contract.</p>

<p>Please note that there exist a great Go library OpenCV. I was about to use it but they had yet to write the C bindings for that part of OpenCV. It&rsquo;s called <a href="https://gocv.io/">GoCV</a>. Check them out! They have some pretty amazing things, like real-time camera feed processing that only needs a couple of lines of code.</p>

<p>The python library is simple in nature. Have a set of images of people you know. I have a folder with a couple of images named, <code>hannibal_1.jpg, hannibal_2.jpg, gergely_1.jpg, john_doe.jpg</code>. In the database I have two tables named, <code>person, person_images</code>. They look like this:</p>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash">+----+----------+
<span class="p">|</span> id <span class="p">|</span> name     <span class="p">|</span>
+----+----------+
<span class="p">|</span>  <span class="m">1</span> <span class="p">|</span> Gergely  <span class="p">|</span>
<span class="p">|</span>  <span class="m">2</span> <span class="p">|</span> John Doe <span class="p">|</span>
<span class="p">|</span>  <span class="m">3</span> <span class="p">|</span> Hannibal <span class="p">|</span>
+----+----------+
+----+----------------+-----------+
<span class="p">|</span> id <span class="p">|</span> image_name     <span class="p">|</span> person_id <span class="p">|</span>
+----+----------------+-----------+
<span class="p">|</span>  <span class="m">1</span> <span class="p">|</span> hannibal_1.jpg <span class="p">|</span>         <span class="m">3</span> <span class="p">|</span>
<span class="p">|</span>  <span class="m">2</span> <span class="p">|</span> hannibal_2.jpg <span class="p">|</span>         <span class="m">3</span> <span class="p">|</span>
+----+----------------+-----------+</code></pre></div>
<p>The face recognition library returns the name of the image from the known people which matches the person on the unknown image. After that, a simple joined query -like this- will return the person in question.</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">select</span> <span class="n">person</span><span class="p">.</span><span class="n">name</span><span class="p">,</span> <span class="n">person</span><span class="p">.</span><span class="n">id</span> <span class="k">from</span> <span class="n">person</span> <span class="k">inner</span> <span class="k">join</span> <span class="n">person_images</span> <span class="k">as</span> <span class="n">pi</span> <span class="k">on</span> <span class="n">person</span><span class="p">.</span><span class="n">id</span> <span class="o">=</span> <span class="n">pi</span><span class="p">.</span><span class="n">person_id</span> <span class="k">where</span> <span class="n">image_name</span> <span class="o">=</span> <span class="s1">&#39;hannibal_2.jpg&#39;</span><span class="p">;</span></code></pre></div>
<p>The gRPC call returns the ID of the person which is then used to update the image&rsquo;s ‘person` column.</p>

<h2 id="nsq">NSQ</h2>

<p>NSQ is a nice little Go based queue. It can be scaled and has a minimal footprint on the system. It also has a lookup service that consumers use to receive messages, and a daemon that senders use when sending messages.</p>

<p>NSQ&rsquo;s philosophy is that the daemon should run with the sender application. That way, the sender will send to the localhost only. But the daemon is connected to the lookup service, and that&rsquo;s how they achieve a global queue.</p>

<p>This means that there are as many NSQ daemons deployed as there are senders. Because the daemon has a minuscule resource requirement, it won&rsquo;t interfere with the requirements of the main application.</p>

<h2 id="configuration">Configuration</h2>

<p>In order to be as flexible as possible, as well as making use of Kubernetes&rsquo;s ConfigSet, I&rsquo;m using .env files in development to store configurations like the location of the database service, or NSQ&rsquo;s lookup address. In production- and that means the Kubernetes’s environment- I&rsquo;ll use environment properties.</p>

<h2 id="conclusion-for-the-application">Conclusion for the Application</h2>

<p>And that&rsquo;s all there is to the architecture of the application we are about to deploy. All of its components are changeable and coupled only through the database, a queue and gRPC. This is imperative when deploying a distributed application due to how updating mechanics work. I will cover that part in the Deployment section.</p>

<h1 id="deployment-with-kubernetes">Deployment with Kubernetes</h1>

<h2 id="basics">Basics</h2>

<p>What <strong>is</strong> Kubernetes?</p>

<p>I&rsquo;m going to cover some of the basics here. I won&rsquo;t go too much into detail-  that would require a whole book like this one: <a href="http://shop.oreilly.com/product/0636920043874.do">Kubernetes Up And Running</a>. Also, if you’re daring enough, you can have a look through this documentation: <a href="https://kubernetes.io/docs/">Kubernetes Documentation</a>.</p>

<p>Kubernetes is a containerized service and application manager. It scales easily, employs a swarm of containers, and most importantly, it&rsquo;s highly configurable via yaml based template files. People often compare Kubernetes to Docker swarm, but Kubernetes does way more than that! For example: it&rsquo;s container agnostic. You could use LXC with Kubernetes and it would work the same way as you using it with Docker. It provides a layer above managing a cluster of deployed services and applications. How? Let&rsquo;s take a quick look at the building blocks of Kubernetes.</p>

<p>In Kubernetes, you’ll describe a desired state of the application and Kubernetes will do what it can to reach that state. States could be something such as deployed; paused; replicated twice; and so on and so forth.</p>

<p>One of the basics of Kubernetes is that it uses Labels and Annotations for all of its components. Services, Deployments, ReplicaSets, DaemonSets, everything is labelled. Consider the following scenario. In order to identify what pod belongs to what application, a label is used called <code>app: myapp</code>. Let’s assume you have two containers of this application deployed; if you would remove the label <code>app</code> from one of the containers, Kubernetes would only detect one and thus would launch a new instance of <code>myapp</code>.</p>

<h3 id="kubernetes-cluster">Kubernetes Cluster</h3>

<p>For Kuberenetes to work, a Kubernetes cluster needs to be present. Setting that up might be a tad painful, but luckily, help is on hand. Minikube sets up a cluster for us locally with one Node. And AWS has a beta service running in the form of a Kubernetes cluster in which the only thing you need to do is request nodes and define your deployments. The Kubernetes cluster components are documented here: <a href="https://kubernetes.io/docs/concepts/overview/components/">Kubernetes Cluster Components</a>.</p>

<h3 id="nodes">Nodes</h3>

<p>A Node is a worker machine. It can be anything- from a vm to a physical machine- including all sorts of cloud provided vms.</p>

<h3 id="pods">Pods</h3>

<p>Pods are a logically grouped collection of containers, meaning one Pod can potentially house a multitude of containers. A Pod gets its own DNS and virtual IP address after it has been created so Kubernetes can load balancer traffic to it. You rarely need to deal with containers directly. Even when debugging, (like looking at logs), you usually invoke <code>kubectl logs deployment/your-app -f</code> instead of looking at a specific container. Although it is possible with <code>-c container_name</code>. The <code>-f</code> does a tail on the log.</p>

<h3 id="deployments">Deployments</h3>

<p>When creating any kind of resource in Kubernetes, it will use a Deployment in the background. A deployment describes a desired state of the current application. It&rsquo;s an object you can use to update Pods or a Service to be in a different state, do an update, or rollout new version of your app. You don&rsquo;t directly control a ReplicaSet, (as described later), but control the deployment object which creates and manages a ReplicaSet.</p>

<h3 id="services">Services</h3>

<p>By default a Pod will get an IP address. However, since Pods are a volatile thing in Kubernetes, you&rsquo;ll need something more permanent. A queue, mysql, or an internal API, a frontend; these need to be long running and behind a static, unchanging IP or preferably a DNS record.</p>

<p>For this purpose, Kubernetes has Services for which you can define modes of accessibility. Load Balanced, simple IP or internal DNS.</p>

<p>How does Kubernetes know if a service is running correctly? You can configure Health Checks and Availability Checks. A Health Check will check whether a container is running, but that doesn&rsquo;t mean that your service is running. For that, you have the availability check which pings a different endpoint in your application.</p>

<p>Since Services are pretty important, I recommend that you read up on them later here: <a href="https://kubernetes.io/docs/concepts/services-networking/service/">Services</a>. Advanced  warning though, this document is quite dense. Twenty four A4 pages of networking, services and discovery. It&rsquo;s also vital to decide whether you want to seriously employ Kubernetes in production.</p>

<h3 id="dns-service-discovery">DNS / Service Discovery</h3>

<p>If you create a service in the cluster, that service will get a DNS record in Kubernetes provided by special Kubernetes deployments called kube-proxy and kube-dns. These two provide service discover inside a cluster. If you have a mysql service running and set <code>clusterIP: none</code>, then everyone in the cluster can reach that service by pinging <code>mysql.default.svc.cluster.local</code>. Where:</p>

<ul>
<li><code>mysql</code> &ndash; is the name of the service</li>
<li><code>default</code> &ndash; is the namespace name</li>
<li><code>svc</code> &ndash; is services</li>
<li><code>cluster.local</code> &ndash; is a local cluster domain</li>
</ul>

<p>The domain can be changed via a custom definition. To access a service outside the cluster, a DNS provider has to be used, and Nginx (for example), to bind an IP address to a record. The public IP address of a service can be queried with the following commands:</p>

<ul>
<li>NodePort &ndash; <code>kubectl get -o jsonpath=&quot;{.spec.ports[0].nodePort}&quot; services mysql</code></li>
<li>LoadBalancer &ndash; <code>kubectl get -o jsonpath=&quot;{.spec.ports[0].LoadBalancer}&quot; services mysql</code></li>
</ul>

<h3 id="template-files">Template Files</h3>

<p>Like Docker Compose, TerraForm or other service management tools, Kubernetes also provides infrastructure describing templates. What that means is that you rarely need  to do anything by hand.</p>

<p>For example, consider the following yaml template which describes an nginx Deployment:</p>
<div class="highlight"><pre class="chroma"><code class="language-yaml" data-lang="yaml">apiVersion<span class="p">:</span><span class="w"> </span>apps/v1<span class="w">
</span><span class="w"></span>kind<span class="p">:</span><span class="w"> </span>Deployment<span class="w"> </span><span class="c">#(1)</span><span class="w">
</span><span class="w"></span>metadata<span class="p">:</span><span class="w"> </span><span class="c">#(2)</span><span class="w">
</span><span class="w">  </span>name<span class="p">:</span><span class="w"> </span>nginx-deployment<span class="w">
</span><span class="w">  </span>labels<span class="p">:</span><span class="w"> </span><span class="c">#(3)</span><span class="w">
</span><span class="w">    </span>app<span class="p">:</span><span class="w"> </span>nginx<span class="w">
</span><span class="w"></span>spec<span class="p">:</span><span class="w"> </span><span class="c">#(4)</span><span class="w">
</span><span class="w">  </span>replicas<span class="p">:</span><span class="w"> </span><span class="m">3</span><span class="w"> </span><span class="c">#(5)</span><span class="w">
</span><span class="w">  </span>selector<span class="p">:</span><span class="w">
</span><span class="w">    </span>matchLabels<span class="p">:</span><span class="w">
</span><span class="w">      </span>app<span class="p">:</span><span class="w"> </span>nginx<span class="w">
</span><span class="w">  </span>template<span class="p">:</span><span class="w">
</span><span class="w">    </span>metadata<span class="p">:</span><span class="w">
</span><span class="w">      </span>labels<span class="p">:</span><span class="w">
</span><span class="w">        </span>app<span class="p">:</span><span class="w"> </span>nginx<span class="w">
</span><span class="w">    </span>spec<span class="p">:</span><span class="w">
</span><span class="w">      </span>containers<span class="p">:</span><span class="w"> </span><span class="c">#(6)</span><span class="w">
</span><span class="w">      </span>-<span class="w"> </span>name<span class="p">:</span><span class="w"> </span>nginx<span class="w">
</span><span class="w">        </span>image<span class="p">:</span><span class="w"> </span>nginx<span class="p">:</span><span class="m">1.7</span>.<span class="m">9</span><span class="w">
</span><span class="w">        </span>ports<span class="p">:</span><span class="w">
</span><span class="w">        </span>-<span class="w"> </span>containerPort<span class="p">:</span><span class="w"> </span><span class="m">80</span></code></pre></div>
<p>This is a simple deployment in which we do the following:</p>

<ul>
<li>(1) Define the type of the template with kind</li>
<li>(2) Add metadata that will identify this deployment and every resource that it would create with a label (3)</li>
<li>(4) Then comes the spec which describes the desired state

<ul>
<li>(5) For the nginx app, have 3 replicas</li>
<li>(6) This is the template definition for the containers that this Pod will contain</li>
<li>nginx named container</li>
<li>nginx:1.7.9 image (docker in this case)</li>
<li>exposed ports</li>
</ul></li>
</ul>

<h3 id="replicaset">ReplicaSet</h3>

<p>A ReplicaSet is a low level replication manager. It ensures that the correct number of replicates are running for a application. However, Deployments are at a higher level and should always manage ReplicaSets. You rarely need to use ReplicaSets directly unless you have a fringe case in which you want to control the specifics of replication.</p>

<h3 id="daemonset">DaemonSet</h3>

<p>Remember how I said Kubernetes is using Labels all the time? A DaemonSet is a controller that ensures that at daemonized application is always running on a node with a certain label.</p>

<p>For example: you want all the nodes labelled with <code>logger</code> or <code>mission_critical</code> to run an logger / auditing service daemon. Then you create a DaemonSet and give it a node selector called <code>logger</code> or <code>mission_critical</code>. Kubernetes will look for a node that has that label. Always ensure that it will have an instance of that daemon running on it. Thus everyone running on that node will have access to that daemon locally.</p>

<p>In case of my application, the NSQ daemon could be a DaemonSet. Make sure it&rsquo;s up on a node which has the receiver component running by labelling a node with <code>receiver</code> and specifying a DaemonSet with a <code>receiver</code> application selector.</p>

<p>The DaemonSet has all the benefits of the ReplicaSet. It&rsquo;s scalable and Kubernetes manages it; which means, all life cycle events are handled by Kube ensuring it never dies, and when it does,  it will be immediately replaced.</p>

<h3 id="scaling">Scaling</h3>

<p>It&rsquo;s trivial to scale in Kubernetes. The ReplicaSets take care of the number of instances of a Pod to run- as seen in the nginx deployment with the setting <code>replicas:3</code>. It&rsquo;s up to us to write our application in a way that allows Kubernetes to run multiple copies of it.</p>

<p>Of course the settings are vast. You can specify which replicates must run on what Nodes, or on various waiting times as to how long to wait for an instance to come up. You can read more on this subject here: <a href="https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/">Horizontal Scaling</a> and here: <a href="https://kubernetes.io/docs/tutorials/kubernetes-basics/scale-interactive/">Interactive Scaling with Kubernetes</a> and of course the details of a <a href="https://kubernetes.io/docs/concepts/workloads/controllers/replicaset/">ReplicaSet</a> which controls all the scaling made possible in Kubernetes.</p>

<h3 id="conclusion-for-kubernetes">Conclusion for Kubernetes</h3>

<p>It&rsquo;s a convenient tool to handle container orchestration. Its unit of work are Pods and it has a layered architecture. The top level layer is Deployments through which you handle all other resources. It&rsquo;s highly configurable. It provides an API for all calls you make, so potentially, instead of running <code>kubectl</code> you can also write your own logic to send information to the Kubernetes API.</p>

<p>It provides support for all major cloud providers natively by now and it&rsquo;s completely open source. Feel free to contribute! And check the code if you would like to have a deeper understanding on how it works: <a href="https://github.com/kubernetes/kubernetes">Kubernetes on Github</a>.</p>

<h2 id="minikube">Minikube</h2>

<p>I&rsquo;m going to use <a href="https://github.com/kubernetes/minikube/">Minikube</a>. Minikube is a local Kubernetes cluster simulator. It&rsquo;s not great in simulating multiple nodes though, but for starting out and local play without any costs, it&rsquo;s great. It uses a VM that can be fine tuned if necessary using VirtualBox and the likes.</p>

<p>All of the kube template files that I&rsquo;ll be using can be found here: <a href="https://github.com/Skarlso/kube-cluster-sample/tree/master/kube_files">Kube files</a>.</p>

<p><strong>NOTE</strong> If, later on, you would like to play with scaling but notice that the replicates are always in <code>Pending</code> state, remember that minikube employs a single node only. It might not allow multiple replicas on the same node, or just plainly ran out of resources to use. You can check available resources with the following command:</p>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash">kubectl get nodes -o yaml</code></pre></div>
<h2 id="building-the-containers">Building the containers</h2>

<p>Kubernetes supports most of the containers out there. I&rsquo;m going to use Docker. For all the services I&rsquo;ve built, there is a Dockerfile included in the repository. I encourage you to study them. Most of them are simple. For the go services, I&rsquo;m using a multi stage build that has been  recently introduced. The Go services are Alpine Linux based. The Face Recognition service is Python. NSQ and MySQL are using their own containers.</p>

<h2 id="context">Context</h2>

<p>Kubernetes uses namespaces. If you don&rsquo;t specify any, it will use the <code>default</code> namespace. I&rsquo;m going to permanently set a context to avoid polluting the default namespace. You do that like this:</p>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash">❯ kubectl config set-context kube-face-cluster --namespace<span class="o">=</span>face
Context <span class="s2">&#34;kube-face-cluster&#34;</span> created.</code></pre></div>
<p>You have to also start using the context once it&rsquo;s created, like so:</p>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash">❯ kubectl config use-context kube-face-cluster
Switched to context <span class="s2">&#34;kube-face-cluster&#34;</span>.</code></pre></div>
<p>After this, all <code>kubectl</code> commands will use the namespace <code>face</code>.</p>

<h2 id="deploying-the-application">Deploying the Application</h2>

<p>Overview of Pods and Services:</p>

<p><img src="/img/kube_deployed.png" alt="kube deployed" /></p>

<h3 id="mysql">MySQL</h3>

<p>The first Service I&rsquo;m going to deploy is my database.</p>

<p>I&rsquo;m using the Kubernetes example located here <a href="https://kubernetes.io/docs/tasks/run-application/run-single-instance-stateful-application/#deploy-mysql">Kube MySQL</a> which fits my needs. Please note that this file is using a plain password for MYSQL_PASSWORD. I&rsquo;m going to employ a vault as described here <a href="https://kubernetes.io/docs/concepts/configuration/secret/">Kubernetes Secrets</a>.</p>

<p>I&rsquo;ve created a secret locally as described in that document using a secret yaml:</p>
<div class="highlight"><pre class="chroma"><code class="language-yaml" data-lang="yaml">apiVersion<span class="p">:</span><span class="w"> </span>v1<span class="w">
</span><span class="w"></span>kind<span class="p">:</span><span class="w"> </span>Secret<span class="w">
</span><span class="w"></span>metadata<span class="p">:</span><span class="w">
</span><span class="w">  </span>name<span class="p">:</span><span class="w"> </span>kube-face-secret<span class="w">
</span><span class="w"></span>type<span class="p">:</span><span class="w"> </span>Opaque<span class="w">
</span><span class="w"></span>data<span class="p">:</span><span class="w">
</span><span class="w">  </span>mysql_password<span class="p">:</span><span class="w"> </span>base64codehere</code></pre></div>
<p>I created the  base64 code via the following command:</p>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash"><span class="nb">echo</span> -n <span class="s2">&#34;ubersecurepassword&#34;</span> <span class="p">|</span> base64</code></pre></div>
<p>And, this is what you&rsquo;ll see in my deployment yaml file:</p>
<div class="highlight"><pre class="chroma"><code class="language-yaml" data-lang="yaml">...<span class="w">
</span><span class="w"></span>-<span class="w"> </span>name<span class="p">:</span><span class="w"> </span>MYSQL_ROOT_PASSWORD<span class="w">
</span><span class="w">  </span>valueFrom<span class="p">:</span><span class="w">
</span><span class="w">    </span>secretKeyRef<span class="p">:</span><span class="w">
</span><span class="w">      </span>name<span class="p">:</span><span class="w"> </span>kube-face-secret<span class="w">
</span><span class="w">      </span>key<span class="p">:</span><span class="w"> </span>mysql_password<span class="w">
</span><span class="w"></span>...</code></pre></div>
<p>Another thing worth mentioning: It&rsquo;s using a volume to persist the database. The volume definition is as follows:</p>
<div class="highlight"><pre class="chroma"><code class="language-yaml" data-lang="yaml">...<span class="w">
</span><span class="w">        </span>volumeMounts<span class="p">:</span><span class="w">
</span><span class="w">        </span>-<span class="w"> </span>name<span class="p">:</span><span class="w"> </span>mysql-persistent-storage<span class="w">
</span><span class="w">          </span>mountPath<span class="p">:</span><span class="w"> </span>/var/lib/mysql<span class="w">
</span><span class="w"></span>...<span class="w">
</span><span class="w">      </span>volumes<span class="p">:</span><span class="w">
</span><span class="w">      </span>-<span class="w"> </span>name<span class="p">:</span><span class="w"> </span>mysql-persistent-storage<span class="w">
</span><span class="w">        </span>persistentVolumeClaim<span class="p">:</span><span class="w">
</span><span class="w">          </span>claimName<span class="p">:</span><span class="w"> </span>mysql-pv-claim<span class="w">
</span><span class="w"></span>...</code></pre></div>
<p><code>presistentVolumeClain</code> is key here. This tells Kubernetes that this resource requires a persistent volume. How it&rsquo;s provided is abstracted away from the user. You can be sure that Kubernetes will provide a volume that will always be there. It is similar to Pods. To read up on the details, check out this document: <a href="https://kubernetes.io/docs/concepts/storage/persistent-volumes">Kubernetes Persistent Volumes</a>.</p>

<p>Deploying the mysql Service is done with the following command:</p>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash">kubectl apply -f mysql.yaml</code></pre></div>
<p><code>apply</code> vs <code>create</code>. In short, <code>apply</code> is considered a declarative object configuration command while <code>create</code> is imperative. What this means for now is that ‘create’ is usually for a one of tasks, like running something or creating a deployment. While, when using apply, the user doesn&rsquo;t define the action to be taken. That will be defined by Kubernetes based on the current status of the cluster. Thus, when there is no service called <code>mysql</code> and I&rsquo;m calling <code>apply -f mysql.yaml</code> it will create the service. When running again, Kubernetes won&rsquo;t do anything. But if I would run <code>create</code> again it will throw an error saying the service is already created.</p>

<p>For more information, check out the following docs: <a href="https://kubernetes.io/docs/concepts/overview/object-management-kubectl/overview/">Kubernetes Object Management</a>, <a href="https://kubernetes.io/docs/concepts/overview/object-management-kubectl/imperative-config/">Imperative Configuration</a>, <a href="https://kubernetes.io/docs/concepts/overview/object-management-kubectl/declarative-config/">Declarative Configuration</a>.</p>

<p>To see progress information, run:</p>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash"><span class="c1"># Describes the whole process</span>
kubectl describe deployment mysql
<span class="c1"># Shows only the pod</span>
kubectl get pods -l <span class="nv">app</span><span class="o">=</span>mysql</code></pre></div>
<p>Output should be similar to this:</p>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash">...
  Type           Status  Reason
  ----           ------  ------
  Available      True    MinimumReplicasAvailable
  Progressing    True    NewReplicaSetAvailable
OldReplicaSets:  &lt;none&gt;
NewReplicaSet:   mysql-55cd6b9f47 <span class="o">(</span><span class="m">1</span>/1 replicas created<span class="o">)</span>
...</code></pre></div>
<p>Or in case of <code>get pods</code>:</p>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash">NAME                     READY     STATUS    RESTARTS   AGE
mysql-78dbbd9c49-k6sdv   <span class="m">1</span>/1       Running   <span class="m">0</span>          18s</code></pre></div>
<p>To test the instance, run the following snippet:</p>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash">kubectl run -it --rm --image<span class="o">=</span>mysql:5.6 --restart<span class="o">=</span>Never mysql-client -- mysql -h mysql -pyourpasswordhere</code></pre></div>
<p><strong>GOTCHA</strong>: If you change the password now, it&rsquo;s not enough to re-apply your yaml file to update the container. Since the DB is persisted, the password will not be changed. You have to delete the whole deployment with <code>kubectl delete -f mysql.yaml</code>.</p>

<p>You should see the following when running a <code>show databases</code>.</p>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash">If you don<span class="err">&#39;</span>t see a <span class="nb">command</span> prompt, try pressing enter.
mysql&gt;
mysql&gt;
mysql&gt; show databases<span class="p">;</span>
+--------------------+
<span class="p">|</span> Database           <span class="p">|</span>
+--------------------+
<span class="p">|</span> information_schema <span class="p">|</span>
<span class="p">|</span> kube               <span class="p">|</span>
<span class="p">|</span> mysql              <span class="p">|</span>
<span class="p">|</span> performance_schema <span class="p">|</span>
+--------------------+
<span class="m">4</span> rows in <span class="nb">set</span> <span class="o">(</span><span class="m">0</span>.00 sec<span class="o">)</span>

mysql&gt; <span class="nb">exit</span>
Bye</code></pre></div>
<p>You&rsquo;ll also notice that I’ve mounted a file located here: <a href="https://github.com/Skarlso/kube-cluster-sample/blob/master/database_setup.sql">Database Setup SQL</a> into the container. MySQL container automatically executes these. That file will bootstrap some data and the schema I&rsquo;m going to use.</p>

<p>The volume definition is as follows:</p>
<div class="highlight"><pre class="chroma"><code class="language-yaml" data-lang="yaml"><span class="w">  </span>volumeMounts<span class="p">:</span><span class="w">
</span><span class="w">  </span>-<span class="w"> </span>name<span class="p">:</span><span class="w"> </span>mysql-persistent-storage<span class="w">
</span><span class="w">    </span>mountPath<span class="p">:</span><span class="w"> </span>/var/lib/mysql<span class="w">
</span><span class="w">  </span>-<span class="w"> </span>name<span class="p">:</span><span class="w"> </span>bootstrap-script<span class="w">
</span><span class="w">    </span>mountPath<span class="p">:</span><span class="w"> </span>/docker-entrypoint-initdb.d/database_setup.sql<span class="w">
</span><span class="w"></span>volumes<span class="p">:</span><span class="w">
</span><span class="w"></span>-<span class="w"> </span>name<span class="p">:</span><span class="w"> </span>mysql-persistent-storage<span class="w">
</span><span class="w">  </span>persistentVolumeClaim<span class="p">:</span><span class="w">
</span><span class="w">    </span>claimName<span class="p">:</span><span class="w"> </span>mysql-pv-claim<span class="w">
</span><span class="w"></span>-<span class="w"> </span>name<span class="p">:</span><span class="w"> </span>bootstrap-script<span class="w">
</span><span class="w">  </span>hostPath<span class="p">:</span><span class="w">
</span><span class="w">    </span>path<span class="p">:</span><span class="w"> </span>/Users/hannibal/golang/src/github.com/Skarlso/kube-cluster-sample/database_setup.sql<span class="w">
</span><span class="w">    </span>type<span class="p">:</span><span class="w"> </span>File</code></pre></div>
<p>To check if the bootstrap script was successful, run this:</p>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash">~/golang/src/github.com/Skarlso/kube-cluster-sample/kube_files master*
❯ kubectl run -it --rm --image<span class="o">=</span>mysql:5.6 --restart<span class="o">=</span>Never mysql-client -- mysql -h mysql -uroot -pyourpasswordhere kube
If you don<span class="err">&#39;</span>t see a <span class="nb">command</span> prompt, try pressing enter.

mysql&gt; show tables<span class="p">;</span>
+----------------+
<span class="p">|</span> Tables_in_kube <span class="p">|</span>
+----------------+
<span class="p">|</span> images         <span class="p">|</span>
<span class="p">|</span> person         <span class="p">|</span>
<span class="p">|</span> person_images  <span class="p">|</span>
+----------------+
<span class="m">3</span> rows in <span class="nb">set</span> <span class="o">(</span><span class="m">0</span>.00 sec<span class="o">)</span>

mysql&gt;</code></pre></div>
<p>This concludes the database service setup. Logs for this service can be viewed with the following command:</p>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash">kubectl logs deployment/mysql -f</code></pre></div>
<h3 id="nsq-lookup">NSQ Lookup</h3>

<p>The NSQ Lookup will run as an internal service. It doesn&rsquo;t need access from the outside, so I&rsquo;m setting <code>clusterIP: None</code> which will tell Kubernetes that this service is a headless service. This means that it won&rsquo;t be load balanced, and it won&rsquo;t be a single IP service. The DNS will be based upon service selectors.</p>

<p>Our NSQ Lookup selector is:</p>
<div class="highlight"><pre class="chroma"><code class="language-yaml" data-lang="yaml"><span class="w">  </span>selector<span class="p">:</span><span class="w">
</span><span class="w">    </span>matchLabels<span class="p">:</span><span class="w">
</span><span class="w">      </span>app<span class="p">:</span><span class="w"> </span>nsqlookup</code></pre></div>
<p>Thus, the internal DNS will look like this: <code>nsqlookup.default.svc.cluster.local</code>.</p>

<p>Headless services are described in detail here: <a href="https://kubernetes.io/docs/concepts/services-networking/service/#headless-services">Headless Service</a>.</p>

<p>Basically it&rsquo;s the same as MySQL just with slight modifications. As stated earlier, I&rsquo;m using NSQ&rsquo;s own Docker Image called <code>nsqio/nsq</code>. All nsq commands are there, so nsqd will also use this image just with a different command. For nsqlookupd the command is:</p>
<div class="highlight"><pre class="chroma"><code class="language-yaml" data-lang="yaml">command<span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="s2">&#34;/nsqlookupd&#34;</span><span class="p">]</span><span class="w">
</span><span class="w"></span>args<span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="s2">&#34;--broadcast-address=nsqlookup.default.svc.cluster.local&#34;</span><span class="p">]</span></code></pre></div>
<p>What&rsquo;s the <code>--broadcast-address</code> for, you might ask? By default, nsqlookup will use the <code>hostname</code> as broadcast address. When the consumer runs a callback it will try to connect to something like <code>http://nsqlookup-234kf-asdf:4161/lookup?topics=image</code>. Note that <code>nsqlookup-234kf-asdf</code> is the hostname of the container. By setting the broadcast-address to the internal DNS that callback will be: <code>http://nsqlookup.default.svc.cluster.local:4161/lookup?topic=images</code>. Which will work as expected.</p>

<p>NSQ Lookup also requires two ports forwarded. One for broadcasting and one for nsqd callback. These are exposed in the Dockerfile and then utilized in the Kubernetes template like this:</p>

<p>In the container template:</p>
<div class="highlight"><pre class="chroma"><code class="language-yaml" data-lang="yaml"><span class="w">        </span>ports<span class="p">:</span><span class="w">
</span><span class="w">        </span>-<span class="w"> </span>containerPort<span class="p">:</span><span class="w"> </span><span class="m">4160</span><span class="w">
</span><span class="w">          </span>hostPort<span class="p">:</span><span class="w"> </span><span class="m">4160</span><span class="w">
</span><span class="w">        </span>-<span class="w"> </span>containerPort<span class="p">:</span><span class="w"> </span><span class="m">4161</span><span class="w">
</span><span class="w">          </span>hostPort<span class="p">:</span><span class="w"> </span><span class="m">4161</span></code></pre></div>
<p>In the service template:</p>
<div class="highlight"><pre class="chroma"><code class="language-yaml" data-lang="yaml">spec<span class="p">:</span><span class="w">
</span><span class="w">  </span>ports<span class="p">:</span><span class="w">
</span><span class="w">  </span>-<span class="w"> </span>name<span class="p">:</span><span class="w"> </span>tcp<span class="w">
</span><span class="w">    </span>protocol<span class="p">:</span><span class="w"> </span>TCP<span class="w">
</span><span class="w">    </span>port<span class="p">:</span><span class="w"> </span><span class="m">4160</span><span class="w">
</span><span class="w">    </span>targetPort<span class="p">:</span><span class="w"> </span><span class="m">4160</span><span class="w">
</span><span class="w">  </span>-<span class="w"> </span>name<span class="p">:</span><span class="w"> </span>http<span class="w">
</span><span class="w">    </span>protocol<span class="p">:</span><span class="w"> </span>TCP<span class="w">
</span><span class="w">    </span>port<span class="p">:</span><span class="w"> </span><span class="m">4161</span><span class="w">
</span><span class="w">    </span>targetPort<span class="p">:</span><span class="w"> </span><span class="m">4161</span></code></pre></div>
<p>Names are required by Kubernetes.</p>

<p>To create this service, I&rsquo;m using the same command as before:</p>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash">kubectl apply -f nsqlookup.yaml</code></pre></div>
<p>This concludes nsqlookupd. Two of the major players are in the sack.</p>

<h3 id="receiver-1">Receiver</h3>

<p>This is a more complex one. The receiver will do three things.</p>

<ul>
<li>Create some deployments</li>
<li>Create the nsq daemon</li>
<li>Expose the service to the public</li>
</ul>

<h4 id="deployments-1">Deployments</h4>

<p>The first deployment it creates is it&rsquo;s own. The receiver’s container is <code>skarlso/kube-receiver-alpine</code>.</p>

<h4 id="nsq-daemon">Nsq Daemon</h4>

<p>The receiver starts an nsq daemon. Like stated earlier, the receiver runs an nsqd with it-self. It does that so talking to it can happen locally and not over the network. By making receiver do this, they will end up on the same node.</p>

<p>NSQ daemon also needs some adjustments and parameters.</p>
<div class="highlight"><pre class="chroma"><code class="language-yaml" data-lang="yaml"><span class="w">        </span>ports<span class="p">:</span><span class="w">
</span><span class="w">        </span>-<span class="w"> </span>containerPort<span class="p">:</span><span class="w"> </span><span class="m">4150</span><span class="w">
</span><span class="w">          </span>hostPort<span class="p">:</span><span class="w"> </span><span class="m">4150</span><span class="w">
</span><span class="w">        </span>-<span class="w"> </span>containerPort<span class="p">:</span><span class="w"> </span><span class="m">4151</span><span class="w">
</span><span class="w">          </span>hostPort<span class="p">:</span><span class="w"> </span><span class="m">4151</span><span class="w">
</span><span class="w">        </span>env<span class="p">:</span><span class="w">
</span><span class="w">        </span>-<span class="w"> </span>name<span class="p">:</span><span class="w"> </span>NSQLOOKUP_ADDRESS<span class="w">
</span><span class="w">          </span>value<span class="p">:</span><span class="w"> </span>nsqlookup.default.svc.cluster.local<span class="w">
</span><span class="w">        </span>-<span class="w"> </span>name<span class="p">:</span><span class="w"> </span>NSQ_BROADCAST_ADDRESS<span class="w">
</span><span class="w">          </span>value<span class="p">:</span><span class="w"> </span>nsqd.default.svc.cluster.local<span class="w">
</span><span class="w">        </span>command<span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="s2">&#34;/nsqd&#34;</span><span class="p">]</span><span class="w">
</span><span class="w">        </span>args<span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="s2">&#34;--lookupd-tcp-address=$(NSQLOOKUP_ADDRESS):4160&#34;</span><span class="p">,</span><span class="w"> </span><span class="s2">&#34;--broadcast-address=$(NSQ_BROADCAST_ADDRESS)&#34;</span><span class="p">]</span></code></pre></div>
<p>You can see that the lookup-tcp-address and the broadcast-address are set. Lookup tcp address is the DNS for the nsqlookupd service. And the broadcast address is necessary just like with nsqlookupd so the callbacks are working properly.</p>

<h4 id="public-facing">Public facing</h4>

<p>Now, this is the first time I&rsquo;m deploying a public facing service. There are two options. I could use a LoadBalancer because this API will be under heavy load. And if this would be deployed anywhere in production, then it should be using one.</p>

<p>I&rsquo;m doing this locally though- with one node- so something called a <code>NodePort</code> is enough. A <code>NodePort</code> exposes a service on each node&rsquo;s IP at a static port. If not specified, it will assign a random port on the host between 30000-32767. But it can also be configured to be a specific port, using <code>nodePort</code> in the template file. To reach this service, use <code>&lt;NodeIP&gt;:&lt;NodePort&gt;</code>. If more than one node is configured a LoadBalancer can multiplex them to a single IP.</p>

<p>For further information check out this document: <a href="https://kubernetes.io/docs/concepts/services-networking/service/#publishing-services---service-types">Publishing Services</a>.</p>

<p>Putting this all together, we&rsquo;ll get a receiver-service for which the template is as follows:</p>
<div class="highlight"><pre class="chroma"><code class="language-yaml" data-lang="yaml">apiVersion<span class="p">:</span><span class="w"> </span>v1<span class="w">
</span><span class="w"></span>kind<span class="p">:</span><span class="w"> </span>Service<span class="w">
</span><span class="w"></span>metadata<span class="p">:</span><span class="w">
</span><span class="w">  </span>name<span class="p">:</span><span class="w"> </span>receiver-service<span class="w">
</span><span class="w"></span>spec<span class="p">:</span><span class="w">
</span><span class="w">  </span>ports<span class="p">:</span><span class="w">
</span><span class="w">  </span>-<span class="w"> </span>protocol<span class="p">:</span><span class="w"> </span>TCP<span class="w">
</span><span class="w">    </span>port<span class="p">:</span><span class="w"> </span><span class="m">8000</span><span class="w">
</span><span class="w">    </span>targetPort<span class="p">:</span><span class="w"> </span><span class="m">8000</span><span class="w">
</span><span class="w">  </span>selector<span class="p">:</span><span class="w">
</span><span class="w">    </span>app<span class="p">:</span><span class="w"> </span>receiver<span class="w">
</span><span class="w">  </span>type<span class="p">:</span><span class="w"> </span>NodePort</code></pre></div>
<p>For a fixed nodePort on 8000 a definition of <code>nodePort</code> must be provided:</p>
<div class="highlight"><pre class="chroma"><code class="language-yaml" data-lang="yaml">apiVersion<span class="p">:</span><span class="w"> </span>v1<span class="w">
</span><span class="w"></span>kind<span class="p">:</span><span class="w"> </span>Service<span class="w">
</span><span class="w"></span>metadata<span class="p">:</span><span class="w">
</span><span class="w">  </span>name<span class="p">:</span><span class="w"> </span>receiver-service<span class="w">
</span><span class="w"></span>spec<span class="p">:</span><span class="w">
</span><span class="w">  </span>ports<span class="p">:</span><span class="w">
</span><span class="w">  </span>-<span class="w"> </span>protocol<span class="p">:</span><span class="w"> </span>TCP<span class="w">
</span><span class="w">    </span>port<span class="p">:</span><span class="w"> </span><span class="m">8000</span><span class="w">
</span><span class="w">    </span>targetPort<span class="p">:</span><span class="w"> </span><span class="m">8000</span><span class="w">
</span><span class="w">  </span>selector<span class="p">:</span><span class="w">
</span><span class="w">    </span>app<span class="p">:</span><span class="w"> </span>receiver<span class="w">
</span><span class="w">  </span>type<span class="p">:</span><span class="w"> </span>NodePort<span class="w">
</span><span class="w">  </span>nodePort<span class="p">:</span><span class="w"> </span><span class="m">8000</span></code></pre></div>
<h3 id="image-processor-1">Image processor</h3>

<p>The Image Processor is where I&rsquo;m handling passing off images to be identified. It should have access to nsqlookupd, mysql and the gRPC endpoint of the face recognition service. This is actually a boring service. In fact, it&rsquo;s not a service at all. It doesn&rsquo;t expose anything and thus it&rsquo;s the first deployment only component. For brevity, here is the whole template:</p>
<div class="highlight"><pre class="chroma"><code class="language-yaml" data-lang="yaml">---<span class="w">
</span><span class="w"></span>apiVersion<span class="p">:</span><span class="w"> </span>apps/v1<span class="w">
</span><span class="w"></span>kind<span class="p">:</span><span class="w"> </span>Deployment<span class="w">
</span><span class="w"></span>metadata<span class="p">:</span><span class="w">
</span><span class="w">  </span>name<span class="p">:</span><span class="w"> </span>image-processor-deployment<span class="w">
</span><span class="w"></span>spec<span class="p">:</span><span class="w">
</span><span class="w">  </span>selector<span class="p">:</span><span class="w">
</span><span class="w">    </span>matchLabels<span class="p">:</span><span class="w">
</span><span class="w">      </span>app<span class="p">:</span><span class="w"> </span>image-processor<span class="w">
</span><span class="w">  </span>replicas<span class="p">:</span><span class="w"> </span><span class="m">1</span><span class="w">
</span><span class="w">  </span>template<span class="p">:</span><span class="w">
</span><span class="w">    </span>metadata<span class="p">:</span><span class="w">
</span><span class="w">      </span>labels<span class="p">:</span><span class="w">
</span><span class="w">        </span>app<span class="p">:</span><span class="w"> </span>image-processor<span class="w">
</span><span class="w">    </span>spec<span class="p">:</span><span class="w">
</span><span class="w">      </span>containers<span class="p">:</span><span class="w">
</span><span class="w">      </span>-<span class="w"> </span>name<span class="p">:</span><span class="w"> </span>image-processor<span class="w">
</span><span class="w">        </span>image<span class="p">:</span><span class="w"> </span>skarlso/kube-processor-alpine<span class="p">:</span>latest<span class="w">
</span><span class="w">        </span>env<span class="p">:</span><span class="w">
</span><span class="w">        </span>-<span class="w"> </span>name<span class="p">:</span><span class="w"> </span>MYSQL_CONNECTION<span class="w">
</span><span class="w">          </span>value<span class="p">:</span><span class="w"> </span><span class="s2">&#34;mysql.default.svc.cluster.local&#34;</span><span class="w">
</span><span class="w">        </span>-<span class="w"> </span>name<span class="p">:</span><span class="w"> </span>MYSQL_USERPASSWORD<span class="w">
</span><span class="w">          </span>valueFrom<span class="p">:</span><span class="w">
</span><span class="w">            </span>secretKeyRef<span class="p">:</span><span class="w">
</span><span class="w">              </span>name<span class="p">:</span><span class="w"> </span>kube-face-secret<span class="w">
</span><span class="w">              </span>key<span class="p">:</span><span class="w"> </span>mysql_userpassword<span class="w">
</span><span class="w">        </span>-<span class="w"> </span>name<span class="p">:</span><span class="w"> </span>MYSQL_PORT<span class="w">
</span><span class="w">          </span><span class="c"># TIL: If this is 3306 without &#34; kubectl throws an error.</span><span class="w">
</span><span class="w">          </span>value<span class="p">:</span><span class="w"> </span><span class="s2">&#34;3306&#34;</span><span class="w">
</span><span class="w">        </span>-<span class="w"> </span>name<span class="p">:</span><span class="w"> </span>MYSQL_DBNAME<span class="w">
</span><span class="w">          </span>value<span class="p">:</span><span class="w"> </span>kube<span class="w">
</span><span class="w">        </span>-<span class="w"> </span>name<span class="p">:</span><span class="w"> </span>NSQ_LOOKUP_ADDRESS<span class="w">
</span><span class="w">          </span>value<span class="p">:</span><span class="w"> </span><span class="s2">&#34;nsqlookup.default.svc.cluster.local:4161&#34;</span><span class="w">
</span><span class="w">        </span>-<span class="w"> </span>name<span class="p">:</span><span class="w"> </span>GRPC_ADDRESS<span class="w">
</span><span class="w">          </span>value<span class="p">:</span><span class="w"> </span><span class="s2">&#34;face-recog.default.svc.cluster.local:50051&#34;</span></code></pre></div>
<p>The only interesting points in this file are the multitude of environment properties that are used to configure the application. Note the nsqlookupd address and the grpc address.</p>

<p>To create this deployment, run:</p>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash">kubectl apply -f image_processor.yaml</code></pre></div>
<h3 id="face-recognition-1">Face - Recognition</h3>

<p>The face recognition service does have a service. It&rsquo;s a simple one, only needed by image-processor. It&rsquo;s template is as follows:</p>
<div class="highlight"><pre class="chroma"><code class="language-yaml" data-lang="yaml">apiVersion<span class="p">:</span><span class="w"> </span>v1<span class="w">
</span><span class="w"></span>kind<span class="p">:</span><span class="w"> </span>Service<span class="w">
</span><span class="w"></span>metadata<span class="p">:</span><span class="w">
</span><span class="w">  </span>name<span class="p">:</span><span class="w"> </span>face-recog<span class="w">
</span><span class="w"></span>spec<span class="p">:</span><span class="w">
</span><span class="w">  </span>ports<span class="p">:</span><span class="w">
</span><span class="w">  </span>-<span class="w"> </span>protocol<span class="p">:</span><span class="w"> </span>TCP<span class="w">
</span><span class="w">    </span>port<span class="p">:</span><span class="w"> </span><span class="m">50051</span><span class="w">
</span><span class="w">    </span>targetPort<span class="p">:</span><span class="w"> </span><span class="m">50051</span><span class="w">
</span><span class="w">  </span>selector<span class="p">:</span><span class="w">
</span><span class="w">    </span>app<span class="p">:</span><span class="w"> </span>face-recog<span class="w">
</span><span class="w">  </span>clusterIP<span class="p">:</span><span class="w"> </span>None</code></pre></div>
<p>The more interesting part is that it requires two volumes. The two volumes are <code>known_people</code> and <code>unknown_people</code>. Can you guess what they will contain? Yep, images. The <code>known_people</code> volume contains all the images associated to the known people in the database. The <code>unknown_people</code> volume will contain all the new images. And that&rsquo;s the path we will need to use when sending images from the receiver. That is, wherever the mount point points too. Which in my case is <code>/unknown_people</code>. Basically the path needs to be one that the face recognition service can access.</p>

<p>Now, with Kubernetes and Docker this is easy. It could be a mounted S3 or some kind of nfs or a local mount from host to guest. The possibilities are endless (around a dozen or so). I&rsquo;m going to use a local mount for the sake of simplicity.</p>

<p>Mounting a volume has two parts. First, the Dockerfile has to specify volumes:</p>
<div class="highlight"><pre class="chroma"><code class="language-Dockerfile" data-lang="Dockerfile"><span class="k">VOLUME</span><span class="s"> [ &#34;/unknown_people&#34;, &#34;/known_people&#34; ]</span></code></pre></div>
<p>Second, the Kubernetes template needs add <code>volumeMounts</code> as seen in the MySQL service; the difference being <code>hostPath</code> instead of a claimed volume:</p>
<div class="highlight"><pre class="chroma"><code class="language-yaml" data-lang="yaml"><span class="w">        </span>volumeMounts<span class="p">:</span><span class="w">
</span><span class="w">        </span>-<span class="w"> </span>name<span class="p">:</span><span class="w"> </span>known-people-storage<span class="w">
</span><span class="w">          </span>mountPath<span class="p">:</span><span class="w"> </span>/known_people<span class="w">
</span><span class="w">        </span>-<span class="w"> </span>name<span class="p">:</span><span class="w"> </span>unknown-people-storage<span class="w">
</span><span class="w">          </span>mountPath<span class="p">:</span><span class="w"> </span>/unknown_people<span class="w">
</span><span class="w">      </span>volumes<span class="p">:</span><span class="w">
</span><span class="w">      </span>-<span class="w"> </span>name<span class="p">:</span><span class="w"> </span>known-people-storage<span class="w">
</span><span class="w">        </span>hostPath<span class="p">:</span><span class="w">
</span><span class="w">          </span>path<span class="p">:</span><span class="w"> </span>/Users/hannibal/Temp/known_people<span class="w">
</span><span class="w">          </span>type<span class="p">:</span><span class="w"> </span>Directory<span class="w">
</span><span class="w">      </span>-<span class="w"> </span>name<span class="p">:</span><span class="w"> </span>unknown-people-storage<span class="w">
</span><span class="w">        </span>hostPath<span class="p">:</span><span class="w">
</span><span class="w">          </span>path<span class="p">:</span><span class="w"> </span>/Users/hannibal/Temp/<span class="w">
</span><span class="w">          </span>type<span class="p">:</span><span class="w"> </span>Directory</code></pre></div>
<p>We also have to set the <code>known_people</code> folder config setting for face recognition. This is done via an environment property:</p>
<div class="highlight"><pre class="chroma"><code class="language-yaml" data-lang="yaml"><span class="w">        </span>env<span class="p">:</span><span class="w">
</span><span class="w">        </span>-<span class="w"> </span>name<span class="p">:</span><span class="w"> </span>KNOWN_PEOPLE<span class="w">
</span><span class="w">          </span>value<span class="p">:</span><span class="w"> </span><span class="s2">&#34;/known_people&#34;</span></code></pre></div>
<p>Then the Python code will look up images like this:</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python">        <span class="n">known_people</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s1">&#39;KNOWN_PEOPLE&#39;</span><span class="p">,</span> <span class="s1">&#39;known_people&#39;</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="s2">&#34;Known people images location is: </span><span class="si">%s</span><span class="s2">&#34;</span> <span class="o">%</span> <span class="n">known_people</span><span class="p">)</span>
        <span class="n">images</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">image_files_in_folder</span><span class="p">(</span><span class="n">known_people</span><span class="p">)</span></code></pre></div>
<p>Where <code>image_files_in_folder</code> is:</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python">    <span class="k">def</span> <span class="nf">image_files_in_folder</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">folder</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">folder</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span> <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">folder</span><span class="p">)</span> <span class="k">if</span> <span class="n">re</span><span class="o">.</span><span class="n">match</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;.*\.(jpg|jpeg|png)&#39;</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">flags</span><span class="o">=</span><span class="n">re</span><span class="o">.</span><span class="n">I</span><span class="p">)]</span></code></pre></div>
<p>Neat.</p>

<p>Now, if the receiver receives a request (and sends it off further the line) similar to the one below&hellip;</p>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash">curl -d <span class="s1">&#39;{&#34;path&#34;:&#34;/unknown_people/unknown220.jpg&#34;}&#39;</span> http://192.168.99.100:30251/image/post</code></pre></div>
<p>&hellip;it will look for an image called unknown220.jpg under <code>/unknown_people</code>, locate an image in the known_folder that corresponds to the person on the unknown image and return the name of the image that matched.</p>

<p>Looking at logs you should see something like this:</p>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash"><span class="c1"># Receiver</span>
❯ curl -d <span class="s1">&#39;{&#34;path&#34;:&#34;/unknown_people/unknown219.jpg&#34;}&#39;</span> http://192.168.99.100:30251/image/post
got path: <span class="o">{</span>Path:/unknown_people/unknown219.jpg<span class="o">}</span>
image saved with id: <span class="m">4</span>
image sent to nsq

<span class="c1"># Image Processor</span>
<span class="m">2018</span>/03/26 <span class="m">18</span>:11:21 INF    <span class="m">1</span> <span class="o">[</span>images/ch<span class="o">]</span> querying nsqlookupd http://nsqlookup.default.svc.cluster.local:4161/lookup?topic<span class="o">=</span>images
<span class="m">2018</span>/03/26 <span class="m">18</span>:11:59 Got a message: <span class="m">4</span>
<span class="m">2018</span>/03/26 <span class="m">18</span>:11:59 Processing image id:  <span class="m">4</span>
<span class="m">2018</span>/03/26 <span class="m">18</span>:12:00 got person:  Hannibal
<span class="m">2018</span>/03/26 <span class="m">18</span>:12:00 updating record with person id
<span class="m">2018</span>/03/26 <span class="m">18</span>:12:00 <span class="k">done</span></code></pre></div>
<p>And that concludes all of the services that we need to deploy.</p>

<h3 id="frontend">Frontend</h3>

<p>Last, there is a small web-app which displays the information in the db for convenience. This is also a public facing service with the same parameters as the receiver.</p>

<p>It looks like this:</p>

<p><img src="/img/kube-frontend.png" alt="frontend" /></p>

<h3 id="recap">Recap</h3>

<p>So what is the situation so far? I deployed a bunch of services all over the place. A recap off the commands I used:</p>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash">kubectl apply -f mysql.yaml
kubectl apply -f nsqlookup.yaml
kubectl apply -f receiver.yaml
kubectl apply -f image_processor.yaml
kubectl apply -f face_recognition.yaml
kubectl apply -f frontend.yaml</code></pre></div>
<p>These could be in any order because the application does not allocate connections on start. Except for image_processor&rsquo;s NSQ consumer. But that re-tries.</p>

<p>Query-ing kube for running pods with <code>kubectl get pods</code> should show something like this:</p>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash">❯ kubectl get pods
NAME                                          READY     STATUS    RESTARTS   AGE
face-recog-6bf449c6f-qg5tr                    <span class="m">1</span>/1       Running   <span class="m">0</span>          1m
image-processor-deployment-6467468c9d-cvx6m   <span class="m">1</span>/1       Running   <span class="m">0</span>          31s
mysql-7d667c75f4-bwghw                        <span class="m">1</span>/1       Running   <span class="m">0</span>          36s
nsqd-584954c44c-299dz                         <span class="m">1</span>/1       Running   <span class="m">0</span>          26s
nsqlookup-7f5bdfcb87-jkdl7                    <span class="m">1</span>/1       Running   <span class="m">0</span>          11s
receiver-deployment-5cb4797598-sf5ds          <span class="m">1</span>/1       Running   <span class="m">0</span>          26s</code></pre></div>
<p>Running <code>minikube service list</code>:</p>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash">❯ minikube service list
<span class="p">|</span>-------------<span class="p">|</span>----------------------<span class="p">|</span>-----------------------------<span class="p">|</span>
<span class="p">|</span>  NAMESPACE  <span class="p">|</span>         NAME         <span class="p">|</span>             URL             <span class="p">|</span>
<span class="p">|</span>-------------<span class="p">|</span>----------------------<span class="p">|</span>-----------------------------<span class="p">|</span>
<span class="p">|</span> default     <span class="p">|</span> face-recog           <span class="p">|</span> No node port                <span class="p">|</span>
<span class="p">|</span> default     <span class="p">|</span> kubernetes           <span class="p">|</span> No node port                <span class="p">|</span>
<span class="p">|</span> default     <span class="p">|</span> mysql                <span class="p">|</span> No node port                <span class="p">|</span>
<span class="p">|</span> default     <span class="p">|</span> nsqd                 <span class="p">|</span> No node port                <span class="p">|</span>
<span class="p">|</span> default     <span class="p">|</span> nsqlookup            <span class="p">|</span> No node port                <span class="p">|</span>
<span class="p">|</span> default     <span class="p">|</span> receiver-service     <span class="p">|</span> http://192.168.99.100:30251 <span class="p">|</span>
<span class="p">|</span> kube-system <span class="p">|</span> kube-dns             <span class="p">|</span> No node port                <span class="p">|</span>
<span class="p">|</span> kube-system <span class="p">|</span> kubernetes-dashboard <span class="p">|</span> http://192.168.99.100:30000 <span class="p">|</span>
<span class="p">|</span>-------------<span class="p">|</span>----------------------<span class="p">|</span>-----------------------------<span class="p">|</span></code></pre></div>
<h3 id="rolling-update">Rolling update</h3>

<p>What happens during a rolling update?</p>

<p><img src="/img/kube_rotate.png" alt="kube rotate" /></p>

<p>As it happens during software development, change is requested/needed to some parts of the system. What happens to our cluster if I would like to change one of its components without breaking the others? And also whilst maintaining backwards compatibility with no disruption to user experience. Thankfully Kubernetes can help with that.</p>

<p>What I don&rsquo;t like is that the API only handles one image at a time. There is no option to bulk upload.</p>

<h4 id="code">Code</h4>

<p>Right now, we have the following code segment dealing with a single image:</p>
<div class="highlight"><pre class="chroma"><code class="language-go" data-lang="go"><span class="c1">// PostImage handles a post of an image. Saves it to the database
</span><span class="c1">// and sends it to NSQ for further processing.
</span><span class="c1"></span><span class="kd">func</span> <span class="nf">PostImage</span><span class="p">(</span><span class="nx">w</span> <span class="nx">http</span><span class="p">.</span><span class="nx">ResponseWriter</span><span class="p">,</span> <span class="nx">r</span> <span class="o">*</span><span class="nx">http</span><span class="p">.</span><span class="nx">Request</span><span class="p">)</span> <span class="p">{</span>
<span class="o">...</span>
<span class="p">}</span>

<span class="kd">func</span> <span class="nf">main</span><span class="p">()</span> <span class="p">{</span>
    <span class="nx">router</span> <span class="o">:=</span> <span class="nx">mux</span><span class="p">.</span><span class="nf">NewRouter</span><span class="p">()</span>
    <span class="nx">router</span><span class="p">.</span><span class="nf">HandleFunc</span><span class="p">(</span><span class="s">&#34;/image/post&#34;</span><span class="p">,</span> <span class="nx">PostImage</span><span class="p">).</span><span class="nf">Methods</span><span class="p">(</span><span class="s">&#34;POST&#34;</span><span class="p">)</span>
    <span class="nx">log</span><span class="p">.</span><span class="nf">Fatal</span><span class="p">(</span><span class="nx">http</span><span class="p">.</span><span class="nf">ListenAndServe</span><span class="p">(</span><span class="s">&#34;:8000&#34;</span><span class="p">,</span> <span class="nx">router</span><span class="p">))</span>
<span class="p">}</span></code></pre></div>
<p>We have two options. Add a new endpoint with <code>/images/post</code> and make the client use that, or modify the existing one.</p>

<p>The new client code has the advantage that it could fall back to submitting the old way if the new endpoint isn&rsquo;t available. The old client code though doesn&rsquo;t have this advantage so we can&rsquo;t change the way our code works right now. Consider this. You have 90 servers. You do a slow paced rolling update that will take out servers one step at a time doing an update. If an update lasts around a minute, the whole process will take around one and a half hours to complete (not counting any parallel updates).</p>

<p>During that time, some of your servers will run the new code and some will run the old one. Calls are load balanced, thus you have no control over what server is hit. If a client is trying to do a call the new way but hits an old server the client would fail. The client could try a fallback, but since you eliminated the old version it will not succeed unless it, by chance, hits a server with the new code (assuming no sticky sessions are set).</p>

<p>Also, once all your servers are updated, an old client will not be able to use your service any longer at all.</p>

<p>Now, you could argue that you don&rsquo;t want to keep old versions of your code forever. And that is true in some sense. That&rsquo;s why what we are going to do is modify the old code to simply call the new one with some slight augmentations. This way once all clients have been migrated, the code can simply be deleted without any problems.</p>

<h4 id="new-endpoint">New Endpoint</h4>

<p>Let&rsquo;s add a new route method:</p>
<div class="highlight"><pre class="chroma"><code class="language-go" data-lang="go"><span class="o">...</span>
<span class="nx">router</span><span class="p">.</span><span class="nf">HandleFunc</span><span class="p">(</span><span class="s">&#34;/images/post&#34;</span><span class="p">,</span> <span class="nx">PostImages</span><span class="p">).</span><span class="nf">Methods</span><span class="p">(</span><span class="s">&#34;POST&#34;</span><span class="p">)</span>
<span class="o">...</span></code></pre></div>
<p>And updating the old one to call the new one with a modified body like this:</p>
<div class="highlight"><pre class="chroma"><code class="language-go" data-lang="go"><span class="c1">// PostImage handles a post of an image. Saves it to the database
</span><span class="c1">// and sends it to NSQ for further processing.
</span><span class="c1"></span><span class="kd">func</span> <span class="nf">PostImage</span><span class="p">(</span><span class="nx">w</span> <span class="nx">http</span><span class="p">.</span><span class="nx">ResponseWriter</span><span class="p">,</span> <span class="nx">r</span> <span class="o">*</span><span class="nx">http</span><span class="p">.</span><span class="nx">Request</span><span class="p">)</span> <span class="p">{</span>
    <span class="kd">var</span> <span class="nx">p</span> <span class="nx">Path</span>
    <span class="nx">err</span> <span class="o">:=</span> <span class="nx">json</span><span class="p">.</span><span class="nf">NewDecoder</span><span class="p">(</span><span class="nx">r</span><span class="p">.</span><span class="nx">Body</span><span class="p">).</span><span class="nf">Decode</span><span class="p">(</span><span class="o">&amp;</span><span class="nx">p</span><span class="p">)</span>
    <span class="k">if</span> <span class="nx">err</span> <span class="o">!=</span> <span class="kc">nil</span> <span class="p">{</span>
      <span class="nx">fmt</span><span class="p">.</span><span class="nf">Fprintf</span><span class="p">(</span><span class="nx">w</span><span class="p">,</span> <span class="s">&#34;got error while decoding body: %s&#34;</span><span class="p">,</span> <span class="nx">err</span><span class="p">)</span>
      <span class="k">return</span>
    <span class="p">}</span>
    <span class="nx">fmt</span><span class="p">.</span><span class="nf">Fprintf</span><span class="p">(</span><span class="nx">w</span><span class="p">,</span> <span class="s">&#34;got path: %+v\n&#34;</span><span class="p">,</span> <span class="nx">p</span><span class="p">)</span>
    <span class="kd">var</span> <span class="nx">ps</span> <span class="nx">Paths</span>
    <span class="nx">paths</span> <span class="o">:=</span> <span class="nb">make</span><span class="p">([]</span><span class="nx">Path</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="nx">paths</span> <span class="p">=</span> <span class="nb">append</span><span class="p">(</span><span class="nx">paths</span><span class="p">,</span> <span class="nx">p</span><span class="p">)</span>
    <span class="nx">ps</span><span class="p">.</span><span class="nx">Paths</span> <span class="p">=</span> <span class="nx">paths</span>
    <span class="kd">var</span> <span class="nx">pathsJSON</span> <span class="nx">bytes</span><span class="p">.</span><span class="nx">Buffer</span>
    <span class="nx">err</span> <span class="p">=</span> <span class="nx">json</span><span class="p">.</span><span class="nf">NewEncoder</span><span class="p">(</span><span class="o">&amp;</span><span class="nx">pathsJSON</span><span class="p">).</span><span class="nf">Encode</span><span class="p">(</span><span class="nx">ps</span><span class="p">)</span>
    <span class="k">if</span> <span class="nx">err</span> <span class="o">!=</span> <span class="kc">nil</span> <span class="p">{</span>
      <span class="nx">fmt</span><span class="p">.</span><span class="nf">Fprintf</span><span class="p">(</span><span class="nx">w</span><span class="p">,</span> <span class="s">&#34;failed to encode paths: %s&#34;</span><span class="p">,</span> <span class="nx">err</span><span class="p">)</span>
      <span class="k">return</span>
    <span class="p">}</span>
    <span class="nx">r</span><span class="p">.</span><span class="nx">Body</span> <span class="p">=</span> <span class="nx">ioutil</span><span class="p">.</span><span class="nf">NopCloser</span><span class="p">(</span><span class="o">&amp;</span><span class="nx">pathsJSON</span><span class="p">)</span>
    <span class="nx">r</span><span class="p">.</span><span class="nx">ContentLength</span> <span class="p">=</span> <span class="nb">int64</span><span class="p">(</span><span class="nx">pathsJSON</span><span class="p">.</span><span class="nf">Len</span><span class="p">())</span>
    <span class="nf">PostImages</span><span class="p">(</span><span class="nx">w</span><span class="p">,</span> <span class="nx">r</span><span class="p">)</span>
<span class="p">}</span></code></pre></div>
<p>Well, the naming could be better, but you should get the basic idea. I&rsquo;m modifying the incoming single path by wrapping it into the new format and sending it over to the new endpoint handler. And that&rsquo;s it. There are a few more modifications, to check them out take a look at this PR: <a href="https://github.com/Skarlso/kube-cluster-sample/pull/1">Rolling Update Bulk Image Path PR</a>.</p>

<p>Now, we can call the receiver in two ways:</p>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash"><span class="c1"># Single Path:</span>
curl -d <span class="s1">&#39;{&#34;path&#34;:&#34;unknown4456.jpg&#34;}&#39;</span> http://127.0.0.1:8000/image/post

<span class="c1"># Multiple Paths:</span>
curl -d <span class="s1">&#39;{&#34;paths&#34;:[{&#34;path&#34;:&#34;unknown4456.jpg&#34;}]}&#39;</span> http://127.0.0.1:8000/images/post</code></pre></div>
<p>Here, the client is curl. Normally, if the client would be a service, I would modify it that in case the new end-point throws a 404 it would try the old one next.</p>

<p>For brevity, I&rsquo;m not modifying NSQ and the others to handle bulk image processing. They will still receive it one - by - one. I&rsquo;ll leave that up to you as homework. ;)</p>

<h4 id="new-image">New Image</h4>

<p>To perform a rolling update, I must create a new image first from the receiver service.</p>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash">docker build -t skarlso/kube-receiver-alpine:v1.1 .</code></pre></div>
<p>Once this is complete, we can begin rolling out the change.</p>

<h4 id="rolling-update-1">Rolling update</h4>

<p>In Kubernetes, you can configure your rolling update in multiple ways.</p>

<h5 id="manual-update">Manual Update</h5>

<p>If, say, I was using a container version in my config file called <code>v1.0</code> than doing an update is simply calling:</p>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash">kubectl rolling-update receiver --image:skarlso/kube-receiver-alpine:v1.1</code></pre></div>
<p>If there is a problem during the rollout we can always rollback.</p>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash">kubectl rolling-update receiver --rollback</code></pre></div>
<p>It will set back the previous version no fuss, no muss.</p>

<h5 id="apply-a-new-configuration-file">Apply a new configuration file</h5>

<p>The problem with by-hand updates is always that they aren&rsquo;t in source control.</p>

<p>Consider this. Something changed, a couple of servers got updated by hand to do a quick “patch fix”, but nobody witnessed it and it wasn’t documented. A new person comes along and does a change to the template and applies the template to the cluster. All the servers are updated, but suddenly, there is a service outage.</p>

<p>Long story short, the servers which got updated are whacked over because the template didn&rsquo;t reflect what has been done by hand. That is bad. Don&rsquo;t do that.</p>

<p>The recommended way is to change the template to use the new version and than apply the template with the <code>apply</code> command.</p>

<p>Kubernetes recommends that the Deployment handles the rollout with ReplicaSets. This means however, that there must be at least two replicates present for a rolling update. Otherwise the update won&rsquo;t work (unless <code>maxUnavailable</code> is set to 1). I&rsquo;m increasing the replica count in the yaml and I set the new image version for the receiver container.</p>
<div class="highlight"><pre class="chroma"><code class="language-yaml" data-lang="yaml"><span class="w">  </span>replicas<span class="p">:</span><span class="w"> </span><span class="m">2</span><span class="w">
</span><span class="w"></span>...<span class="w">
</span><span class="w">    </span>spec<span class="p">:</span><span class="w">
</span><span class="w">      </span>containers<span class="p">:</span><span class="w">
</span><span class="w">      </span>-<span class="w"> </span>name<span class="p">:</span><span class="w"> </span>receiver<span class="w">
</span><span class="w">        </span>image<span class="p">:</span><span class="w"> </span>skarlso/kube-receiver-alpine<span class="p">:</span>v1.<span class="m">1</span><span class="w">
</span><span class="w"></span>...</code></pre></div>
<p>Looking at the progress you should see something like this:</p>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash">❯ kubectl rollout status deployment/receiver-deployment
Waiting <span class="k">for</span> rollout to finish: <span class="m">1</span> out of <span class="m">2</span> new replicas have been updated...</code></pre></div>
<p>You can add in additional rollout configuration settings by specifying the <code>strategy</code> part of the template like this:</p>
<div class="highlight"><pre class="chroma"><code class="language-yaml" data-lang="yaml"><span class="w">  </span>strategy<span class="p">:</span><span class="w">
</span><span class="w">    </span>type<span class="p">:</span><span class="w"> </span>RollingUpdate<span class="w">
</span><span class="w">    </span>rollingUpdate<span class="p">:</span><span class="w">
</span><span class="w">      </span>maxSurge<span class="p">:</span><span class="w"> </span><span class="m">1</span><span class="w">
</span><span class="w">      </span>maxUnavailable<span class="p">:</span><span class="w"> </span><span class="m">0</span></code></pre></div>
<p>Additional information on rolling update can be found in these documents: <a href="https://kubernetes.io/docs/concepts/workloads/controllers/deployment/#rolling-back-a-deployment">Deployment Rolling Update</a>, <a href="https://kubernetes.io/docs/concepts/workloads/controllers/deployment/#updating-a-deployment">Updating a Deployment</a>, <a href="https://kubernetes.io/docs/concepts/cluster-administration/manage-deployment/#updating-your-application-without-a-service-outage">Manage Deployments</a>, <a href="https://kubernetes.io/docs/tasks/run-application/rolling-update-replication-controller/">Rolling Update using ReplicaController</a>.</p>

<p><strong>NOTE MINIKUBE USERS</strong>: Since we are doing this on a local machine with one node and 1 replica of an application, we have to set <code>maxUnavailable</code> to <code>1</code>. Otherwise, Kubernetes won&rsquo;t allow the update to happen and the new version will always be in <code>Pending</code> state since we aren&rsquo;t allowing that at any given point in time there is a situation where no containers are present for <code>receiver</code> app.</p>

<h3 id="scaling-1">Scaling</h3>

<p>Scaling is dead easy with Kubernetes. Since it&rsquo;s managing the whole cluster, you basically, just have to put a number into the template of the desired replicas to use.</p>

<p>This has been a great post so far but it&rsquo;s getting too long. I&rsquo;m planning on writing a follow-up where I will be truly scaling things up on AWS with multiple nodes and replicas. Stay tuned.</p>

<h3 id="cleanup">Cleanup</h3>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash">kubectl delete deployments --all
kubectl delete services -all</code></pre></div>
<h1 id="final-words">Final Words</h1>

<p>And that is it ladies and gentleman. We wrote, deployed, updated and scaled (well, not yet really) a distributed application with Kubernetes.</p>

<p>Any questions, please feel free to chat in the comments below, I&rsquo;m happy to answer.</p>

<p>I hope you enjoyed reading this. I know, it&rsquo;s quiet long and I was thinking of splitting it up, but having a cohesive, one page guide is sometimes useful and makes it easy to find something or save it for later read or even print as PDF.</p>

<p>Thank you for reading,
Gergely.</p>
]]></content>
		</item>
		
		<item>
			<title>Go Budapest Meetup</title>
			<link>https://skarlso.github.io/2018/02/06/go-budapest-meetup/</link>
			<pubDate>Tue, 06 Feb 2018 23:01:00 +0100</pubDate>
			
			<guid>https://skarlso.github.io/2018/02/06/go-budapest-meetup/</guid>
			<description>Intro So I was at Go Budapest Meetup yesterday, where the brilliant Johan Brandhorst gave a talk about his project based on gRPC using gRPC-web + GopherJS + protobuf. He also has some Go contributions and check out his project here: Protobuf. It&amp;rsquo;s GopherJS Bindings for ProtobufJS and gRPC-Web.
It was interesting to see where these projects could lead and I see the potential in them. I liked the usage of Protobuf and gRPC, I don&amp;rsquo;t have THAT much experience with them.</description>
			<content type="html"><![CDATA[

<h1 id="intro">Intro</h1>

<p>So I was at <a href="https://www.meetup.com/go-budapest">Go Budapest Meetup</a> yesterday, where the brilliant <a href="https://jbrandhorst.com/">Johan Brandhorst</a>
gave a talk about his project based on <a href="https://grpc.io/">gRPC</a> using <a href="https://github.com/improbable-eng/grpc-web">gRPC-web</a> +
<a href="https://github.com/gopherjs/gopherjs">GopherJS</a> + <a href="https://github.com/google/protobuf">protobuf</a>. He also has some Go
contributions and check out his project here: <a href="https://github.com/johanbrandhorst/protobuf">Protobuf</a>. It&rsquo;s GopherJS Bindings for
ProtobufJS and gRPC-Web.</p>

<p>It was interesting to see where these projects could lead and I see the potential in them. I liked the usage of Protobuf and gRPC,
I don&rsquo;t have THAT much experience with them. However after yesterday, I&rsquo;m eager to find an excuse to do something with these libraries.
I used gRPC indirectly, well, the result of it, when dealing with Google Cloud Platform&rsquo;s API. Which is largely generated code through
gRPC and protobuf.</p>

<p>He also presented a bi-directional stream communication between the gRPC-web client and the server which was an interesting feat
to produce. It did involve the use of <a href="https://godoc.org/golang.org/x/sync/errgroup">errgroup</a>. Which is nice.</p>

<p>I didn&rsquo;t look THAT much into WebAssembly however, again, after yesterday, I will. He gave a shout out to WebAssembly developers
that he is ready to tackle the Go bindings for WASM!</p>

<p>It was a good change of pace to look at some Go code being written, I&rsquo;ll be sure to visit the meetup again, in about three months
when the next one will come.</p>

<p>Maybe, I&rsquo;ll even give a talk if they are looking for speakers. ;)</p>

<p>A huge thank you to <a href="https://www.emarsys.com/en/about-us/">Emarsys Budapest</a> for organizing the event and bringing Johan to us
for his talk.</p>

<p>Thanks,<br />
Gergely</p>
]]></content>
		</item>
		
		<item>
			<title>Ansible &#43; Nginx &#43; LetsEncrypt &#43; Wiki &#43; Nagios</title>
			<link>https://skarlso.github.io/2018/01/23/nginx-certbot-ansible/</link>
			<pubDate>Tue, 23 Jan 2018 22:34:00 +0100</pubDate>
			
			<guid>https://skarlso.github.io/2018/01/23/nginx-certbot-ansible/</guid>
			<description>Intro Hi folks.
Today, I would like demonstrate how to use Ansible in order to construct a server hosting multiple HTTPS domains with Nginx and LetsEncrypt. Are you ready? Let&amp;rsquo;s dive in.
TL;DR What you will need There is really only one thing you need in order for this to work and that is Ansible. If you would like to run local tests without a remote server, than you will need Vagrant and VirtualBox.</description>
			<content type="html"><![CDATA[

<h1 id="intro">Intro</h1>

<p>Hi folks.</p>

<p>Today, I would like demonstrate how to use <a href="https://www.ansible.com/">Ansible</a> in order to construct a server hosting multiple HTTPS domains with <a href="https://www.nginx.com/">Nginx</a> and <a href="https://letsencrypt.org/">LetsEncrypt</a>. Are you ready? Let&rsquo;s dive in.</p>

<h2 id="tl-dr">TL;DR</h2>

<p><img src="/img/ansible.svg" alt="playbook" /></p>

<h2 id="what-you-will-need">What you will need</h2>

<p>There is really only one thing you need in order for this to work and that is Ansible. If you would like to run local tests without a remote server, than you will need <a href="https://www.vagrantup.com/">Vagrant</a> and <a href="https://www.virtualbox.org/wiki/Downloads">VirtualBox</a>. But those two are optional.</p>

<h2 id="what-we-are-going-to-set-up">What We Are Going To Set Up</h2>

<p>The setup is as follows:</p>

<h3 id="nagios">Nagios</h3>

<p>We are going to have a Nagios with a custom check for pending security updates. That will run under nagios.example.com.</p>

<h3 id="hugo-website">Hugo Website</h3>

<p>The main web site is going to be a basic <a href="https://gohugo.io/">Hugo</a> site. Hugo is a static Go based web site generator. This Blog is run by it.</p>

<p>We are also going to setup <a href="https://www.noip.com/">NoIP</a> which will provide the DNS for the sites.</p>

<h3 id="wiki">Wiki</h3>

<p>The wiki is a plain, basic <a href="https://www.dokuwiki.org/dokuwiki#">DokuWiki</a>.</p>

<h3 id="https-nginx">HTTPS + Nginx</h3>

<p>And all the above will be hosted by Nginx with HTTPS provided by letsencrypt. We are going to set all these up with Ansible on top so it will be idempotent.</p>

<h3 id="repository">Repository</h3>

<p>All of the playbooks and the whole thing together can be viewed here: <a href="https://github.com/Skarlso/ansible-server-setup">Github Ansible Server Setup</a>.</p>

<h2 id="ansible">Ansible</h2>

<p>I won&rsquo;t be writing everything down to the basics about Ansible. For that you will need to go and read its documentation. But I will provide ample of clarification for using what I&rsquo;ll be using.</p>

<h3 id="some-basics">Some Basics</h3>

<p>Ansible is a configuration management tool which, unlike chef or puppet, isn&rsquo;t master - slave based. It&rsquo;s using SSH to run a set of instructions on a target machine. The instructions are written in yaml files and look something like this:</p>
<div class="highlight"><pre class="chroma"><code class="language-yaml" data-lang="yaml">---<span class="w">
</span><span class="w"></span><span class="c"># tasks file for ssh</span><span class="w">
</span><span class="w"></span>-<span class="w"> </span>name<span class="p">:</span><span class="w"> </span>Copy<span class="w"> </span>sshd_config<span class="w">
</span><span class="w">  </span>copy<span class="p">:</span><span class="w"> </span>content=<span class="s2">&#34;{{sshd_config}}&#34;</span><span class="w"> </span>dest=/etc/ssh/sshd_config<span class="w">
</span><span class="w">  </span>notify<span class="p">:</span><span class="w">
</span><span class="w">  </span>-<span class="w"> </span>SSHD<span class="w"> </span>Restart</code></pre></div>
<p>This is a basic Task which copies over an <code>sshd_config</code> file overwriting the one already being there. It can execute in priviliged mode if root password is provided or the user has sudo rights.</p>

<p>It works from so called <code>hosts</code> files where the server details are described. This is how a basic host file would look like:</p>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash"><span class="o">[</span>local<span class="o">]</span>
<span class="m">127</span>.0.0.1

<span class="o">[</span>webserver1<span class="o">]</span>
<span class="m">1</span>.23.4.5</code></pre></div>
<p>Ansible will use these settings to try and access the server. To test if the connection is working, you can send a <code>ping</code> task like this:</p>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash">ansible all -m ping</code></pre></div>
<p>Ansible uses <code>variables</code> for things that change. They are defined under each task&rsquo;s subfolder called <code>vars</code>. Please feel free to change the varialbes there to your liking.</p>

<h3 id="ssh-access">SSH Access</h3>

<p>You can either define SSH information per host or per group or globally. In this example I have it under the groups wars called
<code>webserver1</code> like this (vars.yaml):</p>
<div class="highlight"><pre class="chroma"><code class="language-yaml" data-lang="yaml">---<span class="w">
</span><span class="w"></span><span class="c"># SSH sudo keys and pass</span><span class="w">
</span><span class="w"></span>ansible_become_pass<span class="p">:</span><span class="w"> </span><span class="s1">&#39;{{vault_ansible_become_pass}}&#39;</span><span class="w">
</span><span class="w"></span>ansible_ssh_port<span class="p">:</span><span class="w"> </span><span class="s1">&#39;{{vault_ansible_ssh_port}}&#39;</span><span class="w">
</span><span class="w"></span>ansible_ssh_user<span class="p">:</span><span class="w"> </span><span class="s1">&#39;{{vault_ansible_ssh_user}}&#39;</span><span class="w">
</span><span class="w"></span>ansible_ssh_private_key_file<span class="p">:</span><span class="w"> </span><span class="s1">&#39;{{vault_ansible_ssh_private_key_file}}&#39;</span><span class="w">
</span><span class="w"></span>home_dir<span class="p">:</span><span class="w"> </span>/root</code></pre></div>
<h3 id="further-reading">Further reading</h3>

<p>Further readings are:</p>

<ul>
<li><a href="https://serversforhackers.com/c/an-ansible-tutorial">Servers For Hackers</a></li>
<li><a href="http://docs.ansible.com/ansible/latest/intro_getting_started.html">Ansible docs</a></li>
</ul>

<h3 id="vault">Vault</h3>

<p>The vault is the place where we can keep secure information. This file is called <code>vault</code> and usually lives under either <code>group_vars</code> or <code>host_vars</code>. The preference is up to you.</p>

<p>This file is encrypted using a password you specify. You can have the vault password stored in the following ways:</p>

<ul>
<li>Store it on a secure drive which is encrypted and only mounted when the playbook is executed</li>
<li>Store it on <a href="https://keybase.io">Keybase</a></li>
<li>Store it on an encrypted S3 bucket</li>
<li>Store it in a file next to the playbook which is never commited into source control</li>
</ul>

<p>Either way, in the end, ansible will look for a file called <code>.vault_password</code> for when it&rsquo;s trying to decrypt the file. You can
define a different file in the <code>ansible.cfg</code> file using the <code>vault_password_file</code> option.</p>

<p>You can create a vault like this:</p>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash">ansible-vault create vault</code></pre></div>
<p>If you are following along, you are going to need these variables in the vault:</p>
<div class="highlight"><pre class="chroma"><code class="language-yaml" data-lang="yaml">vault_ansible_become_pass<span class="p">:</span><span class="w"> </span>&lt;your_sudo_password&gt;<span class="w"> </span><span class="c"># if applicable</span><span class="w">
</span><span class="w"></span>vault_ansible_ssh_user<span class="p">:</span><span class="w"> </span>&lt;ssh_user&gt;<span class="w">
</span><span class="w"></span>vault_ansible_ssh_private_key_file<span class="p">:</span><span class="w"> </span>/Users/user/.ssh/ida_rsa<span class="w">
</span><span class="w"></span>vault_nagios_password<span class="p">:</span><span class="w"> </span>supersecurenagiosadminpassword<span class="w">
</span><span class="w"></span>vault_nagios_username<span class="p">:</span><span class="w"> </span>nagiosadmin<span class="w">
</span><span class="w"></span>vault_noip_username<span class="p">:</span><span class="w"> </span>youruser@gmail.com<span class="w">
</span><span class="w"></span>vault_noip_password<span class="p">:</span><span class="w"> </span><span class="s2">&#34;SuperSecureNoIPPassword&#34;</span><span class="w">
</span><span class="w"></span>vault_nginx_user<span class="p">:</span><span class="w"> </span>&lt;localuser&gt;</code></pre></div>
<p>You can always edit the vault later on with:</p>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash">ansible-vault edit group_vars/webserver1/vault --vault-password-file<span class="o">=</span>.vault_pass</code></pre></div>
<h3 id="tasks">Tasks</h3>

<p>The following are a collection of tasks which execute in order. The end task, which is letsencrypt, relies on all the hosts being present and configured under Nginx. Otherwise it will throw an error that the host you are trying to configure HTTPS for, isn&rsquo;t defined.</p>

<h4 id="no-ip">No-IP</h4>

<p>I&rsquo;m choosing No-ip as a DNS provider because it&rsquo;s cheap and the sync tool is easy to automate. To automate the CLI of No-IP, I&rsquo;m using a package called <code>expect</code>. This looks something like this:</p>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash"><span class="nb">cd</span> <span class="o">{{</span>home_dir<span class="o">}}</span>
wget http://www.no-ip.com/client/linux/noip-duc-linux.tar.gz
mkdir -p noip
tar zxf noip-duc-linux.tar.gz -C noip
<span class="nb">cd</span> noip/*
make

/usr/bin/expect <span class="s">&lt;&lt;END_SCRIPT
</span><span class="s">spawn make install
</span><span class="s">expect &#34;Please enter the login/email*&#34; { send &#34;{{noip_username}}\r&#34; }
</span><span class="s">expect &#34;Please enter the password for user*&#34; { send &#34;{{noip_password}}\r&#34; }
</span><span class="s">expect {
</span><span class="s">    &#34;Do you wish to have them all updated*&#34; {
</span><span class="s">        send &#34;y&#34;
</span><span class="s">        exp_continue
</span><span class="s">    }
</span><span class="s">}
</span><span class="s">expect &#34;Please enter an update interval*&#34; { send &#34;30\r&#34; }
</span><span class="s">expect &#34;Do you wish to run something at successful update*&#34; {send &#34;N&#34; }
</span><span class="s">END_SCRIPT</span></code></pre></div>
<p>The interesting part is the command running expect. Basically, it&rsquo;s expecting some kind of output which is outlined there. And has canned answers for those which it <code>send</code>s to the waiting command.</p>

<h4 id="to-util-or-not-to-util">To Util or Not To Util</h4>

<p>So, there are small tasks, like installing vim and wget and such which could warrant the existance of a <code>utils</code> task. Utils task would install the packages that are used as convinience and don&rsquo;t really relate to a singe task.</p>

<p>Yet I settled for the following. Each of my tasks has a dependency part. The given tasks takes care of all the packages it needs so they can be executed on their own as well as in unison.</p>

<p>This looks like this:</p>
<div class="highlight"><pre class="chroma"><code class="language-yaml" data-lang="yaml"><span class="c"># Install dependencies</span><span class="w">
</span><span class="w"></span>-<span class="w"> </span>name<span class="p">:</span><span class="w"> </span>Install<span class="w"> </span>dependencies<span class="w">
</span><span class="w">  </span>apt<span class="p">:</span><span class="w"> </span>pkg=<span class="s2">&#34;{{item}}&#34;</span><span class="w"> </span>state=installed<span class="w">
</span><span class="w">  </span>with_items<span class="p">:</span><span class="w">
</span><span class="w">    </span>-<span class="w"> </span><span class="s2">&#34;{{deps}}&#34;</span></code></pre></div>
<p>For which the <code>deps</code> variable is defined as follows:</p>
<div class="highlight"><pre class="chroma"><code class="language-yaml" data-lang="yaml"><span class="c"># Defined dependencies for letsencrypt task.</span><span class="w">
</span><span class="w"></span>deps<span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="s1">&#39;git&#39;</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;python-dev&#39;</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;build-essential&#39;</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;libpython-dev&#39;</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;libpython2.7&#39;</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;augeas-lenses&#39;</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;libaugeas0&#39;</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;libffi-dev&#39;</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;libssl-dev&#39;</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;python-virtualenv&#39;</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;python3-virtualenv&#39;</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;virtualenv&#39;</span><span class="p">]</span></code></pre></div>
<p>This is much cleaner. And if a task is no longer needed, it&rsquo;s dependencies will no longer be needed either in most of the cases.</p>

<h4 id="nagios-1">Nagios</h4>

<p>I&rsquo;m using Nagios 4 which is a real pain in the butt to install. Luckily, thanks to Ansiblei, I only ever had to figure it out once. Now I have a script for that. Installing Nagios demands several, smaller components to be installed. Thus our task uses import from outside tasks like this:</p>
<div class="highlight"><pre class="chroma"><code class="language-yaml" data-lang="yaml">-<span class="w"> </span>name<span class="p">:</span><span class="w"> </span>Install<span class="w"> </span>Nagios<span class="w">
</span><span class="w">  </span>block<span class="p">:</span><span class="w">
</span><span class="w">    </span>-<span class="w"> </span>include<span class="p">:</span><span class="w"> </span>create_users.yml<span class="w"> </span><span class="c"># creates the Nagios user</span><span class="w">
</span><span class="w">    </span>-<span class="w"> </span>include<span class="p">:</span><span class="w"> </span>install_dependencies.yml<span class="w"> </span><span class="c"># installs Nagios dependencies</span><span class="w">
</span><span class="w">    </span>-<span class="w"> </span>include<span class="p">:</span><span class="w"> </span>core_install.yml<span class="w"> </span><span class="c"># Installs Nagios Core</span><span class="w">
</span><span class="w">    </span>-<span class="w"> </span>include<span class="p">:</span><span class="w"> </span>plugin_install.yml<span class="w"> </span><span class="c"># Installs Nagios Plugins</span><span class="w">
</span><span class="w">    </span>-<span class="w"> </span>include<span class="p">:</span><span class="w"> </span>create_htpasswd.yml<span class="w"> </span><span class="c"># Creates a password for Nagios&#39; admin user</span><span class="w">
</span><span class="w">    </span>-<span class="w"> </span>include<span class="p">:</span><span class="w"> </span>setup_custom_check.yml<span class="w"> </span><span class="c"># Adds a custom check which is to check how many security updates are pending</span><span class="w">
</span><span class="w">  </span>when<span class="p">:</span><span class="w"> </span>st.stat.exists<span class="w"> </span>==<span class="w"> </span>False</code></pre></div>
<p>The <code>when</code> is a check for a variable created by a file check.</p>
<div class="highlight"><pre class="chroma"><code class="language-yaml" data-lang="yaml">-<span class="w"> </span>stat<span class="p">:</span><span class="w">
</span><span class="w">    </span>path<span class="p">:</span><span class="w"> </span>/usr/local/nagios/bin/nagios<span class="w">
</span><span class="w">  </span>register<span class="p">:</span><span class="w"> </span>st</code></pre></div>
<p>It checks if Nagios is installed or not. If yes, skip.</p>

<p>I&rsquo;m not going to paste in here all the subtasks because that would be huge. You can check those out in the repository under Nagios.</p>

<h4 id="hugo">Hugo</h4>

<p>Hugo is easy to install. Its sole requirement is Go. To install hugo you simply run <code>apt-get install hugo</code>. Setting up the
site for me was just checking out the git repo and than execute hugo from the root folder like this:</p>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash">hugo server --bind<span class="o">=</span><span class="m">127</span>.0.0.1 --port<span class="o">=</span><span class="m">8080</span> --baseUrl<span class="o">=</span>https://example.com --appendPort<span class="o">=</span><span class="nb">false</span> --logFile hugo.log --verboseLog --verbose -v <span class="p">&amp;</span></code></pre></div>
<h4 id="wiki-1">Wiki</h4>

<p>I used DokuWiki because it&rsquo;s a file based wiki so installation is basically just downloading the archive, extracting it and done. The only thing that&rsquo;s needed for it, is php-fpm to run it and a few php modules which I&rsquo;ll outline in the ansible playbook.</p>

<p>The VHOST file for DokuWiki is provided by them and looks like this:</p>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash">server <span class="o">{</span>
    server_name   <span class="o">{{</span> wiki_server_name <span class="o">}}</span><span class="p">;</span>
    root <span class="o">{{</span> wiki_root <span class="o">}}</span><span class="p">;</span>
    index index.php index.html index.htm<span class="p">;</span>
    client_max_body_size 2M<span class="p">;</span>
    client_body_buffer_size 128k<span class="p">;</span>
    location / <span class="o">{</span>
        index doku.php<span class="p">;</span>
        try_files <span class="nv">$uri</span> <span class="nv">$uri</span>/ @dokuwiki<span class="p">;</span>
    <span class="o">}</span>
    location @dokuwiki <span class="o">{</span>
        rewrite ^/_media/<span class="o">(</span>.*<span class="o">)</span> /lib/exe/fetch.php?media<span class="o">=</span><span class="nv">$1</span> last<span class="p">;</span>
        rewrite ^/_detail/<span class="o">(</span>.*<span class="o">)</span> /lib/exe/detail.php?media<span class="o">=</span><span class="nv">$1</span> last<span class="p">;</span>
        rewrite ^/_export/<span class="o">([</span>^/<span class="o">]</span>+<span class="o">)</span>/<span class="o">(</span>.*<span class="o">)</span> /doku.php?do<span class="o">=</span>export_<span class="nv">$1</span><span class="p">&amp;</span><span class="nv">id</span><span class="o">=</span><span class="nv">$2</span> last<span class="p">;</span>
        rewrite ^/<span class="o">(</span>.*<span class="o">)</span> /doku.php?id<span class="o">=</span><span class="nv">$1</span> last<span class="p">;</span>
    <span class="o">}</span>
    location ~ <span class="se">\.</span>php$ <span class="o">{</span>
        try_files <span class="nv">$uri</span> <span class="o">=</span><span class="m">404</span><span class="p">;</span>
        fastcgi_pass unix:/var/run/php5-fpm.sock<span class="p">;</span>
        fastcgi_index index.php<span class="p">;</span>
        fastcgi_param SCRIPT_FILENAME <span class="nv">$document_root$fastcgi_script_name</span><span class="p">;</span>
        include fastcgi_params<span class="p">;</span>
    <span class="o">}</span>
    location ~ /<span class="se">\.</span>ht <span class="o">{</span>
        deny all<span class="p">;</span>
    <span class="o">}</span>
    location ~ /<span class="o">(</span>data<span class="p">|</span>conf<span class="p">|</span>bin<span class="p">|</span>inc<span class="o">)</span>/ <span class="o">{</span>
        deny all<span class="p">;</span>
    <span class="o">}</span>
<span class="o">}</span></code></pre></div>
<h4 id="nginx">Nginx</h4>

<p>Nginx install is through apt as well. Here, however, there is a bit of magic going on with templates. The templates provide the
vhost files for the three hosts we will be running. This looks as follows:</p>
<div class="highlight"><pre class="chroma"><code class="language-yaml" data-lang="yaml">-<span class="w"> </span>name<span class="p">:</span><span class="w"> </span>Install<span class="w"> </span>vhosts<span class="w">
</span><span class="w">  </span>block<span class="p">:</span><span class="w">
</span><span class="w">    </span>-<span class="w"> </span>template<span class="p">:</span><span class="w"> </span>src=01_example.com.j2<span class="w"> </span>dest=/etc/nginx/vhosts/01_example.com<span class="w">
</span><span class="w">      </span>notify<span class="p">:</span><span class="w">
</span><span class="w">      </span>-<span class="w"> </span>Restart<span class="w"> </span>Nginx<span class="w">
</span><span class="w">    </span>-<span class="w"> </span>template<span class="p">:</span><span class="w"> </span>src=02_wiki.example.com.j2<span class="w"> </span>dest=/etc/nginx/vhosts/02_wiki_example.com<span class="w">
</span><span class="w">      </span>notify<span class="p">:</span><span class="w">
</span><span class="w">      </span>-<span class="w"> </span>Restart<span class="w"> </span>Nginx<span class="w">
</span><span class="w">    </span>-<span class="w"> </span>template<span class="p">:</span><span class="w"> </span>src=03_nagios.example.com.j2<span class="w"> </span>dest=/etc/nginx/vhosts/03_nagios.example.com<span class="w">
</span><span class="w">      </span>notify<span class="p">:</span><span class="w">
</span><span class="w">      </span>-<span class="w"> </span>Restart<span class="w"> </span>Nginx</code></pre></div>
<p>Now, you might be wondering what <code>notify</code> is? It&rsquo;s basically a handler that gets notified to restart nginx. The great part about
it is that it does this only once, even if it was called multiple times. The handler looks like this:</p>
<div class="highlight"><pre class="chroma"><code class="language-yaml" data-lang="yaml">-<span class="w"> </span>name<span class="p">:</span><span class="w"> </span>Restart<span class="w"> </span>Nginx<span class="w">
</span><span class="w">  </span>service<span class="p">:</span><span class="w">
</span><span class="w">    </span>name<span class="p">:</span><span class="w"> </span>nginx<span class="w">
</span><span class="w">    </span>state<span class="p">:</span><span class="w"> </span>restarted</code></pre></div>
<p>And lives under <code>handlers</code> sub-folder.</p>

<p>With this, Nginx is done and should be providing our sites under plain HTTP.</p>

<h4 id="letsencrypt">LetsEncrypt</h4>

<p>Now comes the part where we enable HTTPS for all these three domains. Which is as follows:</p>

<ul>
<li>example.com</li>
<li>wiki.example.com</li>
<li>nagios.example.com</li>
</ul>

<p>This is actually quiet simple now-a-days with <code>certbot-auto</code>. In fact, it will insert the configurations we need all by itself.
The only thing for us to do is to specify what domains we have and what our challenge would be. Also, we have to pass in some
variables for <code>certbot-auto</code> to run in a non-interactive mode. This looks as follows:</p>
<div class="highlight"><pre class="chroma"><code class="language-yaml" data-lang="yaml">-<span class="w"> </span>name<span class="p">:</span><span class="w"> </span>Generate<span class="w"> </span>Certificate<span class="w"> </span>for<span class="w"> </span>Domains<span class="w">
</span><span class="w">  </span>shell<span class="p">:</span><span class="w"> </span>./certbot-auto<span class="w"> </span>--authenticator<span class="w"> </span>standalone<span class="w"> </span>--installer<span class="w"> </span>nginx<span class="w"> </span>-d<span class="w"> </span><span class="s1">&#39;{{ domain_example }}&#39;</span><span class="w"> </span>-d<span class="w"> </span><span class="s1">&#39;{{ domain_wiki }}&#39;</span><span class="w"> </span>-d<span class="w"> </span><span class="s1">&#39;{{ domain_nagios }}&#39;</span><span class="w"> </span>--email<span class="w"> </span>example@gmail.com<span class="w"> </span>--agree-tos<span class="w"> </span>-n<span class="w"> </span>--no-verify-ssl<span class="w"> </span>--pre-hook<span class="w"> </span><span class="s2">&#34;sudo systemctl stop nginx&#34;</span><span class="w"> </span>--post-hook<span class="w"> </span><span class="s2">&#34;sudo systemctl start nginx&#34;</span><span class="w"> </span>--redirect<span class="w">
</span><span class="w">  </span>args<span class="p">:</span><span class="w">
</span><span class="w">    </span>chdir<span class="p">:</span><span class="w"> </span>/opt/letsencrypt</code></pre></div>
<p>And that&rsquo;s that. The interesting and required part here is the <code>pre-hook</code> and <code>post-hook</code>. Without those it wouldn&rsquo;t work because
the ports that certbot is performing the challenge on would be taken already. This stops nginx, performs the challenge and
generates the certs, and starts nginx again. Also note <code>--redirect</code>. This will force HTTPS on the sites and disables plain HTTP.</p>

<p>If all went well our sites should contain information like this:</p>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash">    listen <span class="m">443</span> ssl<span class="p">;</span> <span class="c1"># managed by Certbot</span>
    ssl_certificate /etc/letsencrypt/live/example.com-0001/fullchain.pem<span class="p">;</span> <span class="c1"># managed by Certbot</span>
    ssl_certificate_key /etc/letsencrypt/live/example.com-0001/privkey.pem<span class="p">;</span> <span class="c1"># managed by Certbot</span>
    include /etc/letsencrypt/options-ssl-nginx.conf<span class="p">;</span> <span class="c1"># managed by Certbot</span>
    ssl_dhparam /etc/letsencrypt/ssl-dhparams.pem<span class="p">;</span> <span class="c1"># managed by Certbot</span></code></pre></div>
<h3 id="test-run-using-vagrant">Test Run using Vagrant</h3>

<p>If you don&rsquo;t want to run all this on a live server to test out, you can do either of these two things:</p>

<ul>
<li>Use a remote dedicated test server</li>
<li>Use a local virtual machine with Vagrant</li>
</ul>

<p>Here, I&rsquo;m giving you an option for the later.</p>

<p>It&rsquo;s possible for most of the things to be tested on a local Vagrant machine. Most of the time a Vagrant box is enough to test out installing things. A sample Vagrant file looks like this:</p>
<div class="highlight"><pre class="chroma"><code class="language-ruby" data-lang="ruby"><span class="c1"># encoding: utf-8</span>
<span class="c1"># -*- mode: ruby -*-</span>
<span class="c1"># vi: set ft=ruby :</span>
<span class="c1"># Box / OS</span>
<span class="no">VAGRANT_BOX</span> <span class="o">=</span> <span class="s1">&#39;ubuntu/xenial64&#39;</span>

<span class="no">VM_NAME</span> <span class="o">=</span> <span class="s1">&#39;ansible-practice&#39;</span>

<span class="no">Vagrant</span><span class="o">.</span><span class="n">configure</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="k">do</span> <span class="o">|</span><span class="n">config</span><span class="o">|</span>
  <span class="c1"># Vagrant box from Hashicorp</span>
  <span class="n">config</span><span class="o">.</span><span class="n">vm</span><span class="o">.</span><span class="n">box</span> <span class="o">=</span> <span class="no">VAGRANT_BOX</span>
  <span class="c1"># Actual machine name</span>
  <span class="n">config</span><span class="o">.</span><span class="n">vm</span><span class="o">.</span><span class="n">hostname</span> <span class="o">=</span> <span class="no">VM_NAME</span>
  <span class="c1"># Set VM name in Virtualbox</span>
  <span class="n">config</span><span class="o">.</span><span class="n">vm</span><span class="o">.</span><span class="n">provider</span> <span class="s1">&#39;virtualbox&#39;</span> <span class="k">do</span> <span class="o">|</span><span class="n">v</span><span class="o">|</span>
    <span class="n">v</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="no">VM_NAME</span>
    <span class="n">v</span><span class="o">.</span><span class="n">memory</span> <span class="o">=</span> <span class="mi">2048</span>
  <span class="k">end</span>
  <span class="c1"># Ansible provision</span>
  <span class="n">config</span><span class="o">.</span><span class="n">vm</span><span class="o">.</span><span class="n">provision</span> <span class="s1">&#39;ansible_local&#39;</span> <span class="k">do</span> <span class="o">|</span><span class="n">ansible</span><span class="o">|</span>
    <span class="n">ansible</span><span class="o">.</span><span class="n">limit</span> <span class="o">=</span> <span class="s1">&#39;all&#39;</span>
    <span class="n">ansible</span><span class="o">.</span><span class="n">inventory_path</span> <span class="o">=</span> <span class="s1">&#39;hosts&#39;</span>
    <span class="n">ansible</span><span class="o">.</span><span class="n">playbook</span> <span class="o">=</span> <span class="s1">&#39;local.yml&#39;</span>
  <span class="k">end</span>
<span class="k">end</span></code></pre></div>
<p>This interesting part here is the ansible provision section. It&rsquo;s running a version of Ansible that is called <code>ansible_local</code>. It&rsquo;s local, becuase it will be only on the VirtualBox. Meaning, you don&rsquo;t have to have Ansible installed to test it on a vagrant box. Neat, huh?</p>

<p>To test your playbook, simply run <code>vagrant up</code> and you should see the provisioning happening.</p>

<h2 id="room-for-improvement">Room for improvement</h2>

<p>And that should be all. Note that this setup isn&rsquo;t quiet enterprise ready. I would add the following things:</p>

<h3 id="tests-and-checks">Tests and Checks</h3>

<p>A ton of tests and checks if the commands that we are using are actually successful or not. If they aren&rsquo;t make them report the failure.</p>

<h3 id="multiple-domains">Multiple Domains</h3>

<p>If you happen to have a ton of domain names to set up, this will not be the most effective way. Right now letsencrypt creates a
single certificate file for those three domains with <code>-d</code> and that&rsquo;s not what you want with potentially hundreds of domains.</p>

<p>In that case, have a list to go through with <code>with_items</code>. Note that you&rsquo;ll have to restart nginx on each line, because you don&rsquo;t
want one of them fail and stop the process entirely. Rather have a few fail but the rest still work.</p>

<h1 id="conclusion">Conclusion</h1>

<p>That&rsquo;s it folks. Have fun setting up servers all over the place and enjoy the power of nginx and letsencrypt and not having to
worry about adding another server into the bunch.</p>

<p>Thank you for reading,
Gergely.</p>
]]></content>
		</item>
		
		<item>
			<title>Huge Furnace Update</title>
			<link>https://skarlso.github.io/2018/01/13/furnace-massive-update/</link>
			<pubDate>Sat, 13 Jan 2018 22:34:00 +0100</pubDate>
			
			<guid>https://skarlso.github.io/2018/01/13/furnace-massive-update/</guid>
			<description>Intro Hi folks.
In the past couple of months I&amp;rsquo;ve been slowly updating Furnace.
There are three major changes that happened. Let&amp;rsquo;s take a look at them, shall we?
Google Cloud Platform Furnace now supports Google Cloud Platform (GCP). It provides the same API to handle GCP resource as with AWS. Namely, create, delete, status, update. I opted to leave out push because Google mostly works with git based repositories, meaning a push is literary just a push, than Google handles distributing the new code by itself.</description>
			<content type="html"><![CDATA[

<h1 id="intro">Intro</h1>

<p>Hi folks.</p>

<p>In the past couple of months I&rsquo;ve been slowly updating <a href="https://github.com/Skarlso/go-furnace">Furnace</a>.</p>

<p>There are three major changes that happened. Let&rsquo;s take a look at them, shall we?</p>

<h2 id="google-cloud-platform">Google Cloud Platform</h2>

<p>Furnace now supports <a href="https://cloud.google.com">Google Cloud Platform (GCP)</a>. It provides the same API to handle GCP resource as with AWS. Namely, <code>create</code>, <code>delete</code>, <code>status</code>, <code>update</code>. I opted to leave out <code>push</code> because Google mostly works with git based repositories, meaning a push is literary just a push, than Google handles distributing the new code by itself.</p>

<p>All the rest of the commands should work the same way as AWS.</p>

<h3 id="deployment-manager">Deployment Manager</h3>

<p>GCP has a similar service to AWS CloudFormations called <a href="https://cloud.google.com/deployment-manager/docs/">Deployment Manager</a>. The documentation is fairly detailed with a Bookshelf example app to deploy. Code and Templates can be found in their Git repositroy here: <a href="https://github.com/GoogleCloudPlatform/deploymentmanager-samples">Deployment Manager Git Repository</a>.</p>

<h3 id="setting-up-gcp">Setting up GCP</h3>

<p>As the README of Furnace outlines&hellip;</p>

<blockquote>
<p>Please carefully read and follow the instruction outlined in this document: <a href="https://cloud.google.com/sdk/#Quick_Start">Google Cloud Getting Started</a>. It will describe how to download and install the SDK and initialize cloud to a Project ID.</p>

<p>Take special attention to these documents:</p>

<p><a href="https://cloud.google.com/sdk/docs/initializing">Initializing GCloud Tools</a>
<a href="https://cloud.google.com/sdk/docs/authorizing">Authorizing Tools</a></p>

<p>Furnace uses a Google Key-File to authenticate with your Google Cloud Account and Project.
In the future, Furnace assumes these things are properly set up and in working order.</p>
</blockquote>

<p>To initialize the client, it uses the following code:</p>
<div class="highlight"><pre class="chroma"><code class="language-go" data-lang="go">  <span class="nx">ctx</span> <span class="o">:=</span> <span class="nx">context</span><span class="p">.</span><span class="nf">Background</span><span class="p">()</span>
  <span class="nx">client</span><span class="p">,</span> <span class="nx">err</span> <span class="o">:=</span> <span class="nx">google</span><span class="p">.</span><span class="nf">DefaultClient</span><span class="p">(</span><span class="nx">ctx</span><span class="p">,</span> <span class="nx">dm</span><span class="p">.</span><span class="nx">NdevCloudmanScope</span><span class="p">)</span></code></pre></div>
<p>The DefaultClient in turn, does the following:</p>
<div class="highlight"><pre class="chroma"><code class="language-go" data-lang="go"><span class="c1">// FindDefaultCredentials searches for &#34;Application Default Credentials&#34;.
</span><span class="c1">//
</span><span class="c1">// It looks for credentials in the following places,
</span><span class="c1">// preferring the first location found:
</span><span class="c1">//
</span><span class="c1">//   1. A JSON file whose path is specified by the
</span><span class="c1">//      GOOGLE_APPLICATION_CREDENTIALS environment variable.
</span><span class="c1">//   2. A JSON file in a location known to the gcloud command-line tool.
</span><span class="c1">//      On Windows, this is %APPDATA%/gcloud/application_default_credentials.json.
</span><span class="c1">//      On other systems, $HOME/.config/gcloud/application_default_credentials.json.
</span><span class="c1">//   3. On Google App Engine it uses the appengine.AccessToken function.
</span><span class="c1">//   4. On Google Compute Engine and Google App Engine Managed VMs, it fetches
</span><span class="c1">//      credentials from the metadata server.
</span><span class="c1">//      (In this final case any provided scopes are ignored.)
</span><span class="c1"></span><span class="kd">func</span> <span class="nf">FindDefaultCredentials</span><span class="p">(</span><span class="nx">ctx</span> <span class="nx">context</span><span class="p">.</span><span class="nx">Context</span><span class="p">,</span> <span class="nx">scope</span> <span class="o">...</span><span class="kt">string</span><span class="p">)</span> <span class="p">(</span><span class="o">*</span><span class="nx">DefaultCredentials</span><span class="p">,</span> <span class="kt">error</span><span class="p">)</span> <span class="p">{</span></code></pre></div>
<p>Take note on the order. This is how Google will authenticate your requests.</p>

<h3 id="running-gcp">Running GCP</h3>

<p>Running gcp is largely similar to AWS. First, you create the necessary templates to your infrastructure. This is done via the Deployment Manager and it&rsquo;s templating engine. The GCP templates are Python <a href="http://jinja.pocoo.org/">JINJA</a> files. Examples are provided in the <code>template</code> directory. It&rsquo;s a bit more complicated than the CloudFormation templates in that it uses outside templates plus schema files to configure dynamic details.</p>

<p>It&rsquo;s all explained in these documents: <a href="https://cloud.google.com/deployment-manager/docs/step-by-step-guide/create-a-template">Creating a Template Step-by-step</a> and <a href="https://cloud.google.com/deployment-manager/docs/configuration/templates/create-basic-template">Creating a Basic Template</a>.</p>

<p>It&rsquo;s not trivial however. And using the API can also be confusing. The Google Code is just a generated Go code file using gRPC. But studying it may provide valuable insigth into how the API is structured. I&rsquo;m also providing some basic samples that I gathered together and the readme does a bit more explaining on how to use them.</p>

<h3 id="your-first-stack">Your First Stack</h3>

<p>Once you have everything set-up you&rsquo;ll need a configuration file for Furnace. The usage is outlined more here <a href="#YAML-Configuration">YAML Configuration</a>. The configuration file for GCP looks like this:</p>
<div class="highlight"><pre class="chroma"><code class="language-yaml" data-lang="yaml">main<span class="p">:</span><span class="w">
</span><span class="w">  </span>project_name<span class="p">:</span><span class="w"> </span>testplatform-<span class="m">1234</span><span class="w">
</span><span class="w">  </span>spinner<span class="p">:</span><span class="w"> </span><span class="m">1</span><span class="w">
</span><span class="w"></span>gcp<span class="p">:</span><span class="w">
</span><span class="w">  </span>template_name<span class="p">:</span><span class="w"> </span>google_template.yaml<span class="w">
</span><span class="w">  </span>stack_name<span class="p">:</span><span class="w"> </span>test-stack</code></pre></div>
<p>Where <code>project_name</code> is the name you generate for your first billable Google Cloud Platform project. Template lives next to this yaml file and stack name must be DNS complient.</p>

<p>Once you have a project and a template setup, it&rsquo;s as simple as calling <code>./furnace-gcp create</code> or <code>./furnace-gcp create mycustomstack</code>.</p>

<h3 id="deleting">Deleting</h3>

<p>Deleting happens with <code>./furnace-gcp delete</code> or <code>./furnace-gcp delete mycustomstack</code>. Luckily, as with AWS, this means that every resource created with the DeploymentManager will be deleted leaving no need for search and cleanup.</p>

<h3 id="project-name-vs-project-id">Project Name vs. Project ID</h3>

<p>Unlike with AWS Google requires your stack name and project id to be DNS complient. This is most likely because all API calls and such contain that information.</p>

<h2 id="separate-binaries">Separate Binaries</h2>

<p>In order to mitigate some of Furnace&rsquo;s size, I&rsquo;m providing separate binaries for each service it supports.</p>

<p>The AWS binaries can be found in <code>aws</code> folder, and respectively, the Google Cloud Platform is located in <code>gcp</code>. Both are build-able by running <code>make</code>.</p>

<p>If you would like to run both with a single command, a top level make file is provided for your convinience. Just run <code>make</code> from the root. That will build all binaries. Later on, Digital Oceans will join the ranks.</p>

<h2 id="yaml-configuration">YAML Configuration</h2>

<p>Last but not least, Furnace now employs YAML files for configuration. However, it isn&rsquo;t JUST using YAML files. It also employs a smart configuration pattern which works as follows.</p>

<p>Since Furnace is a distributed binary file which could be running from any given location at any time. Because of that, at first I opted for a global configuration directory.</p>

<p>Now, however, furnace uses a furnace configuration file named with the following pattern: <code>.stackalias.furnace</code>. Where stackname, or stack is the name of a custom stack you would like to create for a project. The content of this file is a single entry, which is the location, relative to this file, of the YAML configuration files for the given stack. For example:</p>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash">stacks/mydatabasestack.yaml</code></pre></div>
<p>This means, that in the directory called <code>stacks</code> there will a yaml configuration file for your database stack. The AWS config file looks like this:</p>
<div class="highlight"><pre class="chroma"><code class="language-YAML" data-lang="YAML">main<span class="p">:</span><span class="w">
</span><span class="w">  </span>stackname<span class="p">:</span><span class="w"> </span>FurnaceStack<span class="w">
</span><span class="w">  </span>spinner<span class="p">:</span><span class="w"> </span><span class="m">1</span><span class="w">
</span><span class="w"></span>aws<span class="p">:</span><span class="w">
</span><span class="w">  </span>code_deploy_role<span class="p">:</span><span class="w"> </span>CodeDeployServiceRole<span class="w">
</span><span class="w">  </span>region<span class="p">:</span><span class="w"> </span>us-east-<span class="m">1</span><span class="w">
</span><span class="w">  </span>enable_plugin_system<span class="p">:</span><span class="w"> </span><span class="kc">false</span><span class="w">
</span><span class="w">  </span>template_name<span class="p">:</span><span class="w"> </span>cloud_formation.template<span class="w">
</span><span class="w">  </span>app_name<span class="p">:</span><span class="w"> </span>furnace_app<span class="w">
</span><span class="w">  </span>code_deploy<span class="p">:</span><span class="w">
</span><span class="w">    </span><span class="c"># Only needed in case S3 is used for code deployment</span><span class="w">
</span><span class="w">    </span>code_deploy_s3_bucket<span class="p">:</span><span class="w"> </span>furnace_code_bucket<span class="w">
</span><span class="w">    </span><span class="c"># The name of the zip file in case it&#39;s on a bucket</span><span class="w">
</span><span class="w">    </span>code_deploy_s3_key<span class="p">:</span><span class="w"> </span>furnace_deploy_app<span class="w">
</span><span class="w">    </span><span class="c"># In case a Git Repository is used for the application, define these two settings</span><span class="w">
</span><span class="w">    </span>git_account<span class="p">:</span><span class="w"> </span>Skarlso/furnace-codedeploy-app<span class="w">
</span><span class="w">    </span>git_revision<span class="p">:</span><span class="w"> </span>b89451234...</code></pre></div>
<p>The important part is the <code>template_name</code>. The template has to be next to this yaml file. To use this file, you simply call any of the AWS or GCP commands with an extra, optional parameter like this:</p>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash">./furnace-aws create mydatabase</code></pre></div>
<p>Note that mydatabase will translate to <code>.mydatabase.furnace</code>.</p>

<p>The intelligent part is, that this file could be placed anywhere in the project folder structure; because furnace, when looking for a config file, traverses backwards from the current execution directory up until <code>/</code>. Where root is not included in the search.</p>

<p>Consider the following directory tree:</p>

<p>├── docs<br />
│   ├── <code>furnace-aws status mydatabase</code><br />
├── stacks<br />
│   ├── mystack.template<br />
│   └── mystack.yaml<br />
└── .mydatabase.furnace</p>

<p>You are currently in your <code>docs</code> directory and would like to ask for the status of your database. You don&rsquo;t have to move to the location of the setting file, just simply run the command from where you are. This only works if you are above the location of the file. If you would be below, furnace would say it can&rsquo;t find the file. Because it only traverses upwards.</p>

<p><code>.mydatabase.furnace</code> here contains only a single entry <code>stacks/mystack.yaml</code>. And that&rsquo;s it. This way, you could have multiple furnace files, for example a <code>.database.furnace</code>, <code>.front-end.furnace</code> and a <code>.backend.furnace</code>. All three would work in unison, and if want needs updating, simply run <code>./furnace-aws update backend</code>. And done!</p>

<h1 id="closing-words">Closing words</h1>

<p>As always, contributions are welcomed in the form of issues or pull requests. Questions anything, I tend to answer as soon as I can.</p>

<p>Always run the tests before submitting.</p>

<p>Thank you for reading.
Gergely.</p>
]]></content>
		</item>
		
		<item>
			<title>Commit-Build-Deploy With AWS CodeBuild and Lambda</title>
			<link>https://skarlso.github.io/2017/12/04/commit-build-deploy/</link>
			<pubDate>Mon, 04 Dec 2017 22:34:00 +0100</pubDate>
			
			<guid>https://skarlso.github.io/2017/12/04/commit-build-deploy/</guid>
			<description>Intro Hi All.
Today I would like to write about an AWS finger practice.
Previously, I wrote about how I build and deploy my blog with Wercker. Since, I&amp;rsquo;m a cloud engineer and I dislike Oracle and it&amp;rsquo;s ever expending tenctacles into the abyss, I wanted to switch to use something else.
My build and deploy cycle is simple.
Commit to Blogsource Repo -&amp;gt; Wercker WebHook -&amp;gt; Builds my blog using Hugo -&amp;gt; Pushed to a Different Repository which my Github Blog.</description>
			<content type="html"><![CDATA[

<h1 id="intro">Intro</h1>

<p>Hi All.</p>

<p>Today I would like to write about an AWS finger practice.</p>

<p>Previously, I wrote about how I build and deploy my blog with <a href="www.wercker.com">Wercker</a>. Since, I&rsquo;m a cloud engineer and I dislike Oracle and it&rsquo;s ever expending tenctacles into the abyss, I wanted to switch to use something else.</p>

<p>My build and deploy cycle is simple.</p>

<p>Commit to Blogsource Repo -&gt; Wercker WebHook -&gt; Builds my blog using Hugo -&gt; Pushed to a Different Repository which my Github Blog.</p>

<p>That&rsquo;s all.</p>

<p>It&rsquo;s quiet possible to reproduce this on AWS without infering costs. Unless you publish like&hellip; a couple 100 posts / week.</p>

<p>I&rsquo;m going to use the following services: <a href="https://aws.amazon.com/cloudformation/">CloudFormation</a>, <a href="https://aws.amazon.com/lambda/details/">AWS Lambda</a>, <a href="https://aws.amazon.com/codebuild/">CodeBuild</a>, <a href="https://aws.amazon.com/s3/">S3</a>.</p>

<p>To deploy the below describe architecture in your account in us-east-1 region simply click this button:
<a href="https://console.aws.amazon.com/cloudformation/home?region=us-east-1#/stacks/new?stackName=blogbuilder&amp;templateURL=https://s3.amazonaws.com/blog-builder-template-bucket/template.yaml"><img src="/img/cloudformation-launch-stack.png" alt="Launch Stack" /></a></p>

<p>BEFORE doing that though you need the following created:</p>

<p>Have a bucket for your lambda function. The lambda function can be found here:</p>

<p><a href="https://github.com/Skarlso/aws-lambda-code-pusher">Lambda Repository</a>.</p>

<p>Zip up the lambda folder contents by doing this:</p>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash"><span class="nb">cd</span> lambda
zip -r gitpusher.zip *
aws s3 cp gitpusher.zip s3://your-lambda-bucket</code></pre></div>
<p>That&rsquo;s it.</p>

<p>To read a description of the stack, please continue.</p>

<h1 id="tl-dr">TL;DR;</h1>

<p>The architecture I&rsquo;m about to lay out is simple in its use and design. I tried not to complicate things, because I think the simpler something is, the less prone to failure it will be.</p>

<p>In its most basic form the flow is as follows:</p>

<p><img src="/img/blog_builder_flow.png" alt="Flow" />.</p>

<p>You push something into a repository you provide. CodeBuild has a webhook to this repository so on each commit it starts to build the blog. The build will use a so called <code>buildspec.yaml</code> file which describes how your blog should be built. Mine looks like this:</p>
<div class="highlight"><pre class="chroma"><code class="language-yaml" data-lang="yaml">version<span class="p">:</span><span class="w"> </span><span class="m">0.2</span><span class="w">
</span><span class="w">
</span><span class="w"></span>phases<span class="p">:</span><span class="w">
</span><span class="w">  </span>install<span class="p">:</span><span class="w">
</span><span class="w">    </span>commands<span class="p">:</span><span class="w">
</span><span class="w">      </span>-<span class="w"> </span>echo<span class="w"> </span>Installing<span class="w"> </span>required<span class="w"> </span>packages<span class="w"> </span>and<span class="w"> </span>Hugo<span class="w">
</span><span class="w">      </span>-<span class="w"> </span>apt-get<span class="w"> </span>update<span class="w">
</span><span class="w">      </span>-<span class="w"> </span>apt-get<span class="w"> </span>install<span class="w"> </span>-y<span class="w"> </span>git<span class="w"> </span>golang<span class="w"> </span>wget<span class="w">
</span><span class="w">      </span>-<span class="w"> </span>wget<span class="w"> </span>-q<span class="w"> </span>https<span class="p">:</span>//github.com/gohugoio/hugo/releases/download/v0.<span class="m">31</span>/hugo_0.31_Linux-64bit.deb<span class="w"> </span>-O<span class="w"> </span>/tmp/hugo.dep<span class="w">
</span><span class="w">      </span>-<span class="w"> </span>dpkg<span class="w"> </span>-i<span class="w"> </span>/tmp/hugo.dep<span class="w">
</span><span class="w">  </span>pre_build<span class="p">:</span><span class="w">
</span><span class="w">    </span>commands<span class="p">:</span><span class="w">
</span><span class="w">      </span>-<span class="w"> </span>echo<span class="w"> </span>Downloading<span class="w"> </span>source<span class="w"> </span>code<span class="w">
</span><span class="w">      </span>-<span class="w"> </span>git<span class="w"> </span>clone<span class="w"> </span>https<span class="p">:</span>//github.com/Skarlso/blogsource.git<span class="w"> </span>/opt/app<span class="w">
</span><span class="w">  </span>build<span class="p">:</span><span class="w">
</span><span class="w">    </span>commands<span class="p">:</span><span class="w">
</span><span class="w">      </span>-<span class="w"> </span>echo<span class="w"> </span>Build<span class="w"> </span>started<span class="w"> </span>on<span class="w"> </span>`date`<span class="w">
</span><span class="w">      </span>-<span class="w"> </span>cd<span class="w"> </span>/opt/app<span class="w"> </span><span class="cp">&amp;&amp;</span><span class="w"> </span>hugo<span class="w"> </span>--theme<span class="w"> </span>purehugo<span class="w">
</span><span class="w">  </span>post_build<span class="p">:</span><span class="w">
</span><span class="w">    </span>commands<span class="p">:</span><span class="w">
</span><span class="w">      </span>-<span class="w"> </span>echo<span class="w"> </span>Build<span class="w"> </span>completed<span class="w"> </span>on<span class="w"> </span>`date`<span class="w">
</span><span class="w"></span>artifacts<span class="p">:</span><span class="w">
</span><span class="w">  </span>files<span class="p">:</span><span class="w">
</span><span class="w">    </span>-<span class="w"> </span>/opt/app/public/<span class="cp">**/*</span></code></pre></div>
<p>When it&rsquo;s finished, CodeBuild will upload everything in the public folder as a zip to a bucket. The bucket has a lambda attached which triggers on putObject event with the extension <code>.zip</code>. It downloads the archive, extracts it and pushes it to another repository, which is the repository for the blog.</p>

<p>And done! That&rsquo;s it. For an architecture overview, please read on.</p>

<h1 id="architecture">Architecture</h1>

<p>Now, we are going to use CloudFormation stack to deploy these resources. Because we aren&rsquo;t animals to create them by hand, yes?</p>

<p>An overview of my current architecture is best shown by this image:</p>

<p><img src="/img/blog_builder_cf_template.png" alt="AWS Stack" />.</p>

<p>Let&rsquo;s go over these components one - by - one.</p>

<h2 id="lambda-role">Lambda Role</h2>

<p>This is the <a href="http://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles.html">Role</a> which allows the Lambda to access things in your account. It needs the following service access: s3, logs, lambda; and the following permissions: logs:Create*, logs:PutLogEvents, s3:GetObject, s3:ListBucket.</p>

<h2 id="code-build-role">Code Build Role</h2>

<p>This is the role which allows CodeBuild to have access to services it needs. These services are the following: s3, logs, ssm, codebuild. CodeBuild also needs the following actions allowed: logs:Create*, logs:PutLogEvents, s3:GetObject, s3:PutObject, ssm:GetParameters.</p>

<h2 id="build-bucket">Build Bucket</h2>

<p>This is the bucket in which CodeBuild will push the generated build artifact.</p>

<h2 id="blog-pusher-function">Blog Pusher Function</h2>

<p>This is the heart of this project. It contains the logic to download the zipped artifact, extract it, create a hollow repository from the extracted archive and push the changes to the repository. And just the changes.</p>

<p>This is achieve by a short Python 3.6 script which can be found in the linked repository.</p>

<h2 id="parameters">Parameters</h2>

<p>The stack requires you to provide a couple of parameters which are described in the template. Like, bucket name, github repository, git token and such. Please refer to the template for a full description of each.</p>

<h2 id="charges">Charges</h2>

<p>I recently push a couple of builds to test this configuration and I inferred 0.2 USD in charges. But that was like 10-15 builds a day.</p>

<h1 id="deploying">Deploying</h1>

<p>In order to deploy this you can use <a href="https://github.com/Skarlso/go-furnace">Furnace</a> to easily manage the template and it&rsquo;s parameters. Once you copy the template to the target directory, simply run <code>furnace aws create</code> and provide the necessary parameters.</p>

<h1 id="conclusion">Conclusion</h1>

<p>And that is all. A nice little stack which does the same as Wercker without costs but the leisure of simply pushing up some change to a repository of your choosing.</p>

<p>I hope you enjoyed this little write up as much as I enjoyed creating it.</p>

<p>As always,
Thanks for reading!
Gergely.</p>
]]></content>
		</item>
		
		<item>
			<title>Furnace Ikea Manual</title>
			<link>https://skarlso.github.io/2017/11/06/furnace-ikea-manual/</link>
			<pubDate>Mon, 06 Nov 2017 20:34:00 +0100</pubDate>
			
			<guid>https://skarlso.github.io/2017/11/06/furnace-ikea-manual/</guid>
			<description>Hi there folks.
Just a quick post, of how I went on and created an IKEA manual about Furnace.
Page 1: . Page 2: .
I drew these using Krita. I mostly used a mouse but I also used a Wacom Bamboo drawing tabled, for sketches and such.
Thanks, Gergely.</description>
			<content type="html"><![CDATA[<p>Hi there folks.</p>

<p>Just a quick post, of how I went on and created an IKEA manual about <a href="https://github.com/Skarlso/go-furnace">Furnace</a>.</p>

<p>Page 1: <img src="/img/ikea-furnace-1.png" alt="Page 1" />.
Page 2: <img src="/img/ikea-furnace-2.png" alt="Page 2" />.</p>

<p>I drew these using <a href="https://krita.org/en/">Krita</a>. I mostly used a mouse but I also used a Wacom Bamboo drawing tabled, for sketches and such.</p>

<p>Thanks,
Gergely.</p>
]]></content>
		</item>
		
		<item>
			<title>Furnace Binaries</title>
			<link>https://skarlso.github.io/2017/09/03/furnace-binaries/</link>
			<pubDate>Sun, 03 Sep 2017 10:34:00 +0100</pubDate>
			
			<guid>https://skarlso.github.io/2017/09/03/furnace-binaries/</guid>
			<description>Hey folks.
Quick note. Furnace now comes pre-compiled easy to access binaries which you can download and use out of the box.
No need to install anything, or compile the source. Just download, unzip and use.
Here is the website: Furnace Website.
Enjoy, Cheers, Gergely.</description>
			<content type="html"><![CDATA[<p>Hey folks.</p>

<p>Quick note. Furnace now comes pre-compiled easy to access binaries which you can download and use out of the box.</p>

<p>No need to install anything, or compile the source. Just download, unzip and use.</p>

<p>Here is the website: <a href="https://skarlso.github.io/furnace-web">Furnace Website</a>.</p>

<p>Enjoy,
Cheers,
Gergely.</p>
]]></content>
		</item>
		
		<item>
			<title>Notetaking</title>
			<link>https://skarlso.github.io/2017/05/31/notetaking/</link>
			<pubDate>Wed, 31 May 2017 06:23:00 +0100</pubDate>
			
			<guid>https://skarlso.github.io/2017/05/31/notetaking/</guid>
			<description></description>
			<content type="html"><![CDATA[<p><img src="/img/page1.jpeg" alt="Page1" /></p>

<p><img src="/img/page2.jpeg" alt="Page2" /></p>
]]></content>
		</item>
		
		<item>
			<title>Replacing Eval with Object.send and a self written Parser</title>
			<link>https://skarlso.github.io/2017/05/28/replace-eval-with-object-send-and-a-parser/</link>
			<pubDate>Sun, 28 May 2017 19:23:00 +0100</pubDate>
			
			<guid>https://skarlso.github.io/2017/05/28/replace-eval-with-object-send-and-a-parser/</guid>
			<description>Intro A while ago, I was added as a curator for a Gem called JsonPath. It&amp;rsquo;s a small but very useful and brilliant gem. It had a couple of problems which I fixed, but the hardest to eliminate proved to be a series of evals throughout the code.
You could opt in using eval with a constructor parameter, but generally, it was considered to be unsafe. Thus, normally when a project was using it, like Huginn they had to opt out by default, thus missing out on sweet parsing like this: $.</description>
			<content type="html"><![CDATA[

<h1 id="intro">Intro</h1>

<p>A while ago, I was added as a curator for a Gem called <a href="https://github.com/joshbuddy/jsonpath">JsonPath</a>. It&rsquo;s a small but very useful and brilliant gem. It had a couple of problems which I fixed, but the hardest to eliminate proved to be a series of evals throughout the code.</p>

<p>You could opt in using <code>eval</code> with a constructor parameter, but generally, it was considered to be unsafe. Thus, normally when a project was using it, like <a href="https://github.com/huginn/huginn">Huginn</a> they had to opt out by default, thus missing out on sweet parsing like this: <code>$..book[?(@['price'] &gt; 20)]</code>.</p>

<h2 id="eval">Eval</h2>

<p>In order to remove eval, first I had to understand what it is actually doing. I had to take it apart.</p>

<p><img src="/img/takeevalapart.jpg" alt="apart" /></p>

<p>After much digging and understanding the code, I found, all it does is perform the given operations on the current node. And if the operation is true, it will select that node, otherwise, return false, and ignore that node.</p>

<p>For example <code>$..book[?(@['price'] &gt; 20)]</code> could be translated to:</p>
<div class="highlight"><pre class="chroma"><code class="language-ruby" data-lang="ruby"><span class="k">return</span> <span class="vi">@_current_node</span><span class="o">[</span><span class="s1">&#39;price&#39;</span><span class="o">]</span> <span class="o">&gt;</span> <span class="mi">20</span></code></pre></div>
<p>Checking first if <code>'price'</code> is even a key in <code>@_current_node</code>. Once I&rsquo;ve understood this part, I set on trying to fix eval.</p>

<h3 id="safe-4">SAFE = 4</h3>

<p>In ruby, you could extract the part where you Eval and put it into its own proc and set <code>SAFE = 4</code> which will disable some things like system calls.</p>
<div class="highlight"><pre class="chroma"><code class="language-ruby" data-lang="ruby"><span class="nb">proc</span> <span class="k">do</span>
  <span class="no">SAFE</span> <span class="o">=</span> <span class="mi">4</span>
  <span class="nb">eval</span><span class="p">(</span><span class="n">some_expression</span><span class="p">)</span>
<span class="k">end</span><span class="o">.</span><span class="n">call</span></code></pre></div>
<p>SAFE levels:</p>

<p>$SAFE   Description
0   No checking of the use of externally supplied (tainted) data is performed. This is Ruby&rsquo;s default mode.
&gt;= 1    Ruby disallows the use of tainted data by potentially dangerous operations.
&gt;= 2    Ruby prohibits the loading of program files from globally writable locations.
&gt;= 3    All newly created objects are considered tainted.
&gt;= 4    Ruby effectively partitions the running program in two. None - tainted objects may not be modified. Typically, this will be used to create a sandbox: the program sets up an environment using a lower $SAFE level, then resets $SAFE to 4 to prevent subsequent changes to that environment.</p>

<p>This has the disadvantage that anything below 4 is just, meh. But nothing above 1 will actually work with JsonPath so&hellip; scratch that.</p>

<h3 id="sandboxing">Sandboxing</h3>

<p>We could technically try and sandbox eval into it&rsquo;s own process with a PID and whitelist methods which are allowed to be called.</p>

<p>Not bad, and there are a few gems out there which are trying to do that like <a href="https://github.com/ukutaht/safe_ruby">SafeRuby</a>. But all of these project have been abandoned years ago for a good reason.</p>

<h3 id="object-send">Object.send</h3>

<p><img src="/img/nobodylikesyou.jpg" alt="nobodylikesyou" /></p>

<p><code>Object.send</code> is the best way to get some flexibility while still being safe. You basically just call methods on objects by describing said method on an object and giving parameters to it, like:</p>
<div class="highlight"><pre class="chroma"><code class="language-ruby" data-lang="ruby"><span class="mi">1</span><span class="o">.</span><span class="n">send</span><span class="p">(</span><span class="ss">:+</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="o">=&gt;</span> <span class="mi">3</span></code></pre></div>
<p>This is a very powerful tool in our toolbox which we will exploit immensely.</p>

<p>So let&rsquo;s get to it.</p>

<h1 id="writing-a-parser">Writing a parser</h1>

<p>Writing a parser in Ruby is a very fluid experience. It has nice tools which support that, and the one I used is <code>StringScanner</code>. It has the ability to track where you are currently at in a string and move a pointer along with regex matches. In fact, JsonPath already employs this method when parsing a json expression. So reusing that logic was in fact&hellip; elementary.</p>

<h2 id="the-expression">The expression</h2>

<p>How do we get from this:</p>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash">$..book<span class="o">[</span>?<span class="o">(</span>@<span class="o">[</span><span class="s1">&#39;price&#39;</span><span class="o">]</span> &lt; <span class="m">20</span><span class="o">)]</span></code></pre></div>
<p>To this:</p>
<div class="highlight"><pre class="chroma"><code class="language-ruby" data-lang="ruby"><span class="vi">@_current_node</span><span class="o">[</span><span class="s1">&#39;price&#39;</span><span class="o">]</span> <span class="o">&lt;</span> <span class="mi">20</span></code></pre></div>
<p>Well. By simple elimination. There are a couple of problems along the way of course. Because this wouldn&rsquo;t be a parser if it couldn&rsquo;t handle ALL the other cases&hellip;</p>

<h3 id="removing-clutter">Removing Clutter</h3>

<p>Some of this we don&rsquo;t need. Like, <code>$..book</code> part.</p>

<p><img src="/img/dontneed1.jpg" alt="dontneed1" /></p>

<p>The other things we don&rsquo;t need are all the <code>'[]?()</code></p>

<p><img src="/img/dontneed2.jpg" alt="dontneed2" /></p>

<p>Once this is done, we can move to isolating the important bits.</p>

<p><img src="/img/takingaim.jpg" alt="takingaim" /></p>

<h3 id="breakdown">BreakDown</h3>

<h4 id="elements">Elements</h4>

<p>How does an expression actually look like?</p>

<p>Let&rsquo;s break it down.</p>

<p><img src="/img/confused.jpg" alt="confused" /></p>

<p>So, this is a handful. Operations can be <code>&lt;=,&gt;=,&lt;,&gt;,==,!=</code> and operands can be either numbers, or words, and element accessor can be nested since something like this is perfectly valid: <code>$..book[?(@.written.year == 1997)]</code>.</p>

<p><img src="/img/feedline.jpg" alt="feedline" /></p>

<p>To avoid being overwhelmed, ruby has our back with a method called <code>dig</code>.</p>

<p><img src="/img/dig.jpg" alt="dig" /></p>

<p>This, basically lets us pass in some parameters into a dig function on a hash or an array with variadic parameters, which will go on and access those elements in order how they were supplied. Until it either returns a <code>nil</code> or an end result.</p>

<p>For example:</p>
<div class="highlight"><pre class="chroma"><code class="language-ruby" data-lang="ruby"><span class="mi">2</span><span class="o">.</span><span class="mi">3</span><span class="o">.</span><span class="mi">1</span> <span class="p">:</span><span class="mo">001</span> <span class="o">&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="p">{</span><span class="ss">a</span><span class="p">:</span> <span class="p">{</span><span class="ss">b</span><span class="p">:</span> <span class="s1">&#39;c&#39;</span><span class="p">}}</span>
 <span class="o">=&gt;</span> <span class="p">{</span><span class="ss">:a</span><span class="o">=&gt;</span><span class="p">{</span><span class="ss">:b</span><span class="o">=&gt;</span><span class="s2">&#34;c&#34;</span><span class="p">}}</span>
<span class="mi">2</span><span class="o">.</span><span class="mi">3</span><span class="o">.</span><span class="mi">1</span> <span class="p">:</span><span class="mo">002</span> <span class="o">&gt;</span> <span class="n">a</span><span class="o">.</span><span class="n">dig</span><span class="p">(</span><span class="ss">:a</span><span class="p">,</span> <span class="ss">:b</span><span class="p">)</span>
 <span class="o">=&gt;</span> <span class="s2">&#34;c&#34;</span></code></pre></div>
<p>Easy. However&hellip; Dig was only added after ruby 2.3 thus, I had to write my own dig for now, until I stop supporting anything below 2.3.</p>

<p>At first, I wanted to add it to the hash class, but it proved to be a futile attempt if I wanted to do it nicely, thus the parser got it as a private method.</p>
<div class="highlight"><pre class="chroma"><code class="language-ruby" data-lang="ruby">    <span class="k">def</span> <span class="nf">dig</span><span class="p">(</span><span class="n">keys</span><span class="p">,</span> <span class="nb">hash</span><span class="p">)</span>
      <span class="k">return</span> <span class="nb">hash</span> <span class="k">unless</span> <span class="nb">hash</span><span class="o">.</span><span class="n">is_a?</span> <span class="no">Hash</span>
      <span class="k">return</span> <span class="kp">nil</span> <span class="k">unless</span> <span class="nb">hash</span><span class="o">.</span><span class="n">key?</span><span class="p">(</span><span class="n">keys</span><span class="o">.</span><span class="n">first</span><span class="p">)</span>
      <span class="k">return</span> <span class="nb">hash</span><span class="o">.</span><span class="n">fetch</span><span class="p">(</span><span class="n">keys</span><span class="o">.</span><span class="n">first</span><span class="p">)</span> <span class="k">if</span> <span class="n">keys</span><span class="o">.</span><span class="n">size</span> <span class="o">==</span> <span class="mi">1</span>
      <span class="n">prev</span> <span class="o">=</span> <span class="n">keys</span><span class="o">.</span><span class="n">shift</span>
      <span class="n">dig</span><span class="p">(</span><span class="n">keys</span><span class="p">,</span> <span class="nb">hash</span><span class="o">.</span><span class="n">fetch</span><span class="p">(</span><span class="n">prev</span><span class="p">))</span>
    <span class="k">end</span></code></pre></div>
<p>And the corresponding regex behind getting a multitude of elements is as follows:</p>
<div class="highlight"><pre class="chroma"><code class="language-ruby" data-lang="ruby"><span class="o">...</span>
<span class="k">if</span> <span class="n">t</span> <span class="o">=</span> <span class="n">scanner</span><span class="o">.</span><span class="n">scan</span><span class="p">(</span><span class="sr">/\[&#39;\w+&#39;\]+/</span><span class="p">)</span>
<span class="o">...</span></code></pre></div>
<h4 id="operator">Operator</h4>

<p>Selecting the operator is another interesting part as it can be a single one or multiple and all sorts. Until I realized that no&hellip; it can actually be only a couple.</p>

<p><img src="/img/whatone.jpg" alt="whatone" /></p>

<p><img src="/img/whattwo.jpg" alt="whattwo" /></p>

<p>Also, after a bit of fiddling and doing and doing a silly case statement first:</p>
<div class="highlight"><pre class="chroma"><code class="language-ruby" data-lang="ruby"><span class="k">case</span> <span class="n">op</span>
<span class="k">when</span> <span class="s1">&#39;&gt;&#39;</span>
  <span class="n">dig</span><span class="p">(</span><span class="vi">@_current_node</span><span class="p">,</span> <span class="o">*</span><span class="n">elements</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">operand</span>
<span class="k">when</span> <span class="s1">&#39;&lt;&#39;</span>
  <span class="n">dig</span><span class="p">(</span><span class="vi">@_current_node</span><span class="p">,</span> <span class="o">*</span><span class="n">elements</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">operand</span>
<span class="o">...</span>
<span class="k">end</span></code></pre></div>
<p>&hellip;I promptly saw that this is not how it should be done.</p>

<p>And here comes Object.send.</p>

<p><img src="/img/send.jpg" alt="send" /></p>

<p>This gave me the opportunity to write this:</p>
<div class="highlight"><pre class="chroma"><code class="language-ruby" data-lang="ruby"><span class="n">dig</span><span class="p">(</span><span class="n">elements</span><span class="p">,</span> <span class="vi">@_current_node</span><span class="p">)</span><span class="o">.</span><span class="n">send</span><span class="p">(</span><span class="n">operator</span><span class="p">,</span> <span class="n">operand</span><span class="p">)</span></code></pre></div>
<p>Much better. Now I could send all the things in the way of a node.</p>

<p><img src="/img/sendtwo.jpg" alt="send" /></p>

<p>Parsing an op be like:</p>
<div class="highlight"><pre class="chroma"><code class="language-ruby" data-lang="ruby"><span class="k">elsif</span> <span class="n">t</span> <span class="o">=</span> <span class="n">scanner</span><span class="o">.</span><span class="n">scan</span><span class="p">(</span><span class="sr">/\s+[&lt;&gt;=][&lt;&gt;=]?\s+?/</span><span class="p">)</span></code></pre></div>
<h4 id="operand">Operand</h4>

<p>Now comes the final piece. The value which we are comparing. This could either be a simple integer, a floating number, or a word. Hah. So coming up with a regex which fits this tightly took a little fiddling, but eventually I ended up with this:</p>
<div class="highlight"><pre class="chroma"><code class="language-ruby" data-lang="ruby"><span class="k">elsif</span> <span class="n">t</span> <span class="o">=</span> <span class="n">scanner</span><span class="o">.</span><span class="n">scan</span><span class="p">(</span><span class="sr">/(\s+)?&#39;?(\w+)?[.,]?(\w+)?&#39;?(\s+)?/</span><span class="p">)</span></code></pre></div>
<p>Without StackOverflow I would say this is fine ((although I need to remove all those space check, shees)). What are all the question marks? Basically, everything is optional. Because an this expression <code>$..book[?(@.price)]</code> is valid. Which is basically just asserting if a given node has a price element.</p>

<h4 id="logical-operators">Logical Operators</h4>

<p>The last thing that remains is logical operators, which if you are using eval, is pretty straight forward. It takes care of anything that you might add in like <code>&amp;&amp;, ||, |, &amp;, ^</code> etc etc.</p>

<p>Now, that&rsquo;s something I did with a case though. Until I find a nicer solution. Since we can already parse a single expression it&rsquo;s just a question of breaking down a multi structure expression as the following one: <code>$..book[?(@['price'] &gt; 20 &amp;&amp; @.written.year == 1998)]</code>.</p>
<div class="highlight"><pre class="chroma"><code class="language-ruby" data-lang="ruby"><span class="n">exps</span> <span class="o">=</span> <span class="n">exp</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="sr">/(&amp;&amp;)|(\|\|)/</span><span class="p">)</span></code></pre></div>
<p>This splits up the string by either <code>&amp;&amp;</code> or <code>||</code> and the usage of groups () also includes the operators. Than I evaluate the expressions and save the whole thing in an array like <code>[true, '&amp;&amp;', false]</code>. You know what could immediately resolve this? Yep&hellip;</p>

<p><img src="/img/saynotoeval.jpg" alt="saynotoeval" />.</p>

<p>I&rsquo;d rather just parse it although technically an eval at this stage wouldn&rsquo;t be that big of a problem&hellip;</p>
<div class="highlight"><pre class="chroma"><code class="language-ruby" data-lang="ruby"><span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="n">exp</span><span class="p">)</span>
  <span class="n">exps</span> <span class="o">=</span> <span class="n">exp</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="sr">/(&amp;&amp;)|(\|\|)/</span><span class="p">)</span>
  <span class="n">ret</span> <span class="o">=</span> <span class="n">parse_exp</span><span class="p">(</span><span class="n">exps</span><span class="o">.</span><span class="n">shift</span><span class="p">)</span>
  <span class="n">exps</span><span class="o">.</span><span class="n">each_with_index</span> <span class="k">do</span> <span class="o">|</span><span class="n">item</span><span class="p">,</span> <span class="n">index</span><span class="o">|</span>
    <span class="k">case</span> <span class="n">item</span>
    <span class="k">when</span> <span class="s1">&#39;&amp;&amp;&#39;</span>
      <span class="n">ret</span> <span class="o">&amp;&amp;=</span> <span class="n">parse_exp</span><span class="p">(</span><span class="n">exps</span><span class="o">[</span><span class="n">index</span> <span class="o">+</span> <span class="mi">1</span><span class="o">]</span><span class="p">)</span>
    <span class="k">when</span> <span class="s1">&#39;||&#39;</span>
      <span class="n">ret</span> <span class="o">||=</span> <span class="n">parse_exp</span><span class="p">(</span><span class="n">exps</span><span class="o">[</span><span class="n">index</span> <span class="o">+</span> <span class="mi">1</span><span class="o">]</span><span class="p">)</span>
    <span class="k">end</span>
  <span class="k">end</span>
  <span class="n">ret</span>
<span class="k">end</span></code></pre></div>
<h1 id="closing-words">Closing words</h1>

<p>That&rsquo;s it folks. The parser is done. And there is no eval being used. There are some more things here that are interesting. Like, array indexing is allowed in jsonpath which is solved by sending <code>.length</code> to a current node. For example:</p>
<div class="highlight"><pre class="chroma"><code class="language-ruby" data-lang="ruby"><span class="k">if</span> <span class="n">scanner</span><span class="o">.</span><span class="n">scan</span><span class="p">(</span><span class="sr">/\./</span><span class="p">)</span>
  <span class="n">sym</span> <span class="o">=</span> <span class="n">scanner</span><span class="o">.</span><span class="n">scan</span><span class="p">(</span><span class="sr">/\w+/</span><span class="p">)</span>
  <span class="n">op</span> <span class="o">=</span> <span class="n">scanner</span><span class="o">.</span><span class="n">scan</span><span class="p">(</span><span class="sr">/./</span><span class="p">)</span>
  <span class="n">num</span> <span class="o">=</span> <span class="n">scanner</span><span class="o">.</span><span class="n">scan</span><span class="p">(</span><span class="sr">/\d+/</span><span class="p">)</span>
  <span class="k">return</span> <span class="vi">@_current_node</span><span class="o">.</span><span class="n">send</span><span class="p">(</span><span class="n">sym</span><span class="o">.</span><span class="n">to_sym</span><span class="p">)</span><span class="o">.</span><span class="n">send</span><span class="p">(</span><span class="n">op</span><span class="o">.</span><span class="n">to_sym</span><span class="p">,</span> <span class="n">num</span><span class="o">.</span><span class="n">to_i</span><span class="p">)</span>
<span class="k">end</span></code></pre></div>
<p>If an expression begins with a <code>.</code>. So you see that using <code>send</code> will help a lot, and understanding what eval is trying to evaluate and rather writing your own parser, isn&rsquo;t that hard at all using ruby.</p>

<p>I hope you enjoyed reading this little tid-bit as much as I enjoyed writing and drawing it. Leave a comment if your liked the drawings or if you did not and I should never do them again (( I don&rsquo;t really care, this is my blog haha. )). Note to self: I shouldn&rsquo;t draw on the other side of the drawing because of bleed-through.</p>

<p>Thank you!
Gergely.</p>
]]></content>
		</item>
		
		<item>
			<title>Furnace - The building of an AWS CLI Tool for CloudFormation and CodeDeploy - Part 4</title>
			<link>https://skarlso.github.io/2017/04/16/building-furnace-part-4/</link>
			<pubDate>Sun, 16 Apr 2017 09:23:00 +0100</pubDate>
			
			<guid>https://skarlso.github.io/2017/04/16/building-furnace-part-4/</guid>
			<description>Intro Hi folks.
Previously on this blog: Part 1. Part 2. Part 3.
In this part we are going to talk about Unit Testing Furnace and how to work some magic with AWS and Go.
Mock Stub Fake Dummy Canned  Unit testing in Go usually follows the Dependency Injection model of dealing with Mocks and Stubs.
## DI
Dependency Inject in short is one object supplying the dependencies of another object.</description>
			<content type="html"><![CDATA[

<h1 id="intro">Intro</h1>

<p>Hi folks.</p>

<p>Previously on this blog: <a href="https://skarlso.github.io/2017/03/16/building-furnace-part-1/">Part 1</a>. <a href="https://skarlso.github.io/2017/03/19/building-furnace-part-2/">Part 2</a>. <a href="https://skarlso.github.io/2017/03/22/building-furnace-part-3/">Part 3</a>.</p>

<p>In this part we are going to talk about Unit Testing Furnace and how to work some magic with AWS and Go.</p>

<h1 id="mock-stub-fake-dummy-canned-insert-name-here">Mock Stub Fake Dummy Canned <Insert Name Here></h1>

<p>Unit testing in Go usually follows the Dependency Injection model of dealing with Mocks and Stubs.</p>

<p>## DI</p>

<p>Dependency Inject in short is one object supplying the dependencies of another object. In a longer description, it&rsquo;s ideal to be used
for removing the lock on a third party library, like the AWS client. Imaging having code which solely depends on the AWS client. How
would you unit test that code without having to ACTUALLY connect to AWS? You couldn&rsquo;t. Every time you try to test the code it would run
the live code and it would try and connect to AWS and perform the operations it&rsquo;s design to do. The Ruby library with it&rsquo;s metaprogramming
allows you to set the client globally to stub responses, but, alas, this is not the world of Ruby.</p>

<p>Here is where DI comes to the rescue. If you have control over the AWS client on a very high level, and would pass it around as a function
parameter, or create that client in an <code>init()</code> function and have it globally defined; you would be able to implement your own client, and
have your code use that with stubbed responses which your tests need. For example, you would like a CreateApplication call to fail, or you
would like a DescribeStack which returns an aws.Error(&ldquo;StackAlreadyExists&rdquo;).</p>

<p>For this, however, you need the API of the AWS client. Which is provided by AWS.</p>

<h2 id="aws-client-api">AWS Client API</h2>

<p>In order for DI to work, the injected object needs to be of a certain type for us to inject our own. Luckily, AWS provides an Interface for
all of it&rsquo;s clients. Meaning, we can implement our own version for all of the clients, like S3, CloudFormation, CodeDeploy etc.</p>

<p>For each client you want to mock out, an <em>*iface</em> package should be present like this:</p>
<div class="highlight"><pre class="chroma"><code class="language-go" data-lang="go">  <span class="s">&#34;github.com/aws/aws-sdk-go/service/cloudformation/cloudformationiface&#34;</span></code></pre></div>
<p>In this package you find and use the interface like this:</p>
<div class="highlight"><pre class="chroma"><code class="language-go" data-lang="go"><span class="kd">type</span> <span class="nx">fakeCloudFormationClient</span> <span class="kd">struct</span> <span class="p">{</span>
	<span class="nx">cloudformationiface</span><span class="p">.</span><span class="nx">CloudFormationAPI</span>
	<span class="nx">err</span> <span class="kt">error</span>
<span class="p">}</span></code></pre></div>
<p>And with this, we have our own CloudFormation client. The real code uses the real clients as function parameters, like this:</p>
<div class="highlight"><pre class="chroma"><code class="language-go" data-lang="go"><span class="c1">// Execute defines what this command does.
</span><span class="c1"></span><span class="kd">func</span> <span class="p">(</span><span class="nx">c</span> <span class="o">*</span><span class="nx">Create</span><span class="p">)</span> <span class="nf">Execute</span><span class="p">(</span><span class="nx">opts</span> <span class="o">*</span><span class="nx">commander</span><span class="p">.</span><span class="nx">CommandHelper</span><span class="p">)</span> <span class="p">{</span>
	<span class="nx">log</span><span class="p">.</span><span class="nf">Println</span><span class="p">(</span><span class="s">&#34;Creating cloud formation session.&#34;</span><span class="p">)</span>
	<span class="nx">sess</span> <span class="o">:=</span> <span class="nx">session</span><span class="p">.</span><span class="nf">New</span><span class="p">(</span><span class="o">&amp;</span><span class="nx">aws</span><span class="p">.</span><span class="nx">Config</span><span class="p">{</span><span class="nx">Region</span><span class="p">:</span> <span class="nx">aws</span><span class="p">.</span><span class="nf">String</span><span class="p">(</span><span class="nx">config</span><span class="p">.</span><span class="nx">REGION</span><span class="p">)})</span>
	<span class="nx">cfClient</span> <span class="o">:=</span> <span class="nx">cloudformation</span><span class="p">.</span><span class="nf">New</span><span class="p">(</span><span class="nx">sess</span><span class="p">,</span> <span class="kc">nil</span><span class="p">)</span>
	<span class="nx">client</span> <span class="o">:=</span> <span class="nx">CFClient</span><span class="p">{</span><span class="nx">cfClient</span><span class="p">}</span>
	<span class="nf">createExecute</span><span class="p">(</span><span class="nx">opts</span><span class="p">,</span> <span class="o">&amp;</span><span class="nx">client</span><span class="p">)</span>
<span class="p">}</span></code></pre></div>
<p>We can&rsquo;t test Execute itself, as it&rsquo;s using the real client here (or you could have a global from some library, thus allowing you to tests
even <code>Execute</code> here) but there is very little logic in this function for this very reason. All the logic is in small functions for which
the main starting point and our testing opportunity is, <code>createExecute</code>.</p>

<h2 id="stubbing-calls">Stubbing Calls</h2>

<p>Now, that we have our own client, and with the power of Go&rsquo;s interface embedding as seen above with CloudFormationAPI, we have to only stub
the functions which we are actually using, instead of every function of the given interface. This looks like this:</p>
<div class="highlight"><pre class="chroma"><code class="language-go" data-lang="go">	<span class="nx">cfClient</span> <span class="o">:=</span> <span class="nb">new</span><span class="p">(</span><span class="nx">CFClient</span><span class="p">)</span>
	<span class="nx">cfClient</span><span class="p">.</span><span class="nx">Client</span> <span class="p">=</span> <span class="o">&amp;</span><span class="nx">fakeCloudFormationClient</span><span class="p">{</span><span class="nx">err</span><span class="p">:</span> <span class="kc">nil</span><span class="p">}</span></code></pre></div>
<p>Where cfClient is a struct like this:</p>
<div class="highlight"><pre class="chroma"><code class="language-go" data-lang="go"><span class="c1">// CFClient abstraction for cloudFormation client.
</span><span class="c1"></span><span class="kd">type</span> <span class="nx">CFClient</span> <span class="kd">struct</span> <span class="p">{</span>
	<span class="nx">Client</span> <span class="nx">cloudformationiface</span><span class="p">.</span><span class="nx">CloudFormationAPI</span>
<span class="p">}</span></code></pre></div>
<p>And a stubbed call can than be written as follows:</p>
<div class="highlight"><pre class="chroma"><code class="language-go" data-lang="go"><span class="kd">func</span> <span class="p">(</span><span class="nx">fc</span> <span class="o">*</span><span class="nx">fakeCreateCFClient</span><span class="p">)</span> <span class="nf">WaitUntilStackCreateComplete</span><span class="p">(</span><span class="nx">input</span> <span class="o">*</span><span class="nx">cloudformation</span><span class="p">.</span><span class="nx">DescribeStacksInput</span><span class="p">)</span> <span class="kt">error</span> <span class="p">{</span>
	<span class="k">return</span> <span class="kc">nil</span>
<span class="p">}</span></code></pre></div>
<p>This can range from a very trivial example, like the one above, to intricate ones as well, like this gem:</p>
<div class="highlight"><pre class="chroma"><code class="language-go" data-lang="go"><span class="kd">func</span> <span class="p">(</span><span class="nx">fc</span> <span class="o">*</span><span class="nx">fakePushCFClient</span><span class="p">)</span> <span class="nf">ListStackResources</span><span class="p">(</span><span class="nx">input</span> <span class="o">*</span><span class="nx">cloudformation</span><span class="p">.</span><span class="nx">ListStackResourcesInput</span><span class="p">)</span> <span class="p">(</span><span class="o">*</span><span class="nx">cloudformation</span><span class="p">.</span><span class="nx">ListStackResourcesOutput</span><span class="p">,</span> <span class="kt">error</span><span class="p">)</span> <span class="p">{</span>
	<span class="k">if</span> <span class="s">&#34;NoASG&#34;</span> <span class="o">==</span> <span class="o">*</span><span class="nx">input</span><span class="p">.</span><span class="nx">StackName</span> <span class="p">{</span>
		<span class="k">return</span> <span class="o">&amp;</span><span class="nx">cloudformation</span><span class="p">.</span><span class="nx">ListStackResourcesOutput</span><span class="p">{</span>
			<span class="nx">StackResourceSummaries</span><span class="p">:</span> <span class="p">[]</span><span class="o">*</span><span class="nx">cloudformation</span><span class="p">.</span><span class="nx">StackResourceSummary</span><span class="p">{</span>
				<span class="p">{</span>
					<span class="nx">ResourceType</span><span class="p">:</span>       <span class="nx">aws</span><span class="p">.</span><span class="nf">String</span><span class="p">(</span><span class="s">&#34;NoASG&#34;</span><span class="p">),</span>
					<span class="nx">PhysicalResourceId</span><span class="p">:</span> <span class="nx">aws</span><span class="p">.</span><span class="nf">String</span><span class="p">(</span><span class="s">&#34;arn::whatever&#34;</span><span class="p">),</span>
				<span class="p">},</span>
			<span class="p">},</span>
		<span class="p">},</span> <span class="nx">fc</span><span class="p">.</span><span class="nx">err</span>
	<span class="p">}</span>
	<span class="k">return</span> <span class="o">&amp;</span><span class="nx">cloudformation</span><span class="p">.</span><span class="nx">ListStackResourcesOutput</span><span class="p">{</span>
		<span class="nx">StackResourceSummaries</span><span class="p">:</span> <span class="p">[]</span><span class="o">*</span><span class="nx">cloudformation</span><span class="p">.</span><span class="nx">StackResourceSummary</span><span class="p">{</span>
			<span class="p">{</span>
				<span class="nx">ResourceType</span><span class="p">:</span>       <span class="nx">aws</span><span class="p">.</span><span class="nf">String</span><span class="p">(</span><span class="s">&#34;AWS::AutoScaling::AutoScalingGroup&#34;</span><span class="p">),</span>
				<span class="nx">PhysicalResourceId</span><span class="p">:</span> <span class="nx">aws</span><span class="p">.</span><span class="nf">String</span><span class="p">(</span><span class="s">&#34;arn::whatever&#34;</span><span class="p">),</span>
			<span class="p">},</span>
		<span class="p">},</span>
	<span class="p">},</span> <span class="nx">fc</span><span class="p">.</span><span class="nx">err</span>
<span class="p">}</span></code></pre></div>
<p>This ListStackResources stub lets us test two scenarios based on the stackname. If the test stackname is &lsquo;NoASG&rsquo; it will return a result
which equals to a result containing no AutoScaling Group. Otherwise, it will return the correct ResourceType for an ASG.</p>

<p>It is a common practice to line up several scenario based stubbed responses in order to test the robustness of your code.</p>

<p>Unfortunately, this also means that your tests will be a bit cluttered with stubs and mock structs and whatnots. For that, I&rsquo;m partially
using a package available struct file in which I&rsquo;m defining most of the mock structs at least. And from there on, the tests will only contain
specific stubs for that particular file. This can be further fine grained by having defaults and than only override in case you need something
else.</p>

<h1 id="testing-fatals">Testing fatals</h1>

<p>Now, the other point which is not really AWS related, but still comes to mind when dealing with Furnace, is testing error scenarios.</p>

<p>Because Furnace is a CLI application it uses Fatals to signal if something is wrong and it doesn&rsquo;t want to continue or recover because, frankly
it can&rsquo;t. If AWS throws an error, that&rsquo;s it. You can retry, but in 90% of the cases, it&rsquo;s usually something that you messed up.</p>

<p>So, how do we test for a fatal or an <code>os.Exit</code>? There are a number of points on that if you do a quick search. You may end up on this talk:
<a href="https://talks.golang.org/2014/testing.slide#23">GoTalk 2014 Testing Slide #23</a>. Which does an interesting thing. It calls the test binary in a
separate process and tests the exit code.</p>

<p>Others, and me as well, will say that you have to have your own logger implemented and use a different logger / os.Exit in your test environment.</p>

<p>Others others will tell you to not to have tests around os.Exit and fatal things, rather return an error and only the main should pop a world
ending event. I leave it up to you which you want to use. Either is fine.</p>

<p>In Furnace, I&rsquo;m using a global logger in my error handling util like this:</p>
<div class="highlight"><pre class="chroma"><code class="language-go" data-lang="go"><span class="c1">// HandleFatal handler fatal errors in Furnace.
</span><span class="c1"></span><span class="kd">func</span> <span class="nf">HandleFatal</span><span class="p">(</span><span class="nx">s</span> <span class="kt">string</span><span class="p">,</span> <span class="nx">err</span> <span class="kt">error</span><span class="p">)</span> <span class="p">{</span>
	<span class="nf">LogFatalf</span><span class="p">(</span><span class="nx">s</span><span class="p">,</span> <span class="nx">err</span><span class="p">)</span>
<span class="p">}</span></code></pre></div>
<p>And <code>LogFatalf</code> is an exported variable <code>var LogFatalf = log.Fatalf</code>. Than in a test, I just override this variable with a local anonymous
function:</p>
<div class="highlight"><pre class="chroma"><code class="language-go" data-lang="go"><span class="kd">func</span> <span class="nf">TestCreateExecuteEmptyStack</span><span class="p">(</span><span class="nx">t</span> <span class="o">*</span><span class="nx">testing</span><span class="p">.</span><span class="nx">T</span><span class="p">)</span> <span class="p">{</span>
	<span class="nx">failed</span> <span class="o">:=</span> <span class="kc">false</span>
	<span class="nx">utils</span><span class="p">.</span><span class="nx">LogFatalf</span> <span class="p">=</span> <span class="kd">func</span><span class="p">(</span><span class="nx">s</span> <span class="kt">string</span><span class="p">,</span> <span class="nx">a</span> <span class="o">...</span><span class="kd">interface</span><span class="p">{})</span> <span class="p">{</span>
		<span class="nx">failed</span> <span class="p">=</span> <span class="kc">true</span>
	<span class="p">}</span>
	<span class="nx">config</span><span class="p">.</span><span class="nx">WAITFREQUENCY</span> <span class="p">=</span> <span class="mi">0</span>
	<span class="nx">client</span> <span class="o">:=</span> <span class="nb">new</span><span class="p">(</span><span class="nx">CFClient</span><span class="p">)</span>
	<span class="nx">stackname</span> <span class="o">:=</span> <span class="s">&#34;EmptyStack&#34;</span>
	<span class="nx">client</span><span class="p">.</span><span class="nx">Client</span> <span class="p">=</span> <span class="o">&amp;</span><span class="nx">fakeCreateCFClient</span><span class="p">{</span><span class="nx">err</span><span class="p">:</span> <span class="kc">nil</span><span class="p">,</span> <span class="nx">stackname</span><span class="p">:</span> <span class="nx">stackname</span><span class="p">}</span>
	<span class="nx">opts</span> <span class="o">:=</span> <span class="o">&amp;</span><span class="nx">commander</span><span class="p">.</span><span class="nx">CommandHelper</span><span class="p">{}</span>
	<span class="nf">createExecute</span><span class="p">(</span><span class="nx">opts</span><span class="p">,</span> <span class="nx">client</span><span class="p">)</span>
	<span class="k">if</span> <span class="p">!</span><span class="nx">failed</span> <span class="p">{</span>
		<span class="nx">t</span><span class="p">.</span><span class="nf">Error</span><span class="p">(</span><span class="s">&#34;expected outcome to fail during create&#34;</span><span class="p">)</span>
	<span class="p">}</span>
<span class="p">}</span></code></pre></div>
<p>It can get even more granular by testing for the error message to make sure that it actually fails at the point we think we are
testing:</p>
<div class="highlight"><pre class="chroma"><code class="language-go" data-lang="go"><span class="kd">func</span> <span class="nf">TestCreateStackReturnsWithError</span><span class="p">(</span><span class="nx">t</span> <span class="o">*</span><span class="nx">testing</span><span class="p">.</span><span class="nx">T</span><span class="p">)</span> <span class="p">{</span>
	<span class="nx">failed</span> <span class="o">:=</span> <span class="kc">false</span>
	<span class="nx">expectedMessage</span> <span class="o">:=</span> <span class="s">&#34;failed to create stack&#34;</span>
	<span class="kd">var</span> <span class="nx">message</span> <span class="kt">string</span>
	<span class="nx">utils</span><span class="p">.</span><span class="nx">LogFatalf</span> <span class="p">=</span> <span class="kd">func</span><span class="p">(</span><span class="nx">s</span> <span class="kt">string</span><span class="p">,</span> <span class="nx">a</span> <span class="o">...</span><span class="kd">interface</span><span class="p">{})</span> <span class="p">{</span>
		<span class="nx">failed</span> <span class="p">=</span> <span class="kc">true</span>
		<span class="k">if</span> <span class="nx">err</span><span class="p">,</span> <span class="nx">ok</span> <span class="o">:=</span> <span class="nx">a</span><span class="p">[</span><span class="mi">0</span><span class="p">].(</span><span class="kt">error</span><span class="p">);</span> <span class="nx">ok</span> <span class="p">{</span>
			<span class="nx">message</span> <span class="p">=</span> <span class="nx">err</span><span class="p">.</span><span class="nf">Error</span><span class="p">()</span>
		<span class="p">}</span>
	<span class="p">}</span>
	<span class="nx">config</span><span class="p">.</span><span class="nx">WAITFREQUENCY</span> <span class="p">=</span> <span class="mi">0</span>
	<span class="nx">client</span> <span class="o">:=</span> <span class="nb">new</span><span class="p">(</span><span class="nx">CFClient</span><span class="p">)</span>
	<span class="nx">stackname</span> <span class="o">:=</span> <span class="s">&#34;NotEmptyStack&#34;</span>
	<span class="nx">client</span><span class="p">.</span><span class="nx">Client</span> <span class="p">=</span> <span class="o">&amp;</span><span class="nx">fakeCreateCFClient</span><span class="p">{</span><span class="nx">err</span><span class="p">:</span> <span class="nx">errors</span><span class="p">.</span><span class="nf">New</span><span class="p">(</span><span class="nx">expectedMessage</span><span class="p">),</span> <span class="nx">stackname</span><span class="p">:</span> <span class="nx">stackname</span><span class="p">}</span>
	<span class="nx">config</span> <span class="o">:=</span> <span class="p">[]</span><span class="nb">byte</span><span class="p">(</span><span class="s">&#34;{}&#34;</span><span class="p">)</span>
	<span class="nf">create</span><span class="p">(</span><span class="nx">stackname</span><span class="p">,</span> <span class="nx">config</span><span class="p">,</span> <span class="nx">client</span><span class="p">)</span>
	<span class="k">if</span> <span class="p">!</span><span class="nx">failed</span> <span class="p">{</span>
		<span class="nx">t</span><span class="p">.</span><span class="nf">Error</span><span class="p">(</span><span class="s">&#34;expected outcome to fail&#34;</span><span class="p">)</span>
	<span class="p">}</span>
	<span class="k">if</span> <span class="nx">message</span> <span class="o">!=</span> <span class="nx">expectedMessage</span> <span class="p">{</span>
		<span class="nx">t</span><span class="p">.</span><span class="nf">Errorf</span><span class="p">(</span><span class="s">&#34;message did not equal expected message of &#39;%s&#39;, was:%s&#34;</span><span class="p">,</span> <span class="nx">expectedMessage</span><span class="p">,</span> <span class="nx">message</span><span class="p">)</span>
	<span class="p">}</span>
<span class="p">}</span></code></pre></div>
<h1 id="conclusion">Conclusion</h1>

<p>This is it. That&rsquo;s all it took to write Furnace. I hope you enjoyed reading it as much as I enjoyed writing all these thoughts down.</p>

<p>I hope somebody might learn from my journey and also improve upon it.</p>

<p>Any comments are much appreciated and welcomed. Also, PRs and Issues can be submitted on the GitHub page of <a href="https://github.com/Skarlso/go-furnace">Furnace</a>.</p>

<p>Thank you for reading!
Gergely.</p>
]]></content>
		</item>
		
	</channel>
</rss>
