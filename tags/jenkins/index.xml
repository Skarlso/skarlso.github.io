<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>jenkins on Ramblings of a cloud engineer</title>
    <link>https://skarlso.github.io/tags/jenkins/</link>
    <description>Recent content in jenkins on Ramblings of a cloud engineer</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-GB</language>
    <lastBuildDate>Thu, 15 Oct 2015 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://skarlso.github.io/tags/jenkins/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Jenkins Job DSL and Groovy goodness</title>
      <link>https://skarlso.github.io/2015/10/15/jenkins-job-dsl-and-groovy-goodness/</link>
      <pubDate>Thu, 15 Oct 2015 00:00:00 +0000</pubDate>
      <guid>https://skarlso.github.io/2015/10/15/jenkins-job-dsl-and-groovy-goodness/</guid>
      <description>&lt;p&gt;Hi Folks.&lt;/p&gt;
&lt;p&gt;Ever used &lt;!-- raw HTML omitted --&gt;Job DSL plugin&lt;!-- raw HTML omitted --&gt; for Jenkins? What is that you say? Well, it’s TEH most awesome plug-in for Jenkins to have, because you can CODE your job configuration and put it under source control.&lt;/p&gt;
&lt;p&gt;Today, however, I’m not going to write about that because the tutorials on Jenkins JOB DSL are very extensive and very well done. Anyone can pick them up.&lt;/p&gt;
&lt;p&gt;Today, I would like to write about a part of it which is even more interesting. And that is, extracting re-occurring parts in your job configurations.&lt;/p&gt;
&lt;p&gt;If you have jobs, which have a common part that is repeated everywhere, you usually have an urge to extracted that into one place, lest it changes and you have to go an apply the change everywhere. That’s not very efficient. But how do you do that in something which looks like a JSON descriptor?&lt;/p&gt;
&lt;p&gt;Fret not, it is just Groovy. And being just groovy, you can use Groovy to implement parts of the job description and then apply that implementation to the job in the DSL.&lt;/p&gt;
&lt;p&gt;Suppose you have an email which you send after every job for which the DSL looks like this:&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;Now, that big chunk of email setting is copied into a bunch of files, which is pretty ugly. And once you try to change it, you’ll have to change it everywhere. Also, the interesting bits here are those readFileFromWorkspace parts. Those allow us to export even larger chunks of the script into external files. Now, because the slave might be located somewhere else, you should not use new File(‘file’).text in your job DSL. readFileFromWorkspace in the background does that, but applies correct way to the PATH it looks on for the file specified.&lt;/p&gt;
&lt;p&gt;Let’s put this into a groovy script, shall we? Create a utilities folder where the DSL is and create a groovy file in it like this one:&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;The function addEmailTemplate gets two parameters. A job, which is an implementation of a Job, and a dslFactory which is a DslFactory. That factory is an interface which defines our readFileFromWorkspace. Where do we get the implementation from then? That will be from the Job. Let’s alter our job to apply this Groovy script.&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;Notice three things here.&lt;/p&gt;
&lt;p&gt;#1 =&amp;gt; &lt;strong&gt;import&lt;/strong&gt;. We import the script from utilities folder which we created and placed the script into it.&lt;/p&gt;
&lt;p&gt;#2 =&amp;gt; &lt;strong&gt;def myJob&lt;/strong&gt;. We create a variable which will contain our job’s description.&lt;/p&gt;
&lt;p&gt;#3 =&amp;gt; &lt;strong&gt;this&lt;/strong&gt;. ‘this’ will be the DslFactory. That’s where we get our readFileFromWorkspace implementation.&lt;/p&gt;
&lt;p&gt;And that’s it. We have extracted a part of our job which is re-occurring and we found our implementation for our readFileFromWorkspace. DslFactory has most of the things which you need in a job description, would you want to expand on this and extract other bits and pieces.&lt;/p&gt;
&lt;p&gt;Have fun, and happy coding!&lt;/p&gt;
&lt;p&gt;As always,&lt;/p&gt;
&lt;p&gt;Thanks for reading!&lt;/p&gt;
&lt;p&gt;Gergely.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>How to Aggregate Tests with Jenkins with Aggregate Plugin on non-relating jobs</title>
      <link>https://skarlso.github.io/2015/10/02/how-to-aggregate-tests-with-jenkins-with-aggregate-plugin-on-non-relating-jobs/</link>
      <pubDate>Fri, 02 Oct 2015 00:00:00 +0000</pubDate>
      <guid>https://skarlso.github.io/2015/10/02/how-to-aggregate-tests-with-jenkins-with-aggregate-plugin-on-non-relating-jobs/</guid>
      <description>&lt;p&gt;Hello folks.&lt;/p&gt;
&lt;p&gt;Today, I would like to talk about something I came in contact with, and was hard to find a proper answer / solution for it.&lt;/p&gt;
&lt;p&gt;So I’m writing this down to document my findings. Like the title says, this is about aggregating test result with Jenkins, using the plug-in provided. If you, like me, have a pipeline structure which do not work on the same artifact, but do have a upstream-downstream relationship, you will have a hard time configuring and making Aggregation work. So here is how, I fixed the issue.&lt;/p&gt;
&lt;h1 id=&#34;connection&#34;&gt;Connection&lt;/h1&gt;
&lt;p&gt;In order for the aggregation to work, there needs to be an &lt;strong&gt;artifact connection&lt;/strong&gt; between the upstream and downstream projects. And that is the key. But if you don’t have that, well, let’s create one. I have a parent job configured like this one. =&amp;gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;As you can see, it’s pretty basic. It isn’t much. It’s supposed to be a trigger job for downstream projects. You could have this one at anything. Maybe scheduled, or have some kind of gathering here of some results, and so on and so forth. The end part of the configuration is the interesting bit.&lt;/p&gt;
&lt;p&gt;Aggregation is setup, but it won’t work, because despite there being an upstream/downstream relationship, there also needs to be an artifact connection which uses &lt;strong&gt;fingerprinting&lt;/strong&gt;. Fingerprinting for Jenkins is needed in oder to make the physical connection between the jobs via hashes. This is what you will get if that is not setup:&lt;/p&gt;
&lt;p&gt;But if there is no artifact between them, what do you do? You create one.&lt;/p&gt;
&lt;h1 id=&#34;the-artifact-which-binds-us&#34;&gt;The Artifact which Binds Us&lt;/h1&gt;
&lt;p&gt;Adding a simple &lt;strong&gt;timestamp file&lt;/strong&gt; is enough to make a connection. So let’s do that. This is how it will look like =&amp;gt;&lt;/p&gt;
&lt;p&gt;The important bits about this picture are the small echo which simply creates a file which will contain some time stamp data, and after that the archive artifact, which also fingerprints that file, marking it with a hash which identifies this job as using that particular artifact.&lt;/p&gt;
&lt;p&gt;Now, the next step is to create the connection. For that, you need the artifact copy plugin =&amp;gt; &lt;!-- raw HTML omitted --&gt;Copy Artifact Plugin&lt;!-- raw HTML omitted --&gt;.&lt;/p&gt;
&lt;p&gt;With this, we create the childs configuration like this:&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;Again, the improtant bit is this:&lt;/p&gt;
&lt;p&gt;After the copy is setup, we launch our parent job and if everything is correct, you should see something like this:&lt;/p&gt;
&lt;h1 id=&#34;wrapping-it-up&#34;&gt;Wrapping it Up&lt;/h1&gt;
&lt;p&gt;For final words, important bit to take away from this is that you need an &lt;strong&gt;artifact connection between the jobs&lt;/strong&gt; to make this work. Whatever your downstream / upstream connection is, it doesn’t matter. Also, there can be a problem that you have everything set up, and there are artifacts which bind the jobs together but you still can’t see the results, then your best option is to specify the jobs BY NAME in the aggregate test plug-in like this:&lt;/p&gt;
&lt;p&gt;I know this is a pain if there are multiple jobs, but at least, jenkins is providing you with Autoexpande once you start typing.&lt;/p&gt;
&lt;p&gt;Of course this also works with multiple downstream jobs if they copy the artifact to themselves.&lt;/p&gt;
&lt;p&gt;Any questions, please feel free to comment and I will answer to the best of my knowledge.&lt;/p&gt;
&lt;p&gt;Cheers,
Gergely.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Selenium Testing with Packer and Vagrant</title>
      <link>https://skarlso.github.io/2015/07/16/selenium-testing-with-packer-and-vagrant/</link>
      <pubDate>Thu, 16 Jul 2015 00:00:00 +0000</pubDate>
      <guid>https://skarlso.github.io/2015/07/16/selenium-testing-with-packer-and-vagrant/</guid>
      <description>&lt;p&gt;So, recently, the tester team talked to me, that their build takes too long, and why is that? A quick look at their configuration and build scripts showed me, that they are actually using a vagrant box, which never gets destroyed or re-started at least. To remedy this problem, I came up with the following solution…&lt;/p&gt;
&lt;h1 id=&#34;same-old8230&#34;&gt;Same old…&lt;/h1&gt;
&lt;p&gt;Same as in my previous post, we are going to build a Windows Machine for this purpose. The only addition to my previous settings, will be some Java install, downloading selenium and installing Chrome, and Firefox.&lt;/p&gt;
&lt;h1 id=&#34;installation&#34;&gt;Installation&lt;/h1&gt;
&lt;h4 id=&#34;answer-file&#34;&gt;Answer File&lt;/h4&gt;
&lt;p&gt;Here is the configuration and setup of Windows before the provision phase.&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;This is the part were I’m installing Java. The script for the jdk_inst.ps1 is in my previous post, but I’ll paste it here for ease of read.&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;This installs both x86 and 64 bit version of Java.&lt;/p&gt;
&lt;h1 id=&#34;provision&#34;&gt;Provision&lt;/h1&gt;
&lt;p&gt;I decided to put these into the provision phase to get log messages written out properly. Because in the unattended file, you can’t see any progress.&lt;/p&gt;
&lt;h4 id=&#34;chrome-and-firefox&#34;&gt;Chrome And Firefox&lt;/h4&gt;
&lt;p&gt;Installing these two proved a little bit more difficult. Chrome didn’t really like me to download their installer without accepting something first, like Java. Luckily, after a LOT of digging, I found a chrome installer which lets you install silently. Here is the script to install the two.&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;They both install silently. Pretty neat.&lt;/p&gt;
&lt;h4 id=&#34;selenium&#34;&gt;Selenium&lt;/h4&gt;
&lt;p&gt;This only has to be downloaded, so this is pretty simple. Vagrant will handle the startup of course when it does a vagrant up.&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;Straightforward.&lt;/p&gt;
&lt;h4 id=&#34;the-packer-json-file&#34;&gt;The Packer Json File&lt;/h4&gt;
&lt;p&gt;So putting this all together, here is the Packer JSON file for this:&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;h4 id=&#34;additional-software&#34;&gt;Additional Software&lt;/h4&gt;
&lt;p&gt;This is not done here. Obviously, in order to test your stuff, you first need to install your software on this box. Ideally, everything you need should be in the code you clone to this box, and should be contained mostly. And your application deployment should take core of that. But, if you require something like a DB, postgres, oracle, whatnot, than this is the place where you would install all that.&lt;/p&gt;
&lt;h1 id=&#34;vagrant-and-using-the-packer-box&#34;&gt;Vagrant and Using the Packer Box&lt;/h1&gt;
&lt;p&gt;Now, this has been interesting so far, but how do you actually go about using this image? That’s the real question now, isn’t it? Having a box, just sitting on a shared folder, doesn’t do you too much good. So let’s create a Jenkins job, which utilizes this box in a job which runs a bunch of tests for some application.&lt;/p&gt;
&lt;h4 id=&#34;vagrantfile&#34;&gt;Vagrantfile&lt;/h4&gt;
&lt;p&gt;Your vagrant file, could either be generated automatically, under source control ( which is preferred ) or sitting somewhere entirely elsewhere. In any case, it would look something like this.&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;Easy, no? Here is the script to start selenium.&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;Straight forward. We also are forwarding the port on which Selenium is running in order for the test to see it.&lt;/p&gt;
&lt;h4 id=&#34;the-jenkins-job&#34;&gt;The Jenkins Job&lt;/h4&gt;
&lt;p&gt;The job can be anything. This is actually too large to cover here. It could be a gradle job, a maven job, an ant, a nant – or whatever is running the test -, job; it’s up to you.&lt;/p&gt;
&lt;p&gt;Just make sure that before the test runs, do a &lt;strong&gt;vagrant up&lt;/strong&gt; and after the test finishes, in an ALWAYS TO BE EXECUTED HOOK -like gradle’s finalizedBy , call a &lt;strong&gt;vagrant destroy&lt;/strong&gt;. This way, your test will always run on a clean instance that has the necessary stuff on it.&lt;/p&gt;
&lt;h1 id=&#34;closing-words&#34;&gt;Closing words&lt;/h1&gt;
&lt;p&gt;So, there you have it. It’s relatively simple. Tying this all into your infrastructure might prove difficult though depending on how rigid your deployment is. But it will always help you make your tests a bit more robust.&lt;/p&gt;
&lt;p&gt;Also, you could run the whole deployment and test phase on a vagrant box, from the start, which is tied to jenkins as a slave and gets started when the job starts and destroyed when the job ends. That way you wouldn’t have to create a, box in a box running on a box, kind of effect.&lt;/p&gt;
&lt;p&gt;Thanks for reading,&lt;/p&gt;
&lt;p&gt;Gergely.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Updating All Jenkins Jobs Via Jenkins API – Python</title>
      <link>https://skarlso.github.io/2014/11/07/updating-all-jenkins-jobs-via-jenkins-api-python/</link>
      <pubDate>Fri, 07 Nov 2014 00:00:00 +0000</pubDate>
      <guid>https://skarlso.github.io/2014/11/07/updating-all-jenkins-jobs-via-jenkins-api-python/</guid>
      <description>&lt;p&gt;Hello everybody.&lt;/p&gt;
&lt;p&gt;I would like to share with you a small script I wrote to update all, or a single, Jenkins job from a Python script remotely.&lt;/p&gt;
&lt;p&gt;This will enable you to update a Jenkins job from anywhere using an admin credential based on a config.xml template that you have. With this, if you want to apply a config change to all or just a single job in Jenkins, you don’t have to go and do it for all the rest. You just call this script and it will cycle through all the jobs you have and update them if the begin with “yourpipelinedelimiter” or if they aren’t in a restricted list of jobs. The delimiter helps to identify pipelines which are dev pipelines. If you have multiple pipelines which are helpers or builders and you don’t usually apply the same config to them, than the delimiter can help identify the dev pipelines you actually want to update.&lt;/p&gt;
&lt;p&gt;Enjoy, hope it helps someone.&lt;/p&gt;
&lt;p&gt;And now, without any further ado:&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;Thanks for reading.&lt;/p&gt;
&lt;p&gt;Gergely.&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>
