<!DOCTYPE html>
<html lang="en">
<head>
  
    <title>RScrap scraper :: Ramblings of a cloud engineer</title>
  
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">
<meta name="description" content="Intro Hey folks.
So, there is this project called Huginn which I absolutely love.
But the thing is, that for a couple of scrappers ( at least for me ), I don&amp;rsquo;t want to spin up a whole rails app.
Hence, I&amp;rsquo;ve come up with RScrap. Which is a bunch of Ruby scripts run as cron jobs on a raspberry pi. And because I dislike emails as well, and most of the time, I don&amp;rsquo;t read them, I opted for a nicer solution."/>
<meta name="keywords" content=""/>
<meta name="robots" content="noodp"/>
<link rel="canonical" href="https://skarlso.github.io/2016/10/06/rscrap-ruby-scraping-with-cronjob-scripts/" />


<link rel="stylesheet" href="https://skarlso.github.io/assets/style.css">

  <link rel="stylesheet" href="https://skarlso.github.io/assets/green.css">



<link rel="stylesheet" href="https://skarlso.github.io/style.css">


<link rel="apple-touch-icon-precomposed" sizes="144x144" href="https://skarlso.github.io/img/apple-touch-icon-144-precomposed.png">

  <link rel="shortcut icon" href="https://skarlso.github.io/img/favicon/green.png">



<meta name="twitter:card" content="summary" />
<meta name="twitter:title" content="RScrap scraper :: Ramblings of a cloud engineer — " />
<meta name="twitter:description" content="Intro Hey folks.
So, there is this project called Huginn which I absolutely love.
But the thing is, that for a couple of scrappers ( at least for me ), I don&amp;rsquo;t want to spin up a whole rails app.
Hence, I&amp;rsquo;ve come up with RScrap. Which is a bunch of Ruby scripts run as cron jobs on a raspberry pi. And because I dislike emails as well, and most of the time, I don&amp;rsquo;t read them, I opted for a nicer solution." />
<meta name="twitter:site" content="https://skarlso.github.io/" />
<meta name="twitter:creator" content="hannibal" />
<meta name="twitter:image" content="">


<meta property="og:locale" content="en" />
<meta property="og:type" content="article" />
<meta property="og:title" content="RScrap scraper :: Ramblings of a cloud engineer — ">
<meta property="og:description" content="Intro Hey folks.
So, there is this project called Huginn which I absolutely love.
But the thing is, that for a couple of scrappers ( at least for me ), I don&amp;rsquo;t want to spin up a whole rails app.
Hence, I&amp;rsquo;ve come up with RScrap. Which is a bunch of Ruby scripts run as cron jobs on a raspberry pi. And because I dislike emails as well, and most of the time, I don&amp;rsquo;t read them, I opted for a nicer solution." />
<meta property="og:url" content="https://skarlso.github.io/2016/10/06/rscrap-ruby-scraping-with-cronjob-scripts/" />
<meta property="og:site_name" content="RScrap scraper" />
<meta property="og:image" content="">
<meta property="og:image:width" content="2048">
<meta property="og:image:height" content="1024">
<meta property="article:section" content="Ruby" />
<meta property="article:published_time" content="2016-10-06 00:00:00 &#43;0000 UTC" />







</head>
<body class="">
<div class="container">
  <header class="header">
  <div class="header__inner">
    <div class="header__logo">
      <a href="https://skarlso.github.io/">
  <div class="logo">
    Terminal
  </div>
</a>

    </div>
    <div class="menu-trigger">menu</div>
  </div>
  
    <nav class="menu">
  <ul class="menu__inner menu__inner--desktop">
    
      
        
          <li><a href="https://skarlso.github.io/">Home</a></li>
        
      
        
          <li><a href="https://skarlso.github.io/blog/">Blog</a></li>
        
      
        
          <li><a href="https://skarlso.github.io/categories/">Categories</a></li>
        
      
    
  </ul>

  <ul class="menu__inner menu__inner--mobile">
    
      
        <li><a href="https://skarlso.github.io/">Home</a></li>
      
    
      
        <li><a href="https://skarlso.github.io/blog/">Blog</a></li>
      
    
      
        <li><a href="https://skarlso.github.io/categories/">Categories</a></li>
      
    
  </ul>
</nav>

  
</header>


  <div class="content">
    
  <div class="post">
    <h1 class="post-title"><a href="https://skarlso.github.io/2016/10/06/rscrap-ruby-scraping-with-cronjob-scripts/">RScrap scraper</a></h1>
    <div class="post-meta">
      <span class="post-date">
        2016-10-06
      </span>
      <span class="post-author">:: hannibal</span>
    </div>

    

    

    <div class="post-content">
      

<h1 id="intro">Intro</h1>

<p>Hey folks.</p>

<p>So, there is this project called <a href="https://github.com/cantino/huginn">Huginn</a> which I absolutely love.</p>

<p>But the thing is, that for a couple of scrappers ( at least for me ), I don&rsquo;t want to spin up a whole rails app.</p>

<p>Hence, I&rsquo;ve come up with <a href="https://github.com/Skarlso/rscrap">RScrap</a>. Which is a bunch of Ruby scripts run as cron jobs on a raspberry pi. And because I dislike emails as well, and most of the time, I don&rsquo;t read them, I opted for a nicer solution. Enter the world of <a href="https://telegram.org">Telegram</a>. They provide you with the ability to create bots. You basically get an API key, and than using that key, you can send private messages, or even create an interactive bot which you can send messages too.</p>

<p>In my simple example, I&rsquo;m using it to send private messages to myself, but I could just as well, make it interactive and than tell it to run one of the scripts.</p>

<h1 id="the-code">The Code</h1>

<p>Let&rsquo;s take a look at what we got.</p>

<h2 id="the-main-scraper">The main scraper</h2>

<p>The main scraper, is simply bunch of convenience methods that wrap handling and working with the database and the telegram bot. That&rsquo;s all. It&rsquo;s very simple. Very short. The Telegram part is just this bit:</p>

<pre><code class="language-ruby">def send_message(text)
  Telegram::Bot::Client.run(@token) do |bot|
    bot.api.send_message(chat_id: @id, text: text)
  end
end
</code></pre>

<p>Straightforward. Creating an interactive bot, would look something like this:</p>

<pre><code class="language-ruby">#!/usr/bin/env ruby
require 'telegram/bot'

token = 'YOUR_TELEGRAM_BOT_API_TOKEN'

Telegram::Bot::Client.run(token) do |bot|
  bot.listen do |message|
    case message.text
    when '/start'
      bot.api.send_message(chat_id: message.chat.id, text: &quot;Hello, #{message.from.first_name}&quot;)
    when '/stop'
      bot.api.send_message(chat_id: message.chat.id, text: &quot;Bye, #{message.from.first_name}&quot;)
    end
  end
end
</code></pre>

<p>Basically, it will listen, and than you can send it messages and based on the parsed <code>message.text</code> you can define functions to call. For example, for rscrap I could define something like <code>run_script(script)</code>. And the command would be: <code>/run reddit</code>. Which will execute my reddit script. The possibilities are endless.</p>

<h2 id="the-scripts">The scripts</h2>

<p>The scripts use nokogiri to parse a web page, and than return a URL which will be sent by the TelegramBot. They are also saved in the database so that when a new comic strip comes out, I know that it&rsquo;s new. For reddit, I&rsquo;m saving a timestamp as well, and I collect everything after that timestamp through the reddit API as JSON, and send it as a bundled message with shortified links to the posts using bit.ly.</p>

<p>The scraping is most of the times the same for every comic. Thus, there is a helper method for it. The script itself, is very short. For example, lets look at gunnerkrigg court.</p>

<pre><code class="language-ruby">require_relative '../rscrap'
require 'nokogiri'
require 'open-uri'

url = 'http://www.gunnerkrigg.com'
scrap = Rscrap.new
page = Nokogiri::HTML(open(url))
comic_id = page.css('img.comic_image')[0].select { |e| e if e[0] == 'src' }[0][1]
new_comic = &quot;#{url}#{comic_id}&quot;
scrap.send_new_comic(url, new_comic)
</code></pre>

<p>The interesting part of it is this bit: <code>comic_id = page.css('img.comic_image')[0].select { |e| e if e[0] == 'src' }[0][1]</code>. It extracts the URL for the comic image, and stores it as an &ldquo;id&rdquo; of the comic. This than, is sent as a message which Telegram will embed. There is no need to visit the web page, the image is in your feed and you can view it directly. Just like an RSS ready.</p>

<h2 id="cron">Cron</h2>

<p>These scripts are best used in a cron job. The comics are usually running with a daily frequency, where as the reddit gatherer is running with an hour frequency. Basically, I&rsquo;m receiving updates on an hourly basis if there are new posts by then. Running ruby from cron was a bit tricky. I&rsquo;m using bundler for the environment, and came up with this:</p>

<pre><code class="language-bash">0 6-23 * * * /bin/bash -l -c 'cd /home/&lt;youruser&gt;/rubyproj/rscrap &amp;&amp; bundle exec ruby scripts/reddit.rb'
0 8,22 * * * /bin/bash -l -c 'cd /home/&lt;youruser&gt;/rubyproj/rscrap &amp;&amp; bundle exec ruby scripts/gunnerkrigg.rb'
0 8,22 * * * /bin/bash -l -c 'cd /home/&lt;youruser&gt;/rubyproj/rscrap &amp;&amp; bundle exec ruby scripts/aws_blog.rb'
0 5,23 * * * /bin/bash -l -c 'cd /home/&lt;youruser&gt;/rubyproj/rscrap &amp;&amp; bundle exec ruby scripts/goblinscomic.rb'
0 6,20 * * * /bin/bash -l -c 'cd /home/&lt;youruser&gt;/rubyproj/rscrap &amp;&amp; bundle exec ruby scripts/xkcd.rb'
0 7,19 * * * /bin/bash -l -c 'cd /home/&lt;youruser&gt;/rubyproj/rscrap &amp;&amp; bundle exec ruby scripts/commitstrip.rb'
0 8 * * * /bin/bash -l -c 'cd /home/&lt;youruser&gt;/rubyproj/rscrap &amp;&amp; bundle exec ruby scripts/sequiential_art.rb'
</code></pre>

<p>And a telegram message for all these things, looks like this:
Reddit:
<img src="https://github.com/Skarlso/rscrap/raw/master/shorten.png" alt="TelegramIMReddit" />
Comics:
<img src="https://github.com/Skarlso/rscrap/raw/master/rscrap2.png" alt="TelegramIMComics" /></p>

<h1 id="conclusion">Conclusion</h1>

<p>That&rsquo;s it folks. Adding a new scraper is easy. I added the aws blog as a new entry as well by just copying the comics scripts. And I&rsquo;m also getting Weather Reports delivered every morning to me.</p>

<p>Have fun. Any questions, please feel free to leave a comment!</p>

<p>Thanks,
Gergely.</p>

    </div>
    
      <div class="pagination">
        <div class="pagination__title">
          <span class="pagination__title-h"></span>
          <hr />
        </div>
        <div class="pagination__buttons">
          
            <span class="button previous">
              <a href="https://skarlso.github.io/2016/11/02/google-signin-with-go-part2/">
                <span class="button__icon">←</span>
                <span class="button__text">How to do Google Sign-In with Go - Part 2</span>
              </a>
            </span>
          
          
            <span class="button next">
              <a href="https://skarlso.github.io/2016/09/17/simple-hometheater-with-remote-and-flirc/">
                <span class="button__text">Budget Home Theather with a Headless Raspberry Pi and Flirc for Remote Controlling</span>
                <span class="button__icon">→</span>
              </a>
            </span>
          
        </div>
      </div>
    
  </div>

  </div>

  
    <footer class="footer">
  <div class="footer__inner">
    
      <div class="copyright">
        <span>© 2019 Powered by <a href="http://gohugo.io">Hugo</a></span>
        <span>:: Theme made by <a href="https://twitter.com/panr">panr</a></span>
      </div>
    
  </div>
</footer>

<script src="https://skarlso.github.io/assets/main.js"></script>
<script src="https://skarlso.github.io/assets/prism.js"></script>

  
</div>

</body>
</html>
